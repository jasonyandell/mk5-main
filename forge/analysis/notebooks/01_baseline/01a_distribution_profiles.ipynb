{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01a: Distribution Profiles\n",
    "\n",
    "**Goal**: Establish baseline characterization of the oracle data.\n",
    "\n",
    "**Key Questions**:\n",
    "1. Does `n_states` follow a power law with depth? (fractal branching)\n",
    "2. Does `v_unique` saturate early? (low intrinsic dimensionality)\n",
    "3. Does `v_entropy` scale logarithmically or slower? (structure)\n",
    "4. Is `v_std` predictable from depth? (exploitable for compression)\n",
    "\n",
    "**Reference**: docs/analysis-draft.md Section 1.1"
   ]
  },
  {
   "cell_type": "code",
   "source": "# === CONFIGURATION ===\nDATA_DIR = \"/mnt/d/shards-standard/\"\nPROJECT_ROOT = \"/home/jason/v2/mk5-tailwind\"\n\n# === Setup imports ===\nimport sys\nif PROJECT_ROOT not in sys.path:\n    sys.path.insert(0, PROJECT_ROOT)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nfrom forge.analysis.utils import loading, features, compression, viz\nfrom forge.oracle import schema\n\nviz.setup_notebook_style()\nprint(\"✓ Ready\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Seeds\n",
    "\n",
    "Load multiple seeds to get robust statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find available seeds\nshard_files = loading.find_shard_files(DATA_DIR)\nprint(f\"Total shards available: {len(shard_files)}\")\n\n# Sample 10-20 seeds for analysis\nN_SEEDS = min(20, len(shard_files))\nsample_files = shard_files[:N_SEEDS]\nprint(f\"Analyzing {N_SEEDS} shards\")"
  },
  {
   "cell_type": "code",
   "source": "# Compute per-depth statistics for each shard\n# This creates stats_df with columns: seed, decl_id, depth, n_states, v_mean, v_std, v_unique, v_entropy\n\n# Limit to 10 seeds for faster analysis (adjust as needed)\nN_SEEDS = min(10, len(shard_files))\nsample_files = shard_files[:N_SEEDS]\nprint(f\"Analyzing {N_SEEDS} shards...\")\n\nrecords = []\nfor path in tqdm(sample_files, desc=\"Loading shards\"):\n    df, seed, decl_id = schema.load_file(path)\n    V = df['V'].values\n    depths = features.depth(df['state'].values)\n    \n    # Compute stats per depth\n    for d in np.unique(depths):\n        mask = depths == d\n        V_at_depth = V[mask]\n        \n        # Compute entropy\n        unique_vals, counts = np.unique(V_at_depth, return_counts=True)\n        probs = counts / counts.sum()\n        entropy = -np.sum(probs * np.log2(probs + 1e-12))\n        \n        records.append({\n            'seed': seed,\n            'decl_id': decl_id,\n            'depth': d,\n            'n_states': len(V_at_depth),\n            'v_mean': V_at_depth.mean(),\n            'v_std': V_at_depth.std(),\n            'v_unique': len(unique_vals),\n            'v_entropy': entropy,\n        })\n\nstats_df = pd.DataFrame(records)\nprint(f\"✓ Built stats_df: {len(stats_df)} rows ({len(sample_files)} shards × ~28 depths)\")\nprint(f\"Total states: {stats_df['n_states'].sum():,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State Count Scaling\n",
    "\n",
    "Does `n_states` follow a power law with depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average n_states per depth\n",
    "depth_avg = stats_df.groupby('depth').agg({\n",
    "    'n_states': ['mean', 'std', 'count'],\n",
    "    'v_mean': 'mean',\n",
    "    'v_std': 'mean',\n",
    "    'v_unique': 'mean',\n",
    "    'v_entropy': 'mean',\n",
    "}).reset_index()\n",
    "depth_avg.columns = ['depth', 'n_states_mean', 'n_states_std', 'n_seeds', 'v_mean', 'v_std', 'v_unique', 'v_entropy']\n",
    "\n",
    "print(\"Average statistics by depth:\")\n",
    "print(depth_avg[['depth', 'n_states_mean', 'v_unique', 'v_entropy']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-log plot of state count vs depth\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Linear scale\n",
    "axes[0].scatter(depth_avg['depth'], depth_avg['n_states_mean'], alpha=0.7)\n",
    "axes[0].set_xlabel('Depth (dominoes remaining)')\n",
    "axes[0].set_ylabel('Average states')\n",
    "axes[0].set_title('State Count vs Depth (Linear)')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Log-log for power law fit\n",
    "valid = depth_avg[depth_avg['n_states_mean'] > 0]\n",
    "viz.plot_log_log(\n",
    "    valid['depth'].values.astype(float),\n",
    "    valid['n_states_mean'].values,\n",
    "    ax=axes[1],\n",
    "    title='State Count vs Depth (Log-Log)',\n",
    "    xlabel='Depth',\n",
    "    ylabel='Average states',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. V Unique Values\n",
    "\n",
    "Does `v_unique` saturate? (Low intrinsic dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unique V values vs depth\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Unique values\n",
    "axes[0].plot(depth_avg['depth'], depth_avg['v_unique'], 'o-', markersize=6)\n",
    "axes[0].axhline(y=85, color='red', linestyle='--', alpha=0.5, label='Max possible (85)')\n",
    "axes[0].set_xlabel('Depth')\n",
    "axes[0].set_ylabel('Unique V values')\n",
    "axes[0].set_title('V Unique Values vs Depth')\n",
    "axes[0].legend()\n",
    "\n",
    "# As fraction of max\n",
    "axes[1].plot(depth_avg['depth'], depth_avg['v_unique'] / 85, 'o-', markersize=6)\n",
    "axes[1].set_xlabel('Depth')\n",
    "axes[1].set_ylabel('Fraction of possible values used')\n",
    "axes[1].set_title('V Coverage vs Depth')\n",
    "axes[1].set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check saturation\n",
    "max_unique = depth_avg['v_unique'].max()\n",
    "print(f\"Maximum unique V values: {max_unique:.0f} / 85 ({100*max_unique/85:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. V Entropy Scaling\n",
    "\n",
    "Does entropy scale logarithmically or slower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Entropy vs depth\n",
    "axes[0].plot(depth_avg['depth'], depth_avg['v_entropy'], 'o-', markersize=6)\n",
    "max_entropy = np.log2(85)\n",
    "axes[0].axhline(y=max_entropy, color='red', linestyle='--', alpha=0.5, label=f'Max ({max_entropy:.2f} bits)')\n",
    "axes[0].set_xlabel('Depth')\n",
    "axes[0].set_ylabel('H(V) (bits)')\n",
    "axes[0].set_title('V Entropy vs Depth')\n",
    "axes[0].legend()\n",
    "\n",
    "# Entropy vs log(n_states) - check if entropy grows with sample size\n",
    "valid = depth_avg[(depth_avg['n_states_mean'] > 0) & (depth_avg['v_entropy'] > 0)]\n",
    "axes[1].scatter(np.log10(valid['n_states_mean']), valid['v_entropy'], alpha=0.7)\n",
    "axes[1].set_xlabel('log10(n_states)')\n",
    "axes[1].set_ylabel('H(V) (bits)')\n",
    "axes[1].set_title('Entropy vs State Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "overall_entropy = stats_df.groupby('seed')['v_entropy'].mean().mean()\n",
    "print(f\"Average H(V) across seeds: {overall_entropy:.3f} bits\")\n",
    "print(f\"Efficiency vs max: {100*overall_entropy/max_entropy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. V Standard Deviation\n",
    "\n",
    "Is `v_std` predictable from depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# V std vs depth\n",
    "axes[0].plot(depth_avg['depth'], depth_avg['v_std'], 'o-', markersize=6)\n",
    "axes[0].set_xlabel('Depth')\n",
    "axes[0].set_ylabel('V std')\n",
    "axes[0].set_title('V Standard Deviation vs Depth')\n",
    "\n",
    "# V mean vs depth (should be near 0 for symmetric game)\n",
    "axes[1].plot(depth_avg['depth'], depth_avg['v_mean'], 'o-', markersize=6)\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].set_xlabel('Depth')\n",
    "axes[1].set_ylabel('V mean')\n",
    "axes[1].set_title('V Mean vs Depth')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check correlation\n",
    "corr = np.corrcoef(depth_avg['depth'], depth_avg['v_std'])[0,1]\n",
    "print(f\"Correlation(depth, v_std): {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Per-Seed Variation\n",
    "\n",
    "How much do distributions vary across seeds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot V distribution for multiple seeds\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, path in enumerate(sample_files[:6]):\n",
    "    df, seed, decl_id = schema.load_file(path)\n",
    "    V = df['V'].values\n",
    "    viz.plot_v_distribution(\n",
    "        V, ax=axes[i],\n",
    "        title=f'Seed {seed}, {schema.DECL_NAMES[decl_id]}',\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-seed variance analysis\n",
    "seed_stats = stats_df.groupby('seed').agg({\n",
    "    'n_states': 'sum',\n",
    "    'v_mean': 'mean',\n",
    "    'v_entropy': 'mean',\n",
    "}).reset_index()\n",
    "\n",
    "print(\"Per-seed summary:\")\n",
    "print(seed_stats.describe())\n",
    "\n",
    "print(f\"\\nEntropy coefficient of variation: {seed_stats['v_entropy'].std() / seed_stats['v_entropy'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Declaration Type Analysis\n",
    "\n",
    "Does distribution vary by declaration type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by declaration\n",
    "decl_stats = stats_df.groupby('decl_id').agg({\n",
    "    'n_states': 'sum',\n",
    "    'v_mean': 'mean',\n",
    "    'v_std': 'mean',\n",
    "    'v_entropy': 'mean',\n",
    "}).reset_index()\n",
    "\n",
    "decl_stats['decl_name'] = decl_stats['decl_id'].map(lambda x: schema.DECL_NAMES.get(x, str(x)))\n",
    "print(\"By declaration type:\")\n",
    "print(decl_stats[['decl_name', 'n_states', 'v_mean', 'v_entropy']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key findings from distribution profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile key metrics\n",
    "total_states = stats_df['n_states'].sum()\n",
    "avg_entropy = stats_df['v_entropy'].mean()\n",
    "max_unique = stats_df['v_unique'].max()\n",
    "peak_depth = depth_avg.loc[depth_avg['n_states_mean'].idxmax(), 'depth']\n",
    "\n",
    "summary = {\n",
    "    'Total states analyzed': f\"{total_states:,}\",\n",
    "    'Seeds analyzed': N_SEEDS,\n",
    "    'Average H(V)': f\"{avg_entropy:.3f} bits\",\n",
    "    'Max unique V values': f\"{max_unique} / 85\",\n",
    "    'Peak state count depth': int(peak_depth),\n",
    "    'V mean (overall)': f\"{stats_df['v_mean'].mean():.3f}\",\n",
    "    'V std (overall)': f\"{stats_df['v_std'].mean():.3f}\",\n",
    "}\n",
    "\n",
    "print(viz.create_summary_table(summary, \"Distribution Profile Summary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "stats_df.to_csv('../../results/tables/01a_depth_stats.csv', index=False)\n",
    "print(\"Results saved to results/tables/01a_depth_stats.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}