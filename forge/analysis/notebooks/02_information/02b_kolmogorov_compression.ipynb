{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02b: Kolmogorov Compression Analysis\n",
    "\n",
    "**Goal**: Estimate algorithmic complexity of V via compression.\n",
    "\n",
    "**Key Questions**:\n",
    "1. If depth ordering compresses much better, V has depth-coherent structure\n",
    "2. If all orderings compress similarly, structure is global not local\n",
    "3. Absolute ratio: 0.1 = very structured, 0.9 = near random\n",
    "\n",
    "**Reference**: docs/analysis-draft.md Section 3.2"
   ]
  },
  {
   "cell_type": "code",
   "source": "# === CONFIGURATION ===\nDATA_DIR = \"/mnt/d/shards-standard/\"\nPROJECT_ROOT = \"/home/jason/v2/mk5-tailwind\"\n\n# === Setup imports ===\nimport sys\nif PROJECT_ROOT not in sys.path:\n    sys.path.insert(0, PROJECT_ROOT)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nfrom forge.analysis.utils import loading, features, compression, viz\nfrom forge.oracle import schema\n\nviz.setup_notebook_style()\nprint(\"âœ“ Ready\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single Seed Analysis\n",
    "\n",
    "Analyze compression for one seed in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load first shard\nshard_files = loading.find_shard_files(DATA_DIR)\ndf, seed, decl_id = schema.load_file(shard_files[0])\n\nstates = df['state'].values\nV = df['V'].values.astype(np.int8)\n\nprint(f\"Seed: {seed}, Declaration: {schema.DECL_NAMES[decl_id]}\")\nprint(f\"States: {len(states):,}\")\nprint(f\"V size: {V.nbytes:,} bytes\")"
  },
  {
   "cell_type": "code",
   "source": "# Compute compression under different orderings\ncomp_results = compression.compression_analysis(states, V)\n\nprint(\"Compression ratios by ordering:\")\nfor name, ratio in comp_results.items():\n    print(f\"  {name}: {ratio:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "viz.plot_compression_comparison(comp_results, ax=ax, title=f\"Compression by Ordering (seed={seed})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/figures/02b_compression_single.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-Seed Comparison\n",
    "\n",
    "Is the pattern consistent across seeds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analyze multiple seeds (limit to 10 for faster analysis)\nN_SEEDS = min(10, len(shard_files))\nmulti_results = []\n\nfor path in tqdm(shard_files[:N_SEEDS], desc=\"Analyzing seeds\"):\n    df, seed, decl_id = schema.load_file(path)\n    states = df['state'].values\n    V = df['V'].values.astype(np.int8)\n    \n    comp = compression.compression_analysis(states, V)\n    comp['seed'] = seed\n    comp['decl_id'] = decl_id\n    comp['n_states'] = len(states)\n    multi_results.append(comp)\n\ncomp_df = pd.DataFrame(multi_results)\nprint(f\"Analyzed {len(comp_df)} seeds\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nCompression ratio statistics:\")\n",
    "print(comp_df[['depth_order', 'state_order', 'random_order']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison across seeds\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot comparison\n",
    "comp_melted = comp_df.melt(\n",
    "    id_vars=['seed', 'decl_id'],\n",
    "    value_vars=['depth_order', 'state_order', 'random_order'],\n",
    "    var_name='ordering',\n",
    "    value_name='ratio'\n",
    ")\n",
    "import seaborn as sns\n",
    "sns.boxplot(data=comp_melted, x='ordering', y='ratio', ax=axes[0])\n",
    "axes[0].set_ylabel('Compression Ratio')\n",
    "axes[0].set_title('Compression by Ordering (all seeds)')\n",
    "\n",
    "# Scatter: depth vs random\n",
    "axes[1].scatter(comp_df['random_order'], comp_df['depth_order'], alpha=0.6)\n",
    "axes[1].plot([0.1, 0.6], [0.1, 0.6], 'r--', alpha=0.5, label='y=x')\n",
    "axes[1].set_xlabel('Random Order Ratio')\n",
    "axes[1].set_ylabel('Depth Order Ratio')\n",
    "axes[1].set_title('Depth vs Random Ordering')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/figures/02b_compression_multi.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Per-Depth Compression\n",
    "\n",
    "Does compressibility vary with game depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze compression per depth\n",
    "df, seed, decl_id = schema.load_file(shard_files[0])\n",
    "states = df['state'].values\n",
    "V = df['V'].values.astype(np.int8)\n",
    "depths = features.depth(states)\n",
    "\n",
    "depth_compression = []\n",
    "for d in tqdm(range(1, int(depths.max()) + 1), desc=\"Analyzing depths\"):\n",
    "    mask = depths == d\n",
    "    if mask.sum() < 100:  # Skip sparse depths\n",
    "        continue\n",
    "    \n",
    "    v_d = V[mask]\n",
    "    ratio = compression.lzma_ratio(v_d.tobytes())\n",
    "    h = compression.entropy_bits(v_d)\n",
    "    \n",
    "    depth_compression.append({\n",
    "        'depth': d,\n",
    "        'n_states': mask.sum(),\n",
    "        'lzma_ratio': ratio,\n",
    "        'entropy': h,\n",
    "        'v_unique': len(np.unique(v_d)),\n",
    "    })\n",
    "\n",
    "depth_comp_df = pd.DataFrame(depth_compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# LZMA ratio vs depth\n",
    "axes[0].plot(depth_comp_df['depth'], depth_comp_df['lzma_ratio'], 'o-')\n",
    "axes[0].set_xlabel('Depth')\n",
    "axes[0].set_ylabel('LZMA Ratio')\n",
    "axes[0].set_title('Compressibility vs Depth')\n",
    "\n",
    "# Entropy vs depth\n",
    "axes[1].plot(depth_comp_df['depth'], depth_comp_df['entropy'], 'o-', color='orange')\n",
    "axes[1].set_xlabel('Depth')\n",
    "axes[1].set_ylabel('H(V) (bits)')\n",
    "axes[1].set_title('Entropy vs Depth')\n",
    "\n",
    "# LZMA vs entropy (should correlate)\n",
    "axes[2].scatter(depth_comp_df['entropy'], depth_comp_df['lzma_ratio'], alpha=0.6)\n",
    "axes[2].set_xlabel('Entropy (bits)')\n",
    "axes[2].set_ylabel('LZMA Ratio')\n",
    "axes[2].set_title('Compression vs Entropy')\n",
    "\n",
    "# Add correlation\n",
    "corr = np.corrcoef(depth_comp_df['entropy'], depth_comp_df['lzma_ratio'])[0,1]\n",
    "axes[2].text(0.05, 0.95, f'r = {corr:.3f}', transform=axes[2].transAxes, \n",
    "             verticalalignment='top', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Alternative Compression Presets\n",
    "\n",
    "Does stronger compression reveal more structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LZMA presets\n",
    "df, seed, decl_id = schema.load_file(shard_files[0])\n",
    "V = df['V'].values.astype(np.int8)\n",
    "\n",
    "preset_results = {}\n",
    "for preset in [0, 3, 6, 9]:\n",
    "    ratio = compression.lzma_ratio(V.tobytes(), preset=preset)\n",
    "    preset_results[f'preset_{preset}'] = ratio\n",
    "    print(f\"Preset {preset}: {ratio:.4f}\")\n",
    "\n",
    "# Also test gzip for comparison\n",
    "import gzip\n",
    "gzip_compressed = gzip.compress(V.tobytes(), compresslevel=9)\n",
    "gzip_ratio = len(gzip_compressed) / len(V.tobytes())\n",
    "print(f\"gzip-9: {gzip_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Q-Value Compression\n",
    "\n",
    "How compressible are Q-values compared to V?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Q-values\n",
    "df, seed, decl_id = schema.load_file(shard_files[0])\n",
    "V = df['V'].values.astype(np.int8)\n",
    "q_values = df[['q0', 'q1', 'q2', 'q3', 'q4', 'q5', 'q6']].values.astype(np.int8)\n",
    "\n",
    "# Compare compression\n",
    "v_ratio = compression.lzma_ratio(V.tobytes())\n",
    "q_ratio = compression.lzma_ratio(q_values.tobytes())\n",
    "\n",
    "print(f\"V compression ratio: {v_ratio:.4f}\")\n",
    "print(f\"Q compression ratio: {q_ratio:.4f}\")\n",
    "print(f\"Q/V ratio: {q_ratio/v_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-column Q compression\n",
    "q_col_ratios = {}\n",
    "for i in range(7):\n",
    "    q_col = q_values[:, i].astype(np.int8)\n",
    "    ratio = compression.lzma_ratio(q_col.tobytes())\n",
    "    q_col_ratios[f'q{i}'] = ratio\n",
    "\n",
    "print(\"\\nPer-column Q compression:\")\n",
    "for col, ratio in q_col_ratios.items():\n",
    "    print(f\"  {col}: {ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Delta Encoding\n",
    "\n",
    "Does encoding V as differences improve compression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta encoding (differences between adjacent values)\n",
    "depths = features.depth(df['state'].values)\n",
    "order = np.argsort(depths)\n",
    "V_ordered = V[order]\n",
    "\n",
    "# Compute deltas\n",
    "V_delta = np.diff(V_ordered).astype(np.int8)\n",
    "\n",
    "# Compare compression\n",
    "v_ordered_ratio = compression.lzma_ratio(V_ordered.tobytes())\n",
    "v_delta_ratio = compression.lzma_ratio(V_delta.tobytes())\n",
    "\n",
    "print(f\"V ordered ratio: {v_ordered_ratio:.4f}\")\n",
    "print(f\"V delta ratio: {v_delta_ratio:.4f}\")\n",
    "print(f\"Improvement from delta: {100*(v_ordered_ratio - v_delta_ratio)/v_ordered_ratio:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(V_delta, bins=100, alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('V delta (V[i+1] - V[i]) in depth order')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of V Deltas')\n",
    "ax.axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Delta mean: {V_delta.mean():.3f}\")\n",
    "print(f\"Delta std: {V_delta.std():.3f}\")\n",
    "print(f\"% zero deltas: {100*(V_delta == 0).mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall assessment\n",
    "avg_depth = comp_df['depth_order'].mean()\n",
    "avg_random = comp_df['random_order'].mean()\n",
    "improvement = 100 * (avg_random - avg_depth) / avg_random\n",
    "\n",
    "summary = {\n",
    "    'Seeds analyzed': len(comp_df),\n",
    "    'Avg depth-order ratio': f\"{avg_depth:.4f}\",\n",
    "    'Avg random-order ratio': f\"{avg_random:.4f}\",\n",
    "    'Improvement from ordering': f\"{improvement:.1f}%\",\n",
    "    'V ratio (seed 0)': f\"{v_ratio:.4f}\",\n",
    "    'Q ratio (seed 0)': f\"{q_ratio:.4f}\",\n",
    "    'Delta encoding benefit': f\"{100*(v_ordered_ratio - v_delta_ratio)/v_ordered_ratio:.1f}%\",\n",
    "}\n",
    "\n",
    "print(viz.create_summary_table(summary, \"Compression Analysis Summary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation\n",
    "if avg_depth < 0.3:\n",
    "    interpretation = \"HIGHLY STRUCTURED - V has strong depth-coherent patterns\"\n",
    "elif avg_depth < 0.5:\n",
    "    interpretation = \"MODERATELY STRUCTURED - V has exploitable patterns\"\n",
    "elif avg_depth < 0.7:\n",
    "    interpretation = \"WEAKLY STRUCTURED - Some patterns exist\"\n",
    "else:\n",
    "    interpretation = \"NEAR RANDOM - Little compressible structure\"\n",
    "\n",
    "print(f\"\\nInterpretation: {interpretation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "comp_df.to_csv('../../results/tables/02b_compression.csv', index=False)\n",
    "depth_comp_df.to_csv('../../results/tables/02b_compression_by_depth.csv', index=False)\n",
    "print(\"Results saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}