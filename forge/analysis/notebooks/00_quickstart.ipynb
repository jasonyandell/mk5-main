{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texas 42 Oracle Data Analysis - Quickstart\n",
    "\n",
    "This notebook verifies the analysis toolkit setup and demonstrates basic data loading.\n",
    "\n",
    "## Goals\n",
    "1. Verify utils module imports work\n",
    "2. Load sample shard data\n",
    "3. Explore basic V and Q-value distributions\n",
    "4. Test feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "source": "# === CONFIGURATION ===\nDATA_DIR = \"/mnt/d/shards-standard/\"\nPROJECT_ROOT = \"/home/jason/v2/mk5-tailwind\"\n\n# === Setup imports ===\nimport sys\nif PROJECT_ROOT not in sys.path:\n    sys.path.insert(0, PROJECT_ROOT)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom forge.analysis.utils import loading, features, compression, viz\nfrom forge.oracle import schema, tables\n\nviz.setup_notebook_style()\nprint(\"âœ“ Ready\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Discovery\n",
    "\n",
    "Let's see what shard data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find all shard files\nshard_files = loading.find_shard_files(DATA_DIR)\nprint(f\"Total shard files: {len(shard_files)}\")\n\n# Count by split\ncounts = loading.count_shards(DATA_DIR)\nprint(f\"\\nBy split:\")\nfor split, count in counts.items():\n    print(f\"  {split}: {count}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few files\n",
    "print(\"First 5 shard files:\")\n",
    "for f in shard_files[:5]:\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load a Single Shard\n",
    "\n",
    "Load one shard to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first available shard\n",
    "df, seed, decl_id = schema.load_file(shard_files[0])\n",
    "\n",
    "print(f\"Seed: {seed}\")\n",
    "print(f\"Declaration: {decl_id} ({schema.DECL_NAMES[decl_id]})\")\n",
    "print(f\"States: {len(df):,}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic stats\n",
    "print(f\"V range: [{df['V'].min()}, {df['V'].max()}]\")\n",
    "print(f\"V mean: {df['V'].mean():.2f}\")\n",
    "print(f\"V std: {df['V'].std():.2f}\")\n",
    "print(f\"V unique values: {df['V'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. V Distribution\n",
    "\n",
    "Visualize the distribution of minimax values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 6))\nviz.plot_v_distribution(df['V'].values, ax=ax, title=f\"V Distribution (seed={seed}, decl={schema.DECL_NAMES[decl_id]})\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction\n",
    "\n",
    "Extract analytical features from packed states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = df['state'].values\n",
    "V = df['V'].values\n",
    "\n",
    "# Extract basic features\n",
    "depths = features.depth(states)\n",
    "teams = features.team(states)\n",
    "players = features.player(states)\n",
    "\n",
    "print(f\"Depth range: [{depths.min()}, {depths.max()}]\")\n",
    "print(f\"Team 0 turns: {teams.sum():,} ({100*teams.mean():.1f}%)\")\n",
    "print(f\"Player distribution: {np.bincount(players)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V by depth\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "viz.plot_v_by_depth(V, depths, ax=ax, title=\"V Distribution by Depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State count by depth\n",
    "depth_counts = pd.Series(depths).value_counts().sort_index()\n",
    "print(\"States per depth:\")\n",
    "print(depth_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Q-Value Structure\n",
    "\n",
    "Analyze the Q-values (move evaluations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Q-values\n",
    "q_cols = ['q0', 'q1', 'q2', 'q3', 'q4', 'q5', 'q6']\n",
    "q_values = df[q_cols].values\n",
    "\n",
    "# Compute Q-statistics\n",
    "q_stats = features.q_stats(q_values)\n",
    "print(\"Q-value statistics:\")\n",
    "print(q_stats.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Q-structure\n",
    "viz.plot_q_structure(q_stats, title=f\"Q-Value Structure (seed={seed})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Count Domino Analysis\n",
    "\n",
    "The \"count\" dominoes (5-count and 10-count) are critical strategic elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show count dominoes\n",
    "print(\"Count dominoes:\")\n",
    "for d in features.COUNT_DOMINO_IDS:\n",
    "    pips = schema.domino_pips(d)\n",
    "    points = tables.DOMINO_COUNT_POINTS[d]\n",
    "    print(f\"  ID {d}: {pips[0]}-{pips[1]} = {points} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track count locations in this seed\n",
    "hands = schema.deal_from_seed(seed)\n",
    "print(f\"\\nDeal for seed {seed}:\")\n",
    "for p, hand in enumerate(hands):\n",
    "    hand_str = \", \".join(f\"{schema.domino_pips(d)}\" for d in hand)\n",
    "    print(f\"  P{p}: {hand_str}\")\n",
    "\n",
    "# Who holds each count at start?\n",
    "print(\"\\nCount domino locations at deal:\")\n",
    "for d in features.COUNT_DOMINO_IDS:\n",
    "    pips = schema.domino_pips(d)\n",
    "    for p, hand in enumerate(hands):\n",
    "        if d in hand:\n",
    "            team = \"Team 0\" if p % 2 == 0 else \"Team 1\"\n",
    "            print(f\"  {pips[0]}-{pips[1]} ({tables.DOMINO_COUNT_POINTS[d]}): Player {p} ({team})\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count points remaining vs V\n",
    "counts_rem = features.counts_remaining(states, seed)\n",
    "\n",
    "print(f\"Count points remaining: [{counts_rem.min()}, {counts_rem.max()}]\")\n",
    "print(f\"\\nCorrelation with V: {np.corrcoef(counts_rem, V)[0,1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Information Theory Preview\n",
    "\n",
    "Quick entropy calculation to preview structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy of V\n",
    "h_v = compression.entropy_bits(V)\n",
    "print(f\"H(V) = {h_v:.3f} bits\")\n",
    "print(f\"Max possible (85 values): {np.log2(85):.3f} bits\")\n",
    "print(f\"Efficiency: {h_v / np.log2(85) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional entropy given depth\n",
    "h_v_depth = compression.conditional_entropy(V, depths)\n",
    "mi_depth = h_v - h_v_depth\n",
    "\n",
    "print(f\"H(V|depth) = {h_v_depth:.3f} bits\")\n",
    "print(f\"I(V; depth) = {mi_depth:.3f} bits\")\n",
    "print(f\"Reduction from depth: {100 * mi_depth / h_v:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compression Preview\n",
    "\n",
    "Test LZMA compressibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare compression under different orderings\n",
    "comp_results = compression.compression_analysis(states, V.astype(np.int8))\n",
    "\n",
    "print(\"LZMA compression ratios (lower = more structure):\")\n",
    "for ordering, ratio in comp_results.items():\n",
    "    print(f\"  {ordering}: {ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "viz.plot_compression_comparison(comp_results, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook verified:\n",
    "- Analysis utils load correctly\n",
    "- Shard data is accessible\n",
    "- Feature extraction works\n",
    "- Basic entropy and compression metrics\n",
    "\n",
    "**Next notebooks:**\n",
    "- `01a_distribution_profiles.ipynb` - Deep dive into V/Q distributions\n",
    "- `02a_entropy_decomposition.ipynb` - Full information theory analysis\n",
    "- `03b_basin_analysis.ipynb` - Count domino basin partitioning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}