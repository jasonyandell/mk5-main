{"id":"t42-00g7","title":"Implement scripts/solver2 GPU solver for regret tables","description":"Create an independent PyTorch GPU solver in scripts/solver2 based on docs/SOLVER_GPU_TRAINING.md (state packing, GPU expand, BFS enumeration, child index, backward induction) with CLI + parquet output, runnable on 4GB GPUs and deployable to GPU farms.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T17:22:53.893723672-06:00","updated_at":"2025-12-27T17:39:48.01443674-06:00","closed_at":"2025-12-27T17:39:48.01443674-06:00","close_reason":"Completed"}
{"id":"t42-0mt","title":"Investigate one-hand-complete phase missing from UI mappings - signals incomplete feature integration","description":"CRITICAL: Do NOT update mappings without investigation. One-hand feature was recently added (ADR-20251112) but integration is incomplete.\n\nSvelte check errors in Header.svelte (lines 62-63):\n- phaseNames and phaseColors missing 'one-hand-complete' entry\n- GAME_PHASES constant doesn't include 'one-hand-complete'\n- GamePhase type DOES include it (added for one-hand mode)\n\nThis is a TYPE SAFETY VIOLATION - runtime could crash if state has 'one-hand-complete' phase.\n\nINVESTIGATION NEEDED:\n1. Was one-hand-complete phase fully integrated into all systems?\n2. What other UI components might be missing this phase?\n3. Should 'one-hand-complete' be in GAME_PHASES constant or is it special?\n4. What happens when game reaches this phase - does UI break?\n5. Are there other incomplete integrations from the one-hand feature?\n\nRelated: oneHandRuleSet was added to registry, tests updated to expect 7 rulesets. But UI wasn't updated.\n\nDo NOT just add mappings - understand WHY they're missing and what else might be incomplete.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-11-16T16:21:24.591273169-06:00","updated_at":"2025-12-20T22:18:59.672354538-06:00","closed_at":"2025-11-16T18:57:50.786096908-06:00"}
{"id":"t42-0tk","title":"Extract consensus into optional layer","description":"## Problem\n\nCurrent consensus logic is **deeply coupled** into the core engine:\n- `base.ts` generates agree actions directly\n- `types.ts` has `consensus` state in GameState  \n- `actions.ts` has `executeAgreement()` and **validates consensus** in executors\n- `url-compression.ts` includes agree actions in URLs\n- Every AI strategy has hardcoded consensus prioritization\n\n**The coupling problem**: Executors validate `consensus.completeTrick.size !== 4`, so you can't run `complete-trick` without first running 4 agree actions. This means:\n- URLs must include agree actions for replay to work\n- AI/simulations must process meaningless agree actions\n- Tests must handle consensus loops\n\n## Solution: Extract to Optional Layer\n\n**Key insight**: Consensus is PACING, not GAME LOGIC. Agree actions don't affect game outcome - they just gate when `complete-trick` becomes available.\n\n### Architecture Changes\n\n1. **Remove consensus validation from executors** (`actions.ts`)\n   - `executeCompleteTrick`: Remove lines 314-318 (consensus check)\n   - `executeScoreHand`: Remove lines 393-396 (consensus check)\n   - These become pure game logic\n\n2. **Remove `consensus` from GameState** (`types.ts`, `state.ts`)\n   - No more `consensus.completeTrick` and `consensus.scoreHand` Sets\n   - No more `executeAgreement()` function\n\n3. **Create `consensus` layer** that:\n   - Intercepts `complete-trick`/`score-hand` from base layer\n   - Derives acknowledgments from `state.actionHistory`\n   - Gates the action until all players have agreed\n\n4. **URLs become cleaner**\n   - Agree actions are **ephemeral** - exist in live sessions, not persisted to URLs\n   - Old URLs with agree actions → filtered during decompression (backward compat)\n   - New URLs → just meaningful actions\n\n### Layer Composition\n\n```typescript\n// AI/simulations/URL replay - no consensus layer\nlayers: ['speed']  // complete-trick executes immediately\n\n// Real multiplayer games - with consensus layer  \nlayers: ['consensus', 'speed']  // UI pacing via agree actions\n```\n\n## Benefits\n\n- **Pure game logic**: Executors don't care about consensus\n- **Clean URLs**: No pacing actions in event-sourced history\n- **Simple AI**: No hardcoded consensus handling (won't see agree actions)\n- **Simple tests**: No consensus loops needed\n- **Same UI**: Real games still have \"tap to continue\"\n\n## Files Affected\n\n### New\n- `src/game/layers/consensus.ts` - The layer (derives acks from actionHistory)\n- `src/tests/layers/consensus.test.ts` - Layer tests\n\n### Modify (REMOVE consensus)\n- `src/game/types.ts` - Remove `consensus` from GameState\n- `src/game/core/state.ts` - Remove `consensus` initialization  \n- `src/game/core/actions.ts` - Remove `executeAgreement()`, remove consensus validation\n- `src/game/layers/base.ts` - Remove agree generation\n- `src/game/core/url-compression.ts` - Filter agree actions from old URLs\n- `src/game/ai/*.ts` - Remove consensus handling\n\n### Simplify\n- `src/tests/helpers/consensusHelpers.ts` - DELETE\n- `src/tests/layers/integration/*.ts` - No consensus loops","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-26T23:10:02.605161526-06:00","updated_at":"2025-12-20T22:18:59.752133426-06:00","closed_at":"2025-11-27T10:32:28.584059017-06:00"}
{"id":"t42-109","title":"Investigate 5 base-full-hand.test.ts failures - tests likely written before early termination","description":"Tests failing:\n1. should complete a successful 30-point bid with all 7 tricks - ends at trick 5\n2. should complete a successful marks bid (2 marks) - ends at trick 3  \n3. should end early when bidding team reaches their bid - only has 12 points, expected 30+\n4. should end early when defending team scores any points in a marks bid - defending team has 0 points\n5. should play all 7 tricks when outcome is not determined early - ends at trick 5\n\nRoot cause: Tests were written before early termination logic was implemented. The early termination logic is CORRECT - games should end when outcome is mathematically determined. Tests need to be updated with correct expectations or test data adjusted to prevent early termination.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-17T16:40:08.253111211-06:00","updated_at":"2025-12-20T22:18:59.702135157-06:00","closed_at":"2025-11-17T17:06:20.506375864-06:00"}
{"id":"t42-17cc","title":"Remove redundant nello layer overrides","description":"Use texas-42 skill.\n\nThe table system with `absorptionId=7` already handles nello's absorption pattern correctly. Four overrides in nello.ts duplicate this logic and can be removed.\n\n## Overrides to Remove\n\n| Override | Lines | Why Redundant |\n|----------|-------|---------------|\n| `getLedSuit` | 104-108 | `EFFECTIVE_SUIT[d][7]` returns suit 7 for doubles |\n| `suitsWithTrump` | 111-120 | `SUIT_MASK[7]` correctly handles doubles → [7], non-doubles → [hi, lo] |\n| `canFollow` | 123-140 | `canFollowFromTable(d, 7, led)` produces identical results |\n| `getValidPlays` | 144-169 | Uses custom canFollow logic; base `getValidPlaysBase` will work |\n\n## Root Cause\n\n`getAbsorptionId(nello) = 7` - the tables already handle nello's absorption pattern.\n\nThe comment at line 171-174 already recognizes this for `rankInTrick`:\n\u003e \"Base implementation checks absorptionId === 7, which covers nello. No override needed.\"\n\nSame applies to all four overrides above.\n\n## Implementation\n\n1. Delete the 4 redundant rule overrides from `src/game/layers/nello.ts`\n2. Keep: `isValidTrump`, `calculateScore`, `getNextPlayer`, `isTrickComplete`, `checkHandOutcome`, `rankInTrick` (passthrough)\n3. Run `npm run test:all` - tests should pass unchanged","acceptance_criteria":"- [ ] getLedSuit override removed from nello.ts\n- [ ] suitsWithTrump override removed from nello.ts\n- [ ] canFollow override removed from nello.ts\n- [ ] getValidPlays override removed from nello.ts\n- [ ] npm run test:all passes","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-26T19:11:12.79991028-06:00","updated_at":"2025-12-26T19:14:02.391225633-06:00","closed_at":"2025-12-26T19:14:02.391225633-06:00","close_reason":"Removed 4 redundant overrides (~65 lines). Tables handle nello via absorptionId=7."}
{"id":"t42-19k","title":"Build Oracle Test harness to evaluate hand sampling strategies","description":"## Goal\n\nBuild a test harness to empirically measure which hand sampling strategy best predicts the true hidden hands during gameplay.\n\n## Background\n\nDifferent sampling strategies have different biases:\n- **Uniform (rejection)**: Each valid assignment equally likely, but not same as P(assignment | original random deal)\n- **Greedy (min-slack first)**: Biases toward constrained players having contested dominoes\n- **Weighted (by candidate set size)**: Larger candidate set = more likely to have any given domino\n- **Bayesian ideal**: Weight by \"how many original deals map to this assignment\"\n\nWe don't know which is best for AI decision quality. Need empirical data.\n\n## Oracle Test Design\n\n```typescript\nasync function oracleTest(samplerFn, trials = 10000) {\n  for each trial:\n    1. Create game with known seed (true hands known)\n    2. Play to trick 3-6 with AI\n    3. Build constraints from player 0's perspective\n    4. Generate 100 samples with the sampler\n    5. For each unplayed domino:\n       - Compute sampler's P(player X has domino)\n       - Compare to true owner\n       - Score prediction accuracy\n  \n  Return accuracy metrics\n}\n```\n\n## Metrics to Capture\n\n- **Overall accuracy**: % correct \"who has domino X\" predictions\n- **By trick depth**: Accuracy at tricks 3, 4, 5, 6\n- **By domino type**: Count dominoes (5-5, 6-4, etc.) vs others\n- **Calibration**: When sampler says 60% P2, is it right 60% of time?\n\n## Samplers to Test\n\n1. Current rejection sampling (baseline)\n2. Dynamic greedy (min-slack first) \n3. Weighted by candidate set size\n4. Hybrid (rejection with greedy fallback)\n\n## Output\n\nScript that prints comparison table:\n```\nSampler          | Accuracy | Trick3 | Trick6 | Count Dominoes\n-----------------+----------+--------+--------+---------------\nRejection        | 67.2%    | 71.1%  | 62.3%  | 65.8%\nGreedy           | 64.1%    | 68.2%  | 59.0%  | 61.2%\nWeighted         | 69.8%    | 72.4%  | 66.1%  | 70.2%\n```\n\n## Files\n\n- `scripts/sampler-oracle-test.ts` - Main test harness\n- Uses existing: `createInitialState`, `simulateGame`, `buildConstraints`, `sampleOpponentHands`","acceptance_criteria":"- Oracle test harness runs and produces comparison metrics\n- At least 4 sampling strategies compared\n- Results broken down by trick depth and domino type\n- Clear winner identified (or trade-offs documented)","notes":"## Oracle Test Results - FINAL\n\n### Test Parameters\n- 1000 trials × 5000 samples = 5 million total samples\n- Runtime: ~2.5 minutes\n- Total predictions: 5,115\n\n### Results\n\n| Sampler | Accuracy | vs Random (33.3%) |\n|---------|----------|-------------------|\n| **Greedy** | **38.7%** | **+5.4%** |\n| Rejection | 38.6% | +5.3% |\n| Hybrid | 37.4% | +4.1% |\n| Weighted | 32.4% | -0.9% |\n\n### Convergence Verified\n\n| Samples | Rejection | Greedy |\n|---------|-----------|--------|\n| 100 | 37.4% | 37.4% |\n| 500 | 37.9% | 37.4% |\n| 5000 | 38.6% | 38.7% |\n\nResults are stable - we've converged.\n\n### Constraint Information by Trick\n\n| Trick | Players w/ Voids | Avg Candidates | Accuracy |\n|-------|------------------|----------------|----------|\n| 1 | 8.9% | 17.7 | ~36% |\n| 6 | 79.3% | 2.7 | ~44% |\n\nThe ~38% ceiling is the actual information content of constraints, not a sampling artifact.\n\n### Recommendation\n\n**Use Dynamic Greedy** for mk5-tailwind-6b1:\n- Tied for best accuracy with Rejection\n- Deterministic O(n) complexity vs O(∞) worst case\n- Already implemented and tested in oracle script\n\n### Script Location\n`scripts/sampler-oracle-test.ts`\n\nUsage: `npx tsx scripts/sampler-oracle-test.ts [trials] [samplesPerTrial]`","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-27T09:36:53.030137253-06:00","updated_at":"2025-12-20T22:18:59.747936394-06:00","closed_at":"2025-11-27T10:02:06.295602397-06:00"}
{"id":"t42-1a6e","title":"GPU solver cross-validation 1-point discrepancy","description":"Use texas-42 skill. Python solver gives team0=1 point for seed=100 decl=0, but TypeScript minimax gives team0=0. 95 unit tests pass. Need to trace through both systems to find the subtle bug.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-27T13:08:20.654934345-06:00","updated_at":"2025-12-27T15:34:44.044156699-06:00","closed_at":"2025-12-27T15:34:44.044156699-06:00","close_reason":"Fixed: withNoBid() method added to StateBuilder to disable bid-based early termination. TypeScript minimax now plays all 7 tricks like Python solver."}
{"id":"t42-1gv","title":"Documentation","description":"Comprehensive documentation for developers and client implementers.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-11-28T10:14:25.513940208-06:00","updated_at":"2025-12-20T22:18:59.741937713-06:00","closed_at":"2025-11-28T10:21:24.419331616-06:00"}
{"id":"t42-1ol2","title":"Apply benchmark findings: 1M chunks + fused masked_fill","description":"Use texas-42 skill.\n\n## Findings from benchmark.py\n\nRan synthetic benchmarks simulating 85M states with 14M at level 5.\n\n### Chunk Size Results\n- 1M chunks: 2920 MB peak, 113 M/s throughput ← BEST\n- 2M chunks (current): 3139 MB, 45 M/s\n- Smaller chunks = less memory AND faster (better cache locality)\n\n### Optimization Results\n- baseline: 3786 MB\n- fused masked_fill: 3100 MB (saves ~700 MB)\n\n## Changes to solve.py\n\n1. Change SOLVE_CHUNK_SIZE from 2_000_000 to 1_000_000\n2. Replace cv_for_max/cv_for_min with masked_fill:\n   ```python\n   # Before\n   cv_for_max = torch.where(legal, cv16, -128)\n   cv_for_min = torch.where(legal, cv16, 127)\n   \n   # After\n   illegal = ~legal\n   max_val = cv16.masked_fill(illegal, -128).max(dim=1).values\n   min_val = cv16.masked_fill(illegal, 127).min(dim=1).values\n   ```\n\n## Testing Protocol\n\n**USE SHORT TIMEOUTS** - 15s max. Better to fail fast and iterate than wait 3+ minutes on a blank screen. The benchmark already validated these changes work.","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-27T17:17:18.339785187-06:00","updated_at":"2025-12-27T17:17:18.339785187-06:00"}
{"id":"t42-1v4","title":"Update handOutcome.ts helper function","description":"Update src/game/core/handOutcome.ts: Change checkStandardHandOutcome to return discriminated union. Replace { isDetermined: false } with { determined: false }. Depends on mk5-tailwind-2gg.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-16T16:54:40.404610333-06:00","updated_at":"2025-12-20T22:18:59.669942051-06:00","closed_at":"2025-11-16T17:13:10.721028479-06:00"}
{"id":"t42-1vw","title":"Fix URL state serialization to include dealOverrides.initialHands","description":"The URL replay system is currently broken due to ongoing migrations. When we fix it, we need to ensure that config.dealOverrides.initialHands is properly serialized to URL state.\n\nKey points:\n- initialHands are deterministic and valid for URL sharing\n- Use cases: teaching scenarios, bug reproduction, challenges, shared puzzle deals\n- Must validate on deserialization (28 unique dominoes, 7 per player)\n- Should roundtrip perfectly (save → URL → load → same hands)\n- Both seed AND initialHands can coexist (initialHands for deal, seed for AI/other randomness)\n\nContext: Issue 5pm revealed that test initialHands were being silently ignored because they weren't wired through createInitialState. We're implementing dealOverrides.initialHands support, but URL serialization is blocked on the broader URL migration work.\n\nRelated: mk5-tailwind-5pm (nello test failures)","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-11-18T10:03:07.63696352-06:00","updated_at":"2025-12-20T22:18:59.787823128-06:00","closed_at":"2025-11-25T19:22:30.26532866-06:00","comments":[{"id":2,"issue_id":"t42-1vw","author":"jason","text":"Phase 19 completed: config.enabledRuleSets renamed to config.enabledLayers throughout codebase. URL compression/decompression updated - no changes needed for dealOverrides.initialHands work. The URL param 'rs' still maps to enabledLayers internally (backward compatible until we decide to change it).","created_at":"2025-11-24T20:48:48Z"}]}
{"id":"t42-20ue","title":"Remove suitAnalysis cache from state","description":"Eliminate suitAnalysis from GameState/player objects. Compute suit analysis on demand where needed (server/AI), not stored on serialized state. Update cloning/setup/deal/play flows and filtered views accordingly.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T11:03:52.791388429-06:00","updated_at":"2025-12-21T12:09:14.602134185-06:00","closed_at":"2025-12-21T12:09:14.602134185-06:00","close_reason":"Closed","dependencies":[{"issue_id":"t42-20ue","depends_on_id":"t42-g4y","type":"discovered-from","created_at":"2025-12-21T11:03:52.794854927-06:00","created_by":"jason"},{"issue_id":"t42-20ue","depends_on_id":"t42-3xp7","type":"blocks","created_at":"2025-12-21T11:13:53.64600516-06:00","created_by":"jason"}]}
{"id":"t42-21ze","title":"Codebase review: redundancy/unification sweep (non-tests)","description":"Use texas-42 skill.\\n\\nReview non-test code for redundancies, unclear implementations, duplicated logic, and deviations from CLAUDE.md ideals. Track concrete cleanup items as child issues discovered-from this epic, and produce review docs in history/.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-27T00:29:24.342301981-06:00","updated_at":"2025-12-27T00:29:24.342301981-06:00"}
{"id":"t42-230","title":"Run full test suite and verify HandOutcome refactor","description":"Run npm test, verify all 36+ checkHandOutcome test failures resolved, zero TypeScript errors, all tests passing. Depends on all previous tasks.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-16T16:55:22.122964227-06:00","updated_at":"2025-12-20T22:18:59.665879321-06:00","closed_at":"2025-11-16T17:13:10.725027683-06:00"}
{"id":"t42-23x","title":"Phase 8: Update all imports","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.31609879-06:00","updated_at":"2025-12-20T22:18:59.774737218-06:00","closed_at":"2025-11-24T13:30:10.133374807-06:00","dependencies":[{"issue_id":"t42-23x","depends_on_id":"t42-dt2","type":"blocks","created_at":"2025-11-24T10:35:48.668468136-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-23x","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:53.024178529-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-2az","title":"Add code coverage and consolidate non-layer Vitest tests","description":"## Goals\n\n1. **Add code coverage reporting** to Vitest configuration\n2. **Research and consolidate** non-layer unit tests (similar to mk5-tailwind-fls/fka for layers)\n\n## Coverage Setup\n\n- Add `@vitest/coverage-v8` or `@vitest/coverage-istanbul`\n- Configure coverage thresholds\n- Generate HTML reports for local review\n- Identify gaps in test coverage\n\n## Test Consolidation\n\nAudit non-layer tests in `src/tests/` to find:\n- Redundant tests covering the same behavior\n- Tests that could be parameterized\n- Overly verbose test files relative to implementation size\n- Tests that don't provide value\n\nTarget similar ~1:1 code/test ratio as the layers consolidation effort.\n\n## Files to Audit\n\n- `src/tests/unit/` (non-layer tests)\n- `src/tests/integration/` (non-layer tests)\n- Any other Vitest test directories\n\n## Related\n\n- mk5-tailwind-fls: Research and consolidate layers tests\n- mk5-tailwind-fka: Consolidate layers tests with TestLayer isolation pattern","acceptance_criteria":"- Vitest coverage configured and reporting\n- Coverage report generated showing current state\n- Non-layer tests audited with consolidation recommendations\n- Test suite reduced where appropriate while maintaining coverage\n- No regression in meaningful test coverage","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-11-27T00:05:34.722120544-06:00","updated_at":"2025-12-20T22:18:59.749811931-06:00","closed_at":"2025-11-27T01:08:53.249448947-06:00"}
{"id":"t42-2gg","title":"Update HandOutcome type definition to discriminated union","description":"Change src/game/rulesets/types.ts: Replace HandOutcome interface with discriminated union. Update GameRules.checkHandOutcome return type from 'HandOutcome | null' to 'HandOutcome'. BLOCKS ALL OTHER TASKS.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-16T16:54:32.307129366-06:00","updated_at":"2025-12-20T22:18:59.670833818-06:00","closed_at":"2025-11-16T17:13:10.720108786-06:00"}
{"id":"t42-2m0","title":"Define error types as discriminated unions","description":"Use texas-42 skill.\n\nString-typed errors throughout the codebase make error handling ad-hoc and untestable.\n\nFiles: src/multiplayer/authorization.ts, src/game/core/actions.ts","design":"## EWD Memo: On the Pernicious Nature of String Errors\n\n**Date**: 2025-11-29  \n**Subject**: A Plea for Type-Safe Error Handling  \n**Author**: In the spirit of E.W. Dijkstra\n\n### The Problem\n\nIn the current codebase, errors are represented as raw strings—unstructured, untestable, and fundamentally hostile to correctness. This is not a minor aesthetic concern; it is a violation of the most basic principle of engineering: **make invalid states unrepresentable**.\n\nString errors admit several categories of failure:\n1. **No exhaustive handling**: The compiler cannot ensure all error cases are handled\n2. **No type safety**: Typos in error messages are silent failures\n3. **Ad-hoc construction**: Each site invents its own phrasing\n4. **Untestable**: Cannot distinguish error categories programmatically\n5. **Opaque to composition**: Cannot transform or enrich errors systematically\n\n### Complete Error Catalog\n\nI have conducted a thorough archaeology of the codebase. Here are ALL error strings currently in use:\n\n#### **Authorization \u0026 Capability Errors**\n```typescript\n// From: src/multiplayer/authorization.ts\n\"No player found with ID: ${playerId}\"\n\"Action is not valid in current game state: ${action.type}\"\n\"Player ${playerId} lacks capability to execute action: ${action.type}\"\n\n// From: src/kernel/kernel.ts\n\"Player ${playerIndex} not found\"\n\n// From: src/server/Room.ts\n\"Room has been destroyed\"\n\"Not associated with a player. Send JOIN first.\"\n\"Action execution failed\"\n\"Invalid player index. Must be 0-3.\"\n\"Unknown error\"  // Generic fallback\n```\n\n#### **Session Management Errors**\n```typescript\n// From: src/multiplayer/stateLifecycle.ts\n\"Player with ID ${playerId} already exists\"\n\"Seat ${session.playerIndex} is already occupied\"\n\"Player with ID ${playerId} not found\"\n```\n\n#### **Initialization \u0026 State Errors**\n```typescript\n// From: src/stores/gameStore.ts\n\"Game not initialized\"\n\"Current perspective cannot execute actions\"\n\"Game client not yet initialized\"\n\"No seed available to retry\"\n\n// From: src/kernel/kernel.ts (console.error, not Result)\n\"Auto-execute failed: no capable session\"\n\"Auto-execute failed\"\n\"Auto-execute limit reached\"\n\n// From: src/kernel/kernel.ts (throw, not Result)\n\"buildKernelView: No session found for playerId \\\"${forPlayerId}\\\"\"\n```\n\n#### **Action Resolution Errors**\n```typescript\n// From: src/game/core/action-resolution.ts\n\"Action ID at index ${i} is undefined\"\n\"Cannot resolve action ID \\\"${targetId}\\\" at index ${i}. Phase: ${state.phase}. Available IDs: [${availableIds}]. This may indicate a URL from a different game mode or corrupted replay.\"\n\"Cannot resolve action ID \\\"${actionId}\\\". Available IDs: [${availableIds}]\"\n\n// From: src/game/utils/urlReplay.ts\n\"Action resolution failed: ${error instanceof Error ? error.message : 'Unknown error'}\"\n\"Action ${globalIndex}: Execution failed for \\\"${actionId}\\\": ${error instanceof Error ? error.message : 'Unknown error'}\"\n```\n\n#### **Test \u0026 Validation Errors** (throw, not Result)\n```typescript\n// From: src/tests/rules/scoring-validation.test.ts\n\"Distribution values cannot be undefined\"\n\"Score values cannot be undefined\"\n\n// From: src/tests/rules/doubles-treatment.test.ts\n\"No highest six found\"\n\"No highest five found\"\n\n// From: src/tests/rules/winning-trick.test.ts\n\"First play is undefined\"\n\n// From: src/tests/rules/trick-validation.test.ts\n\"TRUMP_SELECTIONS.ONES is undefined\"\n\"Hand dominoes are undefined\"\n\"Expected hand dominoes are undefined\"\n\"First play in trick is undefined\"\n\n// From: src/tests/helpers/dealConstraints.ts\n\"Internal error: Distributed ${totalDominoes} dominoes, expected 28\"\n\"Player ${player}: Has domino with forbidden suit ${suit}\"\n```\n\n#### **HeadlessRoom Errors** (throw, not Result)\n```typescript\n// From: src/server/HeadlessRoom.ts\n\"Cannot determine player for action: ${action.type}\"\n```\n\n### Pattern Analysis\n\nExamining the error catalog reveals **five fundamental categories**:\n\n1. **Authorization Failures** - Permission denied, capability missing\n2. **Not Found** - Player, session, resource doesn't exist\n3. **Invalid State** - Operation invalid in current state (destroyed room, wrong phase)\n4. **Invalid Input** - Malformed data, out-of-range values, unresolvable IDs\n5. **Internal Invariant Violation** - \"This should never happen\" errors\n\n### The Discriminated Union Design\n\n```typescript\n/**\n * Core error types for the Texas 42 game system.\n * \n * Design principles:\n * 1. Exhaustive - compiler forces handling of all cases\n * 2. Structured - errors carry typed context, not interpolated strings\n * 3. Composable - errors can be transformed and enriched\n * 4. Testable - can pattern match on error types\n */\nexport type GameError =\n  // Authorization \u0026 Capability\n  | { type: 'player-not-found'; playerId: string }\n  | { type: 'session-not-found'; playerId: string }\n  | { type: 'lacks-capability'; playerId: string; actionType: string }\n  | { type: 'not-associated-with-player' }\n  \n  // Session Management\n  | { type: 'player-already-exists'; playerId: string }\n  | { type: 'seat-occupied'; seatIndex: number }\n  | { type: 'invalid-player-index'; index: number; validRange: [number, number] }\n  \n  // State Validation\n  | { type: 'room-destroyed' }\n  | { type: 'game-not-initialized' }\n  | { type: 'no-seed-available' }\n  | { type: 'perspective-cannot-execute' }\n  | { type: 'client-not-initialized' }\n  \n  // Action Execution\n  | { type: 'action-not-valid'; actionType: string; phase: string }\n  | { type: 'action-execution-failed'; actionType: string; reason?: string }\n  | { type: 'auto-execute-limit-reached'; limit: number }\n  | { type: 'auto-execute-failed'; actionType: string; reason: string }\n  \n  // Action Resolution (URL replay)\n  | { type: 'action-id-undefined'; index: number }\n  | { type: 'action-id-unresolvable'; \n      actionId: string; \n      index: number; \n      phase: string; \n      availableIds: string[] }\n  | { type: 'action-resolution-failed'; error: string }\n  \n  // Internal Invariants\n  | { type: 'player-undeterminable'; actionType: string }\n  | { type: 'invariant-violation'; description: string };\n\n/**\n * Result type using discriminated union errors.\n */\nexport type Result\u003cT, E = GameError\u003e =\n  | { success: true; value: T }\n  | { success: false; error: E };\n\n/**\n * Helper constructors for common error cases.\n */\nexport const GameErrors = {\n  playerNotFound: (playerId: string): GameError =\u003e \n    ({ type: 'player-not-found', playerId }),\n    \n  sessionNotFound: (playerId: string): GameError =\u003e \n    ({ type: 'session-not-found', playerId }),\n    \n  lacksCapability: (playerId: string, actionType: string): GameError =\u003e \n    ({ type: 'lacks-capability', playerId, actionType }),\n    \n  playerAlreadyExists: (playerId: string): GameError =\u003e \n    ({ type: 'player-already-exists', playerId }),\n    \n  seatOccupied: (seatIndex: number): GameError =\u003e \n    ({ type: 'seat-occupied', seatIndex }),\n    \n  invalidPlayerIndex: (index: number): GameError =\u003e \n    ({ type: 'invalid-player-index', index, validRange: [0, 3] }),\n    \n  roomDestroyed: (): GameError =\u003e \n    ({ type: 'room-destroyed' }),\n    \n  actionNotValid: (actionType: string, phase: string): GameError =\u003e \n    ({ type: 'action-not-valid', actionType, phase }),\n    \n  actionIdUnresolvable: (\n    actionId: string, \n    index: number, \n    phase: string, \n    availableIds: string[]\n  ): GameError =\u003e \n    ({ type: 'action-id-unresolvable', actionId, index, phase, availableIds }),\n    \n  invariantViolation: (description: string): GameError =\u003e \n    ({ type: 'invariant-violation', description })\n};\n```\n\n### Exhaustive Error Handling\n\nWith discriminated unions, the compiler **forces** exhaustive handling:\n\n```typescript\nfunction handleError(error: GameError): string {\n  switch (error.type) {\n    case 'player-not-found':\n      return `No player found with ID: ${error.playerId}`;\n      \n    case 'session-not-found':\n      return `Session not found for player: ${error.playerId}`;\n      \n    case 'lacks-capability':\n      return `Player ${error.playerId} lacks capability to execute action: ${error.actionType}`;\n      \n    case 'player-already-exists':\n      return `Player with ID ${error.playerId} already exists`;\n      \n    case 'seat-occupied':\n      return `Seat ${error.seatIndex} is already occupied`;\n      \n    case 'invalid-player-index':\n      const [min, max] = error.validRange;\n      return `Invalid player index ${error.index}. Must be ${min}-${max}.`;\n      \n    case 'room-destroyed':\n      return 'Room has been destroyed';\n      \n    case 'game-not-initialized':\n      return 'Game not initialized';\n      \n    case 'no-seed-available':\n      return 'No seed available to retry';\n      \n    case 'perspective-cannot-execute':\n      return 'Current perspective cannot execute actions';\n      \n    case 'client-not-initialized':\n      return 'Game client not yet initialized';\n      \n    case 'not-associated-with-player':\n      return 'Not associated with a player. Send JOIN first.';\n      \n    case 'action-not-valid':\n      return `Action is not valid in current game state: ${error.actionType}`;\n      \n    case 'action-execution-failed':\n      return error.reason \n        ? `Action ${error.actionType} execution failed: ${error.reason}`\n        : 'Action execution failed';\n      \n    case 'auto-execute-limit-reached':\n      return `Auto-execute limit reached (${error.limit} iterations)`;\n      \n    case 'auto-execute-failed':\n      return `Auto-execute failed for ${error.actionType}: ${error.reason}`;\n      \n    case 'action-id-undefined':\n      return `Action ID at index ${error.index} is undefined`;\n      \n    case 'action-id-unresolvable':\n      return `Cannot resolve action ID \"${error.actionId}\" at index ${error.index}. ` +\n        `Phase: ${error.phase}. ` +\n        `Available IDs: [${error.availableIds.join(', ')}]. ` +\n        `This may indicate a URL from a different game mode or corrupted replay.`;\n      \n    case 'action-resolution-failed':\n      return `Action resolution failed: ${error.error}`;\n      \n    case 'player-undeterminable':\n      return `Cannot determine player for action: ${error.actionType}`;\n      \n    case 'invariant-violation':\n      return `Internal invariant violation: ${error.description}`;\n      \n    // TypeScript will error if we miss any case!\n  }\n}\n```\n\n### Benefits\n\n1. **Exhaustive handling**: Missing a case is a compile error\n2. **Type-safe construction**: `GameErrors.playerNotFound(id)` cannot be mistyped\n3. **Testable**: `if (error.type === 'player-not-found') { ... }`\n4. **Composable**: Can add context, transform, aggregate errors\n5. **Refactorable**: Rename error type → compiler finds all uses\n6. **Self-documenting**: Error types form a specification\n\n### Migration Strategy\n\n#### Phase 1: Introduce types (non-breaking)\n```typescript\n// Add to src/game/types/errors.ts\nexport type GameError = ...\nexport const GameErrors = ...\n\n// Update Result type in src/multiplayer/types.ts\nexport type Result\u003cT, E = GameError\u003e = \n  | { success: true; value: T }\n  | { success: false; error: E };\n```\n\n#### Phase 2: Migrate core multiplayer (breaking)\n1. Update `src/multiplayer/authorization.ts` to return `Result\u003cT, GameError\u003e`\n2. Update `src/multiplayer/stateLifecycle.ts`\n3. Update `src/kernel/kernel.ts`\n4. Update `src/server/Room.ts`\n\n#### Phase 3: Convert throws to Results (breaking)\n1. Replace `throw new Error(...)` with `return err(GameErrors.xxx)`\n2. Update HeadlessRoom to use Results\n3. Update gameStore error handling\n\n#### Phase 4: Update protocol (breaking)\n```typescript\n// From: { type: 'ERROR'; error: string }\n// To:   { type: 'ERROR'; error: GameError }\n```\n\n#### Phase 5: Update tests\n1. Replace string matching: ~~`expect(result.error).toContain('lacks capability')`~~\n2. Use type guards: `expect(result.error?.type).toBe('lacks-capability')`\n\n### Conclusion\n\nString errors are the enemy of correctness. They make invalid states representable, preclude exhaustive handling, and resist systematic reasoning. \n\nA discriminated union of error types restores order:\n- The compiler **proves** all cases are handled\n- Construction is type-safe\n- Errors carry structured, typed context\n- Testing becomes precise\n\nThis is not mere pedantry. This is **engineering discipline**. This is how we build systems we can reason about.\n\n\"Simplicity is prerequisite for reliability.\" — E.W. Dijkstra\n\n---\n\n### Files to Modify\n\n**New file:**\n- `src/game/types/errors.ts` - Error type definitions\n\n**Core changes:**\n- `src/multiplayer/types.ts` - Update Result type\n- `src/multiplayer/authorization.ts` - Use GameError\n- `src/multiplayer/stateLifecycle.ts` - Use GameError\n- `src/kernel/kernel.ts` - Use GameError, convert throws\n- `src/server/Room.ts` - Use GameError\n- `src/server/HeadlessRoom.ts` - Convert throws to Results\n- `src/stores/gameStore.ts` - Handle GameError\n- `src/game/core/action-resolution.ts` - Convert throws\n- `src/game/utils/urlReplay.ts` - Handle GameError\n\n**Protocol:**\n- `src/multiplayer/protocol.ts` - Type ERROR message\n\n**Testing impact:**\n- All test files using Result types must update assertions\n- Replace `.toContain()` string matching with `.toBe()` type matching","status":"open","priority":3,"issue_type":"chore","created_at":"2025-11-29T12:10:08.028267565-06:00","updated_at":"2025-12-20T22:18:59.802639012-06:00","dependencies":[{"issue_id":"t42-2m0","depends_on_id":"t42-8ee","type":"blocks","created_at":"2025-11-29T12:10:23.740042548-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-2m0","depends_on_id":"t42-4b9","type":"parent-child","created_at":"2025-11-29T12:10:38.041712605-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"t42-2qg","title":"RESOLVED: dominoFollowsSuit now handles suit 7 (doubles) correctly","description":"✅ FIXED in src/game/rulesets/base.ts:204-211\n\nThe bug where 0-0 beat 5-5 in nello is resolved. dominoFollowsSuit() now correctly handles suit 7 (doubles).\n\nFix: Added special case for ledSuit === 7 to check if domino is a double (high === low) instead of checking if it contains the number 7.\n\nVerification:\n- scratch/debug-with-game-logic.ts: ✅ All 7 tricks play correctly\n- scratch/verify-fix.test.ts: ✅ Unit test confirms 5-5 beats 0-0\n\nNote: nello-full-hand.test.ts still has 4 failing tests, but this is a TEST HELPER issue (mk5-tailwind-5zp), not a game logic bug.\n\nRelated: mk5-tailwind-5pm (original report), mk5-tailwind-5zp (test helper issue)","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-19T08:21:27.199387565-06:00","updated_at":"2025-12-20T22:18:59.659190582-06:00","closed_at":"2025-11-19T10:28:18.923571618-06:00","dependencies":[{"issue_id":"t42-2qg","depends_on_id":"t42-5pm","type":"blocks","created_at":"2025-11-19T08:21:27.202256181-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-2sz","title":"Profile seedFinder tests to identify actual performance bottlenecks","description":"## Context\nWe want to optimize seedFinder test performance with data-driven decisions, not just educated guesses from code inspection.\n\n## Goal\nSet up profiling tooling and run actual performance analysis to identify real bottlenecks.\n\n## Tasks\n\n### 1. Set up profiling infrastructure\n- Add npm script for profiling: `\"profile:seedfinder\": \"0x npm test -- seedFinder.test.ts\"`\n- Install 0x globally or document installation: `npm install -g 0x`\n- Alternative: Node built-in profiler script with Chrome DevTools analysis\n\n### 2. Run profiling session\n- Profile seedFinder.test.ts with full test suite\n- Generate flamegraph or CPU profile\n- Save profile artifacts to scratch/ (gitignored)\n\n### 3. Analyze results\n- Identify top 5 functions by wall-clock time\n- Verify our assumptions:\n  - Is getDominoesCanBeat/Beaten actually the bottleneck?\n  - How much time in JSON.stringify?\n  - Is composeRules() significant?\n  - What about buildActionsMap()?\n- Document findings with actual percentages\n\n### 4. Prioritize optimizations\n- Create follow-up bd issues for validated bottlenecks with data\n- Archive/deprioritize issues for things that don't show up in profile\n\n## Profiling Options\n- **Quick**: `node --cpu-prof npm test -- seedFinder.test.ts` + Chrome DevTools\n- **Recommended**: `0x npm test -- seedFinder.test.ts` (interactive flamegraph)\n- **Deep**: Clinic.js for comprehensive analysis\n\n## Output\n- Flamegraph or CPU profile saved to scratch/\n- Summary document with top bottlenecks and time percentages\n- Data-driven optimization priority list\n\n## Related\n- mk5-tailwind-vpn: Strength table integration (verify if this is actually the bottleneck)\n- mk5-tailwind-os3: JSON.stringify optimization (measure actual impact)","notes":"## Profiling Complete ✅\n\nMethod: Node.js --cpu-prof on seedFinder tests\nDuration: 29.21s wall-clock time\nProfiles: 17 worker profiles, 417,460 total CPU samples\n\n### Key Findings\n\n1. Assumptions Validated:\n   - getDominoesCanBeat/Beaten IS a bottleneck (0.46% CPU combined)\n   - buildActionsMap is moderately expensive (0.07% CPU)\n   - BUT: magnitude overestimated (only 0.46%, not 60-80%)\n\n2. Surprise: calculateSuitRanking is #4 overall (0.41% CPU)\n\n3. Garbage Collection: Highest single impact at 0.77%\n\n### Top Categories by CPU %\n1. GC: 0.77% | 2. State: 0.64% | 3. Actions: 0.59%\n4. Kernel: 0.54% | 5. AI Logic: 0.46% | 6. Suits: 0.41%\n\n### Optimization Priorities\n\nTier 1 (High Impact):\n- Strength table for getDominoes* (vpn) → 0.23% gain\n- Optimize calculateSuitRanking → 0.21% gain (NEW)\n\nTier 2 (Medium Impact):\n- Cache action maps → 0.24% gain\n- Reduce state cloning → 0.32% gain\n\nExpected: 2-5% wall-clock improvement\n\n### Artifacts\n- scratch/profiling-cpu/*.cpuprofile (17 files)\n- scratch/profiling-results/analysis.md\n- scratch/analyze-profiles.cjs\n\n### Next\n1. Create bd issue for suit analysis optimization\n2. Prioritize mk5-tailwind-vpn (strength table)\n3. Add npm profiling script","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-19T15:52:43.183366562-06:00","updated_at":"2025-12-20T22:18:59.692385801-06:00","closed_at":"2025-11-19T21:27:17.414635377-06:00"}
{"id":"t42-2vqf","title":"Benchmark PIMC tractability with random deals","description":"Use texas-42 skill.\n\n## Context\n\nThe checkHandOutcome optimization (t42-4ytq) showed surprising results: even 7 tricks remaining completed in \u003c1ms with ~40 nodes. This suggests PIMC might be tractable for Texas 42, which would be a major architectural simplification.\n\nHowever, the benchmark used fixed hand compositions. We need to verify with random deals.\n\n## Goal\n\nDetermine if PIMC is reliably tractable by testing minimax on random deals.\n\n## Design\n\n```typescript\nconst DEALS = 100;\nconst results: { time: number; nodes: number }[] = [];\n\nfor (let i = 0; i \u003c DEALS; i++) {\n  const hands = dealRandomHands(); // 7 dominoes to each of 4 players\n  const state = createStateFromHands(hands, { trump: randomTrump() });\n  \n  const start = performance.now();\n  const result = minimaxEvaluate(state, ctx);\n  const time = performance.now() - start;\n  \n  results.push({ time, nodes: result.nodesExplored });\n  \n  // Write interim results every 10 deals\n  if (i % 10 === 9) writeInterimResults(results);\n}\n\n// Report statistics\nconsole.log(`Min: ${min(times)}ms, Max: ${max(times)}ms, Avg: ${avg(times)}ms`);\nconsole.log(`Min nodes: ${min(nodes)}, Max: ${max(nodes)}, Avg: ${avg(nodes)}`);\n```\n\n## Key Questions\n\n1. **Worst case**: What's the slowest evaluation across 100 random deals?\n2. **Variance**: How much do times vary? (σ/μ)\n3. **Node distribution**: Are there outliers with 10K+ nodes?\n\n## Success Criteria\n\nPIMC is tractable if:\n- **P99 time \u003c 100ms** (99% of evals under 100ms)\n- **Max time \u003c 1 second** (no pathological cases)\n- **Avg time \u003c 20ms** (reasonable for real-time play)\n\n## Implications\n\nIf tractable:\n- Current PIMC architecture is viable for production\n- No need for heuristic cutoffs or depth limits\n- AI can search to terminal state reliably\n\nIf NOT tractable:\n- Need to identify what makes certain positions hard\n- May need iterative deepening or time-bounded search\n- Current approach needs guardrails","notes":"## Key Finding: Original Benchmark Was INCORRECT\n\nThe previous benchmark (t42-4ytq) showed minimax completing in \u003c1ms with ~40 nodes for 7 tricks. This was **false** - the minimax was returning early without actually playing out tricks.\n\n### Bug Found\nAfter 4 plays complete a trick, the consensus layer generates `agree-trick` (for human acknowledgment). With human playerTypes, this blocked `complete-trick`. Minimax saw no play actions and returned immediately with unchanged scores.\n\n### Fix Applied\nSet `playerTypes: ['ai', 'ai', 'ai', 'ai']` in the state for simulation. This makes consensus layer pass through, allowing `complete-trick` to execute and scores to update.\n\n### Actual Scaling (CORRECTED)\nWith proper trick completion:\n- 1 trick: 6 nodes, 1.4ms\n- 2 tricks: 60 nodes, 1.6ms\n- 3 tricks: 665 nodes, 8ms\n- 4 tricks: 10,942 nodes, 49ms\n- 5 tricks: 274,147 nodes, 582ms\n- 6+ tricks: extrapolated 10+ seconds\n\n### Conclusion\n**PIMC IS NOT TRACTABLE** for full 7-trick games in the current implementation. Node counts grow exponentially. \n\n### Implications\n- Need iterative deepening or time-bounded search\n- Need better pruning (transposition tables, killer moves)\n- Or: limit PIMC to late-game positions (≤4 tricks remaining)\n- Or: use heuristic evaluation instead of terminal search","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-24T10:05:29.856069763-06:00","updated_at":"2025-12-24T10:57:52.479764641-06:00","closed_at":"2025-12-24T10:57:52.479764641-06:00","close_reason":"Completed investigation. Key findings:\n\n1. **Original benchmark was incorrect** - minimax was returning early due to consensus layer blocking complete-trick\n\n2. **Actual scaling (with fix)**:\n   - 1 trick: 6 nodes, 1.4ms\n   - 2 tricks: 60 nodes, 1.6ms  \n   - 3 tricks: 665 nodes, 8ms\n   - 4 tricks: 10,942 nodes, 49ms\n   - 5 tricks: 274,147 nodes, 582ms\n\n3. **Conclusion**: PIMC is NOT tractable for full 7-trick games. Need depth limits, heuristic evaluation, or hybrid approach.","labels":["ai","benchmark","performance"]}
{"id":"t42-31j","title":"Phase 9: Update all test configs","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.319932624-06:00","updated_at":"2025-12-20T22:18:59.773949276-06:00","closed_at":"2025-11-24T13:30:16.913508193-06:00","dependencies":[{"issue_id":"t42-31j","depends_on_id":"t42-23x","type":"blocks","created_at":"2025-11-24T10:35:49.538773101-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-31j","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:53.90809289-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-349","title":"Investigate 14 integration test failures","description":"14 integration tests failing across base-full-hand.test.ts (5), early-termination-general.test.ts (8), nello-full-hand.test.ts (2), sevens-full-hand.test.ts (2). These appear unrelated to HandOutcome discriminated union refactor. Need investigation to determine root cause. Tests involve: full hand playthrough, early termination, phase transitions, winner determination.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-16T17:16:47.921333308-06:00","updated_at":"2025-12-20T22:18:59.664178062-06:00","closed_at":"2025-11-17T16:40:52.707011066-06:00","comments":[{"id":1,"issue_id":"t42-349","author":"jason","text":"INVESTIGATION COMPLETE - Root cause identified and fixed.\n\n## Root Cause\nBase ruleset's checkHandOutcome violated threading pattern by not accepting prev parameter, breaking composition chain for special contracts.\n\n## Fixes Applied\n1. ✅ base.ts checkHandOutcome - Added prev parameter, respects prev.isDetermined\n2. ✅ handOutcome.ts checkStandardHandOutcome - Skip marks logic for special trumps/bids  \n3. ✅ handOutcome.ts calculateRemainingPoints - Account for tricks in progress\n\n## Results\n- Reduced from 14 failures to 10 failures\n- Threading pattern restored\n- Special contracts (nello, splash, plunge) now compose correctly\n\n## Remaining Work (New Issues Created)\n- mk5-tailwind-109 [P1]: 5 base-full-hand.test.ts failures\n- mk5-tailwind-5pm [P1]: 2 nello-full-hand.test.ts failures\n- mk5-tailwind-r4x [P0]: 3 sevens-full-hand.test.ts failures\n\nTests were written before early termination logic existed. Early termination is CORRECT - tests need updating.","created_at":"2025-11-17T22:40:43Z"}]}
{"id":"t42-3b3","title":"MCTS bidding always passes - debug script needed","description":"Use texas-42 skill.\n\nThe MCTS player appears to always pass during bidding, causing repeated redeals and slow games. Need to investigate why the Monte Carlo bid evaluation isn't finding viable bids.\n\n## Symptoms\n- MCTS games are slow (80s+ for a full game with 100 simulations)\n- Suspected cause: all players pass → redeal → repeat\n- The bidding evaluation may have a bug in make-rate calculation\n\n## Debug script requirements\n1. Run a game with MCTS bidding\n2. Log each bid decision:\n   - Player index\n   - Hand composition\n   - Evaluated bids with their make rates\n   - Threshold (currently 0.50)\n   - Final decision (bid or pass)\n3. Count redeals vs actual hands played\n4. Identify why make rates are below threshold\n\n## Relevant code\n- `src/game/ai/strategies.ts`: `makeBidDecision()` - BID_THRESHOLD = 0.50\n- `src/game/ai/monte-carlo.ts`: `evaluateBidActions()` - simulates bid outcomes\n- `src/game/ai/hand-strength.ts`: `determineBestTrump()` - trump selection for simulation","notes":"## Root Cause Found \u0026 Fixed\n\n### The Real Bug: Consensus Layer Breaking Simulations\n\nIn `monte-carlo.ts`, the `createPlayReadyState()` function was copying `playerTypes` from the original game state. When playing with human players (`['human', 'ai', 'ai', 'ai']`), the Monte Carlo simulation would inherit this, causing the **consensus layer** to generate `agree-trick` actions instead of auto-executing `complete-trick`.\n\nThis made ALL simulations get stuck after the first trick with 0 points, causing 0% make rates for ALL bids.\n\n**Fix**: Override `playerTypes` to `['ai', 'ai', 'ai', 'ai']` in the simulated state so consensus layer auto-executes.\n\n### Additional Fix: Trump Selection\n\nAlso fixed `determineBestTrump()` to give +2 bonus for having the double (highest card) in a suit.\n\n### Files Changed\n\n1. `src/game/ai/monte-carlo.ts:229` - Added `playerTypes: ['ai', 'ai', 'ai', 'ai']` to createPlayReadyState\n2. `src/game/ai/hand-strength.ts` - Rewrote trump selection to value doubles\n\n### Verification\n\n- All 970 unit tests pass\n- All 20 e2e tests pass  \n- Bid evaluations now return realistic make rates (30-50%) instead of 0%","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-02T22:40:48.814911015-06:00","updated_at":"2025-12-20T22:18:59.722540846-06:00","closed_at":"2025-12-02T23:17:28.517743376-06:00","labels":["ai","debug","mcts"]}
{"id":"t42-3bq","title":"Phase 19 (OPTIONAL): Rename config property","description":"**Title**: Phase 19 (Optional): Rename config.enabledRuleSets to config.enabledLayers","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T13:51:33.091175565-06:00","updated_at":"2025-12-20T22:18:59.765132414-06:00","closed_at":"2025-11-24T14:49:05.984202251-06:00","dependencies":[{"issue_id":"t42-3bq","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T13:52:07.976539959-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-3bq","depends_on_id":"t42-48w","type":"blocks","created_at":"2025-11-24T13:52:17.591289697-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-3jb","title":"Phase 13: Full test suite verification","description":"**Type**: task","acceptance_criteria":"npm run test:all passes AND all manual tests verified","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.336473271-06:00","updated_at":"2025-12-20T22:18:59.770688894-06:00","closed_at":"2025-11-24T13:56:23.660351071-06:00","dependencies":[{"issue_id":"t42-3jb","depends_on_id":"t42-3yw","type":"blocks","created_at":"2025-11-24T10:35:52.954939963-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-3jb","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:57.247858597-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-3xl","title":"Unify composition patterns in compose.ts","description":"Use texas-42 skill.\n\nThe file uses both explicit loops and reduce for identical operations. Pick one canonical form.\n\nFiles: src/game/layers/compose.ts","design":"## The Inconsistency: Two Patterns for One Operation\n\n*\"Which is the canonical form?\" — The question Dijkstra would ask*\n\n### I. THE CRIME SCENE\n\n**File:** `src/game/layers/compose.ts`\n**Evidence:** Two distinct patterns for the identical reduction operation\n\n### Pattern A: Explicit For-Loops (Lines 198-282)\n\nUsed by 7 methods:\n- `getTrumpSelector` (lines 198-208)\n- `getFirstLeader` (lines 210-220)\n- `getNextPlayer` (lines 222-232)\n- `isTrickComplete` (lines 234-244)\n- `checkHandOutcome` (lines 246-256)\n- `getLedSuit` (lines 258-268)\n- `calculateTrickWinner` (lines 270-282)\n\n```typescript\ngetTrumpSelector: (state, bid) =\u003e {\n  let result = bid.player;\n  for (const layer of layers) {\n    if (layer.rules?.getTrumpSelector) {\n      result = layer.rules.getTrumpSelector(state, bid, result);\n    }\n  }\n  return result;\n}\n```\n\n**Characteristics:**\n- Mutable `let result`\n- Explicit iteration\n- 9 lines per method\n\n### Pattern B: Functional Reduce (Lines 288-335)\n\nUsed by 7 methods:\n- `isValidPlay` (lines 288-293)\n- `getValidPlays` (lines 295-300)\n- `isValidBid` (lines 302-307)\n- `getBidComparisonValue` (lines 309-314)\n- `isValidTrump` (lines 316-321)\n- `calculateScore` (lines 323-328)\n- `getPhaseAfterHandComplete` (lines 330-335)\n\n```typescript\nisValidPlay: (state, domino, playerId) =\u003e\n  layers.reduce(\n    (prev, layer) =\u003e\n      layer.rules?.isValidPlay?.(state, domino, playerId, prev) ?? prev,\n    isValidPlayBase(state, domino, playerId)\n  )\n```\n\n**Characteristics:**\n- Immutable accumulation\n- Declarative transformation\n- 5 lines per method\n\n### II. MATHEMATICAL PROOF OF EQUIVALENCE\n\nBoth patterns implement:\n```\nresult = f_n(f_{n-1}(...f_2(f_1(base))...))\n```\n\nThe for-loop is the **imperative** form.\nThe reduce is the **functional** form.\n\nThey are **semantically identical**.\n\n### III. ARCHAEOLOGICAL EVIDENCE\n\n1. **File header (line 2):** \"Rule composition **via reduce pattern**\"\n2. **Comment at line 284:** Marks \"VALIDATION RULES\" - where reduce begins\n3. **Hypothesis:** Validation section was refactored to reduce; the other 7 were forgotten\n\n**There is NO technical justification for the split.**\n\n### IV. THE CANONICAL FORM: REDUCE\n\n**REDUCE must be universal** because:\n\n1. **Declared intent**: File header promises reduce pattern\n2. **Functional purity**: No `let`, no mutation - aligns with \"pure functional architecture\"\n3. **Concision**: 4 fewer lines per method\n4. **Pattern recognition**: Developers immediately recognize the fold operation\n5. **Majority rule**: Already used in 7/14 methods (plus file declaration)\n\n### V. TRANSFORMATION TEMPLATE\n\n**Before (for-loop):**\n```typescript\ngetNextPlayer: (state, current) =\u003e {\n  let result = getNextPlayerCore(current);\n\n  for (const layer of layers) {\n    if (layer.rules?.getNextPlayer) {\n      result = layer.rules.getNextPlayer(state, current, result);\n    }\n  }\n\n  return result;\n}\n```\n\n**After (reduce):**\n```typescript\ngetNextPlayer: (state, current) =\u003e\n  layers.reduce(\n    (prev, layer) =\u003e\n      layer.rules?.getNextPlayer?.(state, current, prev) ?? prev,\n    getNextPlayerCore(current)\n  )\n```\n\n### VI. THE 7 METHODS TO TRANSFORM\n\n1. `getTrumpSelector` (lines 198-208)\n2. `getFirstLeader` (lines 210-220)\n3. `getNextPlayer` (lines 222-232)\n4. `isTrickComplete` (lines 234-244)\n5. `checkHandOutcome` (lines 246-256)\n6. `getLedSuit` (lines 258-268)\n7. `calculateTrickWinner` (lines 270-282)\n\nAlso: `applyLayerActions` (lines 347-361) uses a for-loop\n\n### VII. IMPACT\n\n- **Lines removed:** ~28 lines\n- **Risk:** LOW (semantic equivalence proven)\n- **Cognitive load:** REDUCED (single pattern to learn)\n- **File coherence:** RESTORED (matches header declaration)\n\n### VIII. ACCEPTANCE CRITERIA\n\n1. All 14 rule methods use `layers.reduce()` pattern\n2. `applyLayerActions` helper uses reduce\n3. All tests pass unchanged\n4. No behavioral changes (pure refactoring)","status":"open","priority":3,"issue_type":"chore","created_at":"2025-11-29T12:10:05.927985601-06:00","updated_at":"2025-12-20T22:18:59.807432946-06:00","dependencies":[{"issue_id":"t42-3xl","depends_on_id":"t42-8ee","type":"blocks","created_at":"2025-11-29T12:10:23.36769872-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-3xl","depends_on_id":"t42-4b9","type":"parent-child","created_at":"2025-11-29T12:10:37.661438759-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"t42-3xp7","title":"Server-owned projection; dumb client","description":"Build the authoritative view projection in kernel/buildKernelView using ExecutionContext.rules + filtered state. Remove or neutralize client-side rule logic (view-projection helpers, trump/follow checks). Client consumes serialized derived fields only; no local rule evaluation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T11:03:49.917619001-06:00","updated_at":"2025-12-21T11:59:38.695986951-06:00","closed_at":"2025-12-21T11:59:38.695986951-06:00","close_reason":"implemented","dependencies":[{"issue_id":"t42-3xp7","depends_on_id":"t42-g4y","type":"discovered-from","created_at":"2025-12-21T11:03:49.921555505-06:00","created_by":"jason"},{"issue_id":"t42-3xp7","depends_on_id":"t42-mtq","type":"blocks","created_at":"2025-12-21T11:13:53.452552263-06:00","created_by":"jason"}]}
{"id":"t42-3xyt","title":"Implement DP solver and fixed-seed perfect-play AI","description":"Use texas-42 skill.\n\nImplement the table-driven DP solver from `docs/SOLVER_REFINED.md` and integrate it as a fixed-seed AI strategy for testing purposes.\n\n## Goal\n\nCreate a perfect-play AI that, given a known deal (seed) and trump selection, can compute and execute optimal moves. This enables:\n- Testing that the game engine handles optimal play correctly\n- Benchmarking other AI strategies against perfect play\n- Generating training data for ML approaches\n- Debugging specific game states with known-optimal moves\n\n## Implementation Scope\n\n### Phase 1: Core Solver (`src/solver/`)\n\n1. **Global tables** (`src/solver/tables.ts`)\n   - Build `TAU[declId][ledSuit][dominoId]` table (2,240 bytes)\n   - Use existing `EFFECTIVE_SUIT`, `SUIT_MASK`, `HAS_POWER` from `domino-tables.ts`\n   - Add `POINTS[dominoId]` table (28 bytes)\n\n2. **Per-seed setup** (`src/solver/setup.ts`)\n   - `setupSeed(hands, trump, bidderId?)` → `SeedContext`\n   - Build local-to-global mapping `L[player][localIdx]`\n   - Build `FOLLOW_LOCAL[player][ledSuit]` (7-bit masks)\n   - Build `TRICK_WINNER` and `TRICK_POINTS` tables (9,604 entries each)\n   - Handle nello partner skipping via `bidderId`\n\n3. **Solver** (`src/solver/solve.ts`)\n   - `SolverState` interface with `remaining`, `team0Points`, `leader`, etc.\n   - `packState()` → bigint for Map keys\n   - `legalMoves()`, `applyMove()` using precomputed tables\n   - `solve(hands, trump, firstLeader, bidderId?)` → `SolvedSeed`\n   - Recursive `dp()` with memoization\n\n4. **Query API** (`src/solver/query.ts`)\n   - `getOptimal(seed, state)` → best local index\n   - `getAllValues(seed, state, ctx)` → all move values\n   - `regret(seed, state, move, ctx)` → suboptimality measure\n\n### Phase 2: AI Strategy Integration\n\n1. **SolverAIStrategy** (`src/game/ai/solver-strategy.ts`)\n   - Implements `AIStrategy` interface\n   - On first call for a hand: run `solve()` to get `SolvedSeed`\n   - On subsequent calls: lookup optimal move from `SolvedSeed.Move`\n   - Convert between `GameState`/`Domino` and solver's local indices\n\n2. **Fixed-seed wrapper** for testing\n   - `createSolverAI(seed: number)` that uses deterministic deals\n   - Integrate with existing AI spawning in `Room.ts`\n\n### Phase 3: Testing Hooks\n\n1. **HeadlessRoom integration**\n   - Add option to use SolverAI for specific players\n   - Enable running solver vs solver games\n\n2. **Test utilities**\n   - `runPerfectGame(seed)` → play out with all solver AIs\n   - `analyzeGame(seed)` → get regret at each decision point\n   - Compare Monte Carlo AI decisions against perfect play\n\n## Key Files to Reference\n\n- `docs/SOLVER_REFINED.md` - Complete spec with TypeScript\n- `src/game/core/domino-tables.ts` - Existing global tables\n- `src/game/layers/rules-base.ts` - `rankInTrickWithConfig()`\n- `src/game/ai/monte-carlo.ts` - Existing AI strategy pattern\n- `src/server/HeadlessRoom.ts` - For testing integration\n\n## Acceptance Criteria\n\n- [ ] `solve()` correctly computes optimal value for test seeds\n- [ ] SolverAI plays optimally (verified against manual analysis of simple positions)\n- [ ] Can run HeadlessRoom game with 4 solver AIs\n- [ ] Solver handles nello (3-player tricks, partner skip)\n- [ ] Performance: solve one seed in \u003c 5 seconds\n- [ ] Memory: \u003c 10 MB per seed during solve","design":"## Architecture\n\n```\nsrc/solver/\n├── tables.ts      # Global TAU + POINTS tables\n├── types.ts       # SolverState, SeedContext, SolvedSeed\n├── setup.ts       # setupSeed() - per-seed precomputation\n├── solve.ts       # dp() backward induction\n└── query.ts       # getOptimal(), getAllValues(), regret()\n\nsrc/game/ai/\n└── solver-strategy.ts  # AIStrategy wrapper\n```\n\n## State Flow\n\n```\nGameState (from Room)\n    ↓ extract hands, trump, leader\nSeedContext (precomputed tables)\n    ↓ solve()\nSolvedSeed (V, Move maps)\n    ↓ query on each turn\nLocalIndex → Domino → GameAction\n```\n\n## Key Design Decisions\n\n1. **Local indices**: Solver uses 0-6 per player, not global domino IDs\n2. **Bigint keys**: Pack state to 64-bit for efficient Map storage\n3. **One-shot solve**: Compute entire game tree on first call, then lookup\n4. **No caching across hands**: Each hand is independent seed\n\n## Integration Points\n\n- `AIStrategy.selectAction(view)` calls `getOptimal()` after first-time `solve()`\n- `HeadlessRoom.executeAction()` unchanged - solver returns normal `GameAction`\n- Test harness creates room with `aiStrategy: 'solver'` config","acceptance_criteria":"- [ ] Unit tests for `setupSeed()` table construction\n- [ ] Unit tests for `solve()` on known-outcome positions\n- [ ] Integration test: solver AI plays complete hand\n- [ ] Integration test: 4 solver AIs play to completion\n- [ ] Nello support: 3-player tricks with partner skip\n- [ ] Performance: \u003c 5s per seed on standard hardware\n- [ ] Memory: peak \u003c 10 MB during solve\n- [ ] Regret analysis: can compute regret for any move","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-27T00:29:25.319430909-06:00","updated_at":"2025-12-27T00:29:25.319430909-06:00"}
{"id":"t42-3yf","title":"doesDominoFollowSuit is misleading - doesn't account for trump exclusion","description":"## Problem\n\nThe function `doesDominoFollowSuit` in `src/game/core/dominoes.ts:234-253` has a misleading name. It suggests it answers \"can this domino follow this suit?\" but actually just checks \"does this domino contain this suit?\"\n\nThe actual game rule (trump dominoes cannot follow non-trump suits) is implemented separately in `getValidPlaysBase` in `compose.ts`.\n\n## Example\n\nWith 4s as trump and 0s led:\n- `doesDominoFollowSuit({ high: 4, low: 0 }, 0, trump)` returns **TRUE**\n- But 4-0 is trump and **cannot** be used to follow 0s in actual gameplay\n\n## Impact\n\nThis caused a significant bug in the Intermediate AI's constraint tracker. We had to create a separate `canFollowSuitForConstraints` function that mirrors the actual game logic.\n\n## Suggested Fix\n\nEither:\n1. Rename `doesDominoFollowSuit` to `dominoContainsSuit` to be more accurate\n2. Or update it to take trump exclusion into account (matching `getValidPlaysBase` behavior)\n\nOption 2 would require auditing all call sites to ensure they expect the new behavior.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-25T21:11:56.179437847-06:00","updated_at":"2025-12-20T22:18:59.754645671-06:00","closed_at":"2025-11-26T23:05:13.278014171-06:00"}
{"id":"t42-3yw","title":"Phase 12: Update test assertions","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.332457909-06:00","updated_at":"2025-12-20T22:18:59.771538502-06:00","closed_at":"2025-11-24T13:30:39.416197256-06:00","dependencies":[{"issue_id":"t42-3yw","depends_on_id":"t42-xlg","type":"blocks","created_at":"2025-11-24T10:35:52.077162774-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-3yw","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:56.400501951-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-3zk","title":"[Documentation] New consensus actions (agree-trick, agree-score) not in URL compression","description":"## Observation\n\nDuring the consensus refactor, we intentionally did NOT add the new action types (`agree-trick`, `agree-score`) to URL compression. They are ephemeral pacing actions.\n\nHowever, if someone enables consensus layer and then copies a URL mid-game (before all players agree), the agree actions in actionHistory won't be encoded. When that URL is loaded, the consensus state will be lost.\n\n## Is This a Problem?\n\nProbably not - URLs are meant to capture game state, not pacing state. But worth documenting:\n\n- URLs capture meaningful game events only\n- Consensus progress within a trick/scoring phase is not persisted\n- Loading a URL always starts with \"fresh\" consensus (no one has agreed yet)\n\n## Decision Needed\n\nIs this the desired behavior? Options:\n\n1. **Keep as-is** - URLs are for game state replay, not live session state\n2. **Add compression codes** - If we want URLs to capture mid-consensus state\n\nRecommend option 1 - consensus is ephemeral by design.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-27T12:28:30.691531553-06:00","updated_at":"2025-12-20T22:18:59.81892005-06:00","closed_at":"2025-11-29T10:58:08.359061605-06:00"}
{"id":"t42-425","title":"Layer-aware terminal state detection","description":"## Problem\n\nMonte Carlo AI (and other code) has to hardcode knowledge of terminal phases:\n\n```typescript\n// monte-carlo.ts:271-293\nfunction isHandComplete(state: GameState): boolean {\n  if (state.phase === 'scoring') return true;\n  if (state.phase === 'game_end') return true;\n  if (state.phase === 'one-hand-complete') return true;  // Layer-specific\\!\n  if (state.phase === 'bidding' \u0026\u0026 state.tricks.length \u003e 0) return true;\n  return false;\n}\n```\n\nThis leaks layer knowledge (one-hand-complete) into generic AI code. Adding new game modes with custom terminal states would require updating AI code.\n\n## Proposed Solution\n\nAdd `isTerminalPhase` to the Layer interface:\n\n```typescript\n// In Layer interface\nisTerminalPhase?: (phase: GamePhase) =\u003e boolean;\n\n// Base layer defines standard terminals\nisTerminalPhase: (phase) =\u003e phase === 'game_end' || phase === 'scoring'\n\n// OneHand layer adds its terminal\nisTerminalPhase: (phase) =\u003e phase === 'one-hand-complete'\n```\n\nCompose into rules:\n```typescript\nisTerminal: (state) =\u003e composedLayers.some(l =\u003e l.isTerminalPhase?.(state.phase))\n```\n\nThen AI just calls `ctx.rules.isTerminal(state)` - no layer-specific knowledge needed.\n\n## Benefit\n\nNew game modes can define their own terminal states without touching AI code.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-26T16:12:40.15436947-06:00","updated_at":"2025-12-20T22:18:59.752988434-06:00","closed_at":"2025-11-26T23:12:46.359456416-06:00"}
{"id":"t42-43w4","title":"Retire markdown checklist planning workflow (use bd instead)","description":"Use texas-42 skill.\\n\\nProject guidelines require bd/beads for issue tracking, but we still have a script and plan file that implement work via markdown checkboxes. This duplicates tracking systems and conflicts with AGENTS.md + CLAUDE.md guidance.\\n\\nEvidence:\\n- scripts/implement-plan.sh scans docs/rules-gherkin-plan.md for '[ ]' tasks and checks them off\\n\\nFix direction:\\n- Replace docs/rules-gherkin-plan.md with bd issues (or import into bd)\\n- Update/remove scripts/implement-plan.sh accordingly\\n- Ensure any future planning docs go into history/ and do not become the task system","status":"open","priority":3,"issue_type":"chore","created_at":"2025-12-27T00:31:01.54023465-06:00","updated_at":"2025-12-27T00:31:01.54023465-06:00","dependencies":[{"issue_id":"t42-43w4","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:31:01.543560652-06:00","created_by":"jason"}]}
{"id":"t42-44x","title":"Fix tests for new multiplayer architecture","description":"Update all tests to work with the new simplified multiplayer architecture.\n\n**Reference**: docs/MULTIPLAYER.md\n\n**IMPORTANT**: This is roll forward / clean break / NO backwards compatibility whatsoever.\n\n**Changes**:\n- Delete tests for deleted code (NetworkGameClient, Transport, etc.)\n- Update integration tests to use new patterns\n- Add tests for Socket, GameClient, local.ts wiring\n- Ensure all existing game logic tests still pass\n\n**Goal**: Green test suite with the new architecture.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-25T14:56:29.344043981-06:00","updated_at":"2025-12-20T22:18:59.685259799-06:00","closed_at":"2025-11-25T16:17:45.695011537-06:00","dependencies":[{"issue_id":"t42-44x","depends_on_id":"t42-don","type":"parent-child","created_at":"2025-11-25T14:56:58.839797771-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-44x","depends_on_id":"t42-l2l","type":"blocks","created_at":"2025-11-25T14:56:59.730297369-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-48w","title":"Phase 18: Rename public API (registry functions and constants)","description":"**Title**: Phase 18: Rename public API - registry functions and exported constants","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T13:51:33.087086864-06:00","updated_at":"2025-12-20T22:18:59.765995827-06:00","closed_at":"2025-11-24T14:36:34.754729382-06:00","dependencies":[{"issue_id":"t42-48w","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T13:52:07.133188114-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-48w","depends_on_id":"t42-u87","type":"blocks","created_at":"2025-11-24T13:52:16.746782927-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-4b9","title":"Dijkstra's Discipline: Architectural Refinements","description":"A collection of architectural improvements inspired by Dijkstra's principles of simplicity, correctness, and elegance. These issues address complexity that has accumulated in the codebase - not bugs, but opportunities to make the crystal palace clearer.\n\n\"Simplicity is prerequisite for reliability.\" — E.W. Dijkstra","status":"open","priority":3,"issue_type":"epic","created_at":"2025-11-29T12:09:38.404934019-06:00","updated_at":"2025-12-20T22:18:59.810217594-06:00","dependencies":[{"issue_id":"t42-4b9","depends_on_id":"t42-8ee","type":"blocks","created_at":"2025-12-20T09:29:08.003513748-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-4et","title":"Pathfind to desired game state for tests","description":"Use texas-42 skill.\n\n**Problem**: Tests currently use fragile seeds and hard-coded domino sets that don't reliably produce desired game states.\n\n**Solution**: Create a pathfinding function that:\n1. Takes a desired state specification (e.g., \"player 1 has [6:6, 5:5, 4:4]\", \"player 2 bid 42\")\n2. Searches for a seed that produces that configuration\n3. Returns both the seed AND the complete pure game state at that point\n\n**Benefits**:\n- Tests become self-documenting (specify what you want, not magic numbers)\n- No more brittle hard-coded domino arrays\n- States are guaranteed valid (pathfound through actual game logic)\n- Reproducible via returned seed\n\n**Implementation ideas**:\n- Constraint-based search over RNG seeds\n- Could use backtracking if needed for complex multi-constraint scenarios\n- Cache discovered seeds for common test scenarios","design":"## Approach: Constraint-Based Deal Generation\n\nPer Stable Dependency Principle: a pure function with zero external dependencies that, once correct, never needs to change.\n\n### Architecture\n\n```\nsrc/tests/helpers/\n  dealConstraints.ts      # NEW: Pure constraint satisfaction\n  dealConstraints.test.ts # NEW: Comprehensive tests\n  stateBuilder.ts         # MODIFY: Add constraint methods\n```\n\n**Dependency Direction:**\n```\nTests → StateBuilder → dealConstraints.ts → (only domino creation utilities)\n                                          ↓\n                              Zero dependency on game RNG/dealing\n```\n\n### Core Types\n\n```typescript\ninterface PlayerConstraint {\n  exactDominoes?: string[];           // Must have these specific dominoes\n  minDoubles?: number;                // At least N doubles\n  maxDoubles?: number;                // At most N doubles\n  mustHaveSuit?: number[];            // Must have ≥1 domino in these suits\n  voidInSuit?: number[];              // Must have 0 dominoes in these suits\n  minSuitCount?: Record\u003cnumber, number\u003e; // Suit → minimum count\n  minPoints?: number;                 // Minimum hand point value\n}\n\ninterface DealConstraints {\n  players?: Partial\u003cRecord\u003c0|1|2|3, PlayerConstraint\u003e\u003e;\n  fillSeed?: number;  // For deterministic filling of remaining slots\n}\n```\n\n### Algorithm\n\n1. Validate constraints (detect impossibilities early)\n2. Create pool of all 28 dominoes\n3. Assign exactDominoes (remove from pool)\n4. Satisfy minDoubles by assigning doubles from pool\n5. Satisfy mustHaveSuit by assigning suit dominoes\n6. Respect voidInSuit when filling remaining slots\n7. Fill remaining with seeded shuffle of remaining pool\n8. Validate final hands satisfy all constraints\n\n### StateBuilder Integration\n\n```typescript\n.withPlayerConstraint(player: 0|1|2|3, constraint: PlayerConstraint)\n.withPlayerDoubles(player: 0|1|2|3, minDoubles: number)\n.withDealConstraints(constraints: DealConstraints)\n.withFillSeed(seed: number)\n```\n\n### Example Usage\n\n```typescript\n// Plunge-eligible hand\nStateBuilder.inBiddingPhase()\n  .withPlayerDoubles(0, 4)\n  .withFillSeed(42)\n  .build();\n\n// Complex scenario\nStateBuilder.inBiddingPhase()\n  .withDealConstraints({\n    players: {\n      0: { exactDominoes: ['6-6'], minDoubles: 3 },\n      1: { voidInSuit: [6], maxDoubles: 1 }\n    },\n    fillSeed: 99999\n  })\n  .build();\n```","acceptance_criteria":"- [ ] `generateDealFromConstraints()` is a pure function with no game dependencies\n- [ ] All satisfiable constraints produce valid hands\n- [ ] Impossible constraints throw descriptive errors\n- [ ] Deterministic: same constraints + fillSeed = identical output\n- [ ] StateBuilder integration is ergonomic\n- [ ] All existing tests pass\n- [ ] New tests demonstrate common constraint patterns","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-28T16:56:15.4555961-06:00","updated_at":"2025-12-20T22:18:59.741127809-06:00","closed_at":"2025-11-28T17:34:44.195045836-06:00","labels":["dx","testing"]}
{"id":"t42-4qa","title":"Phase 15: Final cleanup and verification","description":"**Type**: task","acceptance_criteria":"npm run test:all passes AND all verification greps clean","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.345098252-06:00","updated_at":"2025-12-20T22:18:59.769060291-06:00","closed_at":"2025-11-24T13:30:46.769079766-06:00","dependencies":[{"issue_id":"t42-4qa","depends_on_id":"t42-9yi","type":"blocks","created_at":"2025-11-24T10:35:54.631650698-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-4qa","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:59.023077308-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-4vn","title":"Add unit tests for multiplayer infrastructure (GameClient, local.ts at 0%)","description":"Use texas-42 skill.\n\nCore multiplayer infrastructure has 0% unit test coverage despite being actively used:\n\n- `GameClient.ts` - 0% (lines 5-43) \n- `local.ts` - 0% (lines 3-110)\n- `stateLifecycle.ts` - 49.2% (lines 28-47, 50-63, 73-74)\n\nThese are ACTIVE files - they're the foundation of all game connections.\n\n## What needs testing:\n\n### GameClient.ts\n- Message handling (STATE_UPDATE, ERROR)\n- Subscription mechanism (subscribe/unsubscribe)\n- JSON serialization/deserialization\n- Mock Socket and verify method calls\n\n### local.ts\n- `createLocalGame()` socket creation and routing\n- Handler registration\n- AI client creation\n- `attachAIBehavior()` subscription mechanics\n- `skipAIBehavior` option\n\n### stateLifecycle.ts (fill remaining 51%)\n- `addPlayer()` error cases (duplicate playerId, duplicate playerIndex)\n- `removePlayer()` marks disconnected (doesn't delete)\n- `updatePlayerSession()` Result type handling\n- Player sorting in `addPlayer()`\n\n## Note:\nSocket.ts, index.ts, and protocol.ts are type definitions/interfaces with no testable logic - 0% coverage is expected and acceptable.","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-29T12:49:30.49132112-06:00","updated_at":"2025-12-20T22:18:59.737614071-06:00","labels":["multiplayer","testing"],"dependencies":[{"issue_id":"t42-4vn","depends_on_id":"t42-65p","type":"parent-child","created_at":"2025-11-30T10:44:27.82031714-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-4vn","depends_on_id":"t42-8d5","type":"blocks","created_at":"2025-12-20T09:12:01.902583377-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-4ytq","title":"Optimize checkHandOutcome: O(1) point-based logic","description":"Use texas-42 skill.\n\n## Problem\n\nProfiling (t42-79h0) identified `checkHandOutcome` → `calculateRemainingPoints` as the #1 bottleneck (~50% CPU). On every minimax node, it:\n- Creates a Set from all played tricks\n- Creates 28 Domino objects via `createDominoes()`\n- Iterates all 28 dominoes\n\nWith 300K+ search nodes per PIMC evaluation, this is catastrophic.\n\n## Solution\n\nReplace complex iteration with O(1) arithmetic:\n\n```typescript\n// Old: O(28 + tricks) with allocations\nconst remainingPoints = calculateRemainingPoints(state);\nconst maxPossible = biddingScore + remainingPoints;\nif (maxPossible \u003c bidValue) { /* can't make */ }\n\n// New: O(1), zero allocations  \nif (defendingScore \u003e 42 - bidValue) { /* set */ }\n```\n\nKey insight: `maxPossible = 42 - defendingScore`, so the checks are equivalent.\n\n## Changes\n\n### 1. Base layer (`handOutcome.ts`)\nReplace `calculateRemainingPoints` usage with direct score checks:\n- Points bid: `defendingScore \u003e 42 - bidValue` → set\n- Marks bid: `defendingScore \u003e 0` → set (redundant check can be removed)\n\n### 2. Optional: Splash/Plunge layers\nCould simplify `checkTrickBasedHandOutcome` to `defendingScore \u003e 0`, but current O(7) is negligible.\n\n### 3. Nello layer\nAlready efficient, but could simplify to `biddingTeamScore \u003e 0` for consistency.\n\n## Verification\n\nRe-run profiler after fix:\n```bash\nnpx esbuild scripts/profile-pimc.ts --bundle --platform=node --outfile=./artifacts/profile-pimc.bundle.js --format=esm\nnode --cpu-prof --cpu-prof-dir=./artifacts ./artifacts/profile-pimc.bundle.js\n```\n\nTarget: \u003c30ms per eval (currently 89ms)","acceptance_criteria":"- [ ] `calculateRemainingPoints` removed or simplified to O(1)\n- [ ] Base layer checkHandOutcome uses direct score comparisons\n- [ ] All existing tests pass\n- [ ] Profiler shows checkHandOutcome/getAllPlayedDominoes no longer in top 10\n- [ ] Average eval time reduced by 50%+ (target \u003c45ms)","status":"closed","priority":1,"issue_type":"task","assignee":"claude","created_at":"2025-12-23T17:10:31.266404654-06:00","updated_at":"2025-12-24T08:24:12.543853529-06:00","closed_at":"2025-12-24T08:24:12.543853529-06:00","close_reason":"All acceptance criteria met:\n- calculateRemainingPoints removed (O(1) arithmetic now)\n- Base layer uses direct score comparisons\n- All 1016 unit + 18 e2e tests pass\n- Benchmark shows \u003c2ms per eval (was 89ms) = 98%+ reduction\n- checkHandOutcome no longer a bottleneck (verified via t42-gpwz benchmark)","labels":["ai","performance"]}
{"id":"t42-55p","title":"AI players not wired to configurable strategy - only inline random","description":"Found during Intermediate AI comprehension test review.\n\nIn the multiplayer code, AI players appear to use an inline random move selector rather than the configurable AI strategy system (beginner/intermediate/random via setDefaultAIStrategy).\n\nNeed to:\n1. Verify how AI players are currently selecting moves in local.ts / attachAIBehavior\n2. Wire up the actual AIStrategy system so setDefaultAIStrategy() affects gameplay\n3. Ensure IntermediateAIStrategy can be selected for AI opponents\n\nRelated: mk5-tailwind-vw0 (attachAIBehavior doc/code mismatch)","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-26T15:58:29.827658096-06:00","updated_at":"2025-12-20T22:18:59.683550684-06:00","closed_at":"2025-11-26T23:42:42.746437694-06:00"}
{"id":"t42-5pm","title":"Investigate 2 nello-full-hand.test.ts failures - tests likely written before early termination","description":"Tests failing:\n1. should continue playing when bidder loses all tricks so far - ends at trick 1 instead of 7\n2. should end early when bidder wins on 3rd trick after losing first 2 - Cannot read properties of undefined (reading 'action')\n\nRoot cause: Tests were written before early termination logic was implemented. Early termination is firing when it shouldn't for nello (bidder successfully losing tricks), OR test expectations are wrong. Need to verify nello's checkHandOutcome logic only terminates when bidder WINS a trick (fails nello), not when they're successfully losing.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-17T16:40:10.883538211-06:00","updated_at":"2025-12-20T22:18:59.701214044-06:00","closed_at":"2025-11-19T10:28:53.343044755-06:00"}
{"id":"t42-5zp","title":"Fix nello-full-hand.test.ts: test helper not completing tricks","description":"The dominoFollowsSuit bug is FIXED (5-5 now correctly beats 0-0 in nello). However, 4/10 nello integration tests still fail because the playNelloHand test helper isn't completing tricks properly.\n\nStatus:\n- Game logic: ✅ FIXED (verified via scratch/debug-with-game-logic.ts and scratch/verify-fix.test.ts)\n- Integration tests: ❌ Still failing (test infrastructure issue)\n\nFailing tests:\n1. should complete when bidder loses all 7 tricks - gets 0 tricks instead of 7\n2. should end early when bidder wins a trick - gets 0 tricks  \n3. should continue playing when bidder loses all tricks so far - gets 0 tricks\n4. should end early when bidder wins on 3rd trick after losing first 2 - undefined error\n\nRoot cause: The playNelloHand helper in nello-full-hand.test.ts isn't playing through tricks correctly. Likely issues:\n- Consensus handling\n- Trick completion logic\n- Loop exit conditions\n\nThe debug script works perfectly with the SAME hands, proving game logic is sound.\n\nRelated: mk5-tailwind-5pm (original issue about nello failures)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-19T08:19:34.903019322-06:00","updated_at":"2025-12-20T22:18:59.695036256-06:00","closed_at":"2025-11-19T10:28:37.324589544-06:00","dependencies":[{"issue_id":"t42-5zp","depends_on_id":"t42-5pm","type":"discovered-from","created_at":"2025-11-19T08:19:34.907352594-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-61x","title":"Update executeCompleteTrick executor","description":"Update src/game/core/actions.ts: Change from 'if (outcome \u0026\u0026 outcome.isDetermined)' to 'if (outcome.determined)'. Leverage TypeScript type narrowing. Depends on mk5-tailwind-2gg.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-16T16:55:00.839201257-06:00","updated_at":"2025-12-20T22:18:59.667571754-06:00","closed_at":"2025-11-16T17:13:10.723237851-06:00"}
{"id":"t42-65p","title":"Code Coverage Improvements","description":"Epic for improving unit test coverage across the codebase.\n\nCurrent coverage: 70.36% statements, 83.68% branches, 78.46% functions\n\nFocus areas:\n- AI pipeline (Monte Carlo, hand sampling, constraint tracking)\n- Multiplayer infrastructure (GameClient, local game wiring)\n- Server error handling paths\n- UI projection logic\n- Layer metadata generation","status":"open","priority":2,"issue_type":"epic","created_at":"2025-11-30T10:44:17.874434651-06:00","updated_at":"2025-12-20T22:18:59.73665665-06:00","labels":["testing"],"dependencies":[{"issue_id":"t42-65p","depends_on_id":"t42-8d5","type":"blocks","created_at":"2025-12-20T09:12:01.744863098-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-6b1","title":"Replace rejection sampling with deterministic constraint satisfaction","description":"## Problem\n\nHand sampler uses rejection sampling with up to 1000 attempts. With tight constraints, most random attempts fail → O(∞) worst case.\n\n## Analysis: It's Not Just About Guarantees\n\nInitial analysis focused on deterministic guarantees (CSP, max-flow, greedy). But deeper analysis revealed a more important question: **which sampling distribution is best for AI decision quality?**\n\n### The Key Question: \"Who Has the 5-5?\"\n\nThe AI uses hand sampling to estimate P(player X has domino D). Different strategies produce different probability distributions:\n\n| Strategy | Bias | Implication |\n|----------|------|-------------|\n| **Uniform (rejection)** | Each valid assignment equally likely | Not same as P(assignment \\| random deal) |\n| **Greedy (min-slack)** | Constrained players pick first | Over-weights constrained players having key dominoes |\n| **Weighted (by candidates)** | More candidates = more likely | May better approximate Bayesian posterior |\n\n### Bayesian Insight\n\nThe \"correct\" distribution isn't uniform over valid assignments. It should be weighted by \"how many original random deals map to this assignment.\"\n\nExample: If opponent has tight constraints (void in 3 suits), and yet 5-5 is in their candidate set, Bayesian reasoning says they're *less* likely to have it (most deals would have ruled them out). Greedy gets this backwards.\n\n## Blocked By\n\n**mk5-tailwind-19k**: Build Oracle Test harness first to empirically measure which strategy best predicts true hidden hands. Don't commit to a strategy without data.\n\n## Candidate Implementations (pending oracle results)\n\n1. **Dynamic Greedy**: O(189), guaranteed, but biased toward constrained players\n2. **Weighted Random**: O(n), guaranteed, weights by candidate set size  \n3. **Hybrid**: Rejection first (uniform when easy), greedy fallback (guaranteed when hard)\n4. **MCMC**: O(n³), approximately uniform, expensive\n\n## Files\n\n- `src/game/ai/hand-sampler.ts` - Current rejection sampling\n- `src/game/ai/constraint-tracker.ts` - Constraint building","acceptance_criteria":"- Oracle test (mk5-tailwind-19k) completed with clear winner\n- Chosen strategy implemented with deterministic guarantee\n- No regression in AI decision quality (validated by oracle metrics)\n- Rejection sampling retry loop removed","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-26T16:13:06.115356691-06:00","updated_at":"2025-12-20T22:18:59.825786053-06:00","closed_at":"2025-11-27T10:26:25.090547086-06:00","dependencies":[{"issue_id":"t42-6b1","depends_on_id":"t42-19k","type":"blocks","created_at":"2025-11-27T09:39:05.90857604-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"t42-6b4","title":"[Documentation] Generate client implementation guide for multiplayer","description":"Create a comprehensive CLIENT_IMPLEMENTATION_GUIDE.md that documents everything a new client implementer needs to know to build a Texas 42 client in any language.\n\nThe guide should cover:\n\n## Socket Interface\n- The minimal Socket interface (send, onMessage, close)\n- How it maps to WebSocket, postMessage, or any bidirectional channel\n\n## Protocol Messages\n- ClientMessage types (EXECUTE_ACTION, JOIN, SET_CONTROL)\n- ServerMessage types (STATE_UPDATE, ERROR)\n- JSON serialization format\n- Fire-and-forget semantics (no promise correlation)\n\n## GameView Structure\n- What fields are in a GameView\n- How views are filtered per-client (capabilities system)\n- What data is available to spectators vs players\n\n## GameAction Types\n- All action types a client can send\n- Required fields for each action type\n- When each action is valid (derived from validActions in view)\n\n## Client Lifecycle\n1. Connect to socket\n2. Send JOIN message (optional based on mode)\n3. Subscribe to STATE_UPDATE messages\n4. When validActions contains actions for your player, choose and send EXECUTE_ACTION\n5. Handle ERROR messages gracefully\n\n## Room Configuration\n- GameConfig structure\n- Player count, scoring rules, special contracts\n- How config affects what actions are valid\n\n## AI Client Example\n- Minimal AI that subscribes to view and sends random valid action\n- Shows the simplicity of the client model\n\n## Testing Your Client\n- How to verify correct behavior\n- Common mistakes to avoid","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-27T20:51:31.756056605-06:00","updated_at":"2025-12-20T22:18:59.743553371-06:00","closed_at":"2025-11-28T10:52:39.411388333-06:00","labels":["documentation","multiplayer"],"dependencies":[{"issue_id":"t42-6b4","depends_on_id":"t42-1gv","type":"parent-child","created_at":"2025-11-28T10:14:52.980550609-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-6hi4","title":"Train policy network on solver2 perfect-play data","description":"Use texas-42 skill.\n\n## Goal\n\nTrain a neural network to predict optimal moves from solver2's exhaustive move-value tables.\n\n## Input Data\n\nsolver2 outputs per (seed, decl):\n- `all_states`: packed int64 states\n- `V`: optimal value per state (int16)\n- `move_values`: value of each of 7 moves (int16, -128 = illegal)\n\n## Network Architecture\n\n### Input Features (~50-100 dims)\n- Hand masks: 4 × 7 bits = 28 (which cards remain)\n- Leader: 2 bits\n- Trick state: trick_len (2 bits) + 3 × 3-bit plays\n- Declaration: one-hot (10 values)\n- Current player derived from leader + trick_len\n\n### Output\n- 7 logits (one per local index)\n- Softmax with temperature\n- Mask illegal moves (-128 in move_values)\n\n### Loss\n- Cross-entropy against argmax(move_values) for best move\n- Or soft targets from move_values (treat as Q-values)\n\n## Training Script\n\n```\nscripts/solver2/train_policy.py\n  --data-dir data/solver2/\n  --output models/policy-net.pt\n  --epochs 10\n  --batch-size 4096\n```\n\n## Validation\n\n- Hold out some seeds for validation\n- Compare network's top choice vs solver's optimal\n- Target: \u003e90% top-1 accuracy on optimal move\n\n## Output\n\n- PyTorch model: `models/policy-net.pt`\n- ONNX export: `models/policy-net.onnx`\n- Training metrics log","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T20:57:46.793702211-06:00","updated_at":"2025-12-27T20:57:46.793702211-06:00","dependencies":[{"issue_id":"t42-6hi4","depends_on_id":"t42-vvvz","type":"blocks","created_at":"2025-12-27T20:58:21.662671357-06:00","created_by":"jason"}]}
{"id":"t42-6hv5","title":"Unify action equality/matching logic (avoid JSON.stringify comparisons)","description":"Use texas-42 skill.\\n\\nWe currently compare GameAction objects in multiple places with subtly different rules (and JSON.stringify for trump). This is duplicated logic and risks drift.\\n\\nEvidence:\\n- src/multiplayer/authorization.ts actionsMatch()\\n- src/kernel/kernel.ts findMatchingTransition()\\n\\nFix direction:\\n- Prefer matching via actionToId() where possible\\n- If actionToId is not sufficiently unique, introduce a single shared actionKey/actionEquals helper in src/game/core/actions.ts (or a dedicated module) and use it everywhere\\n- Remove JSON.stringify comparisons in favor of stable, typed comparisons","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T00:30:15.997916765-06:00","updated_at":"2025-12-27T00:30:15.997916765-06:00","dependencies":[{"issue_id":"t42-6hv5","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:30:16.001392606-06:00","created_by":"jason"}]}
{"id":"t42-6hx","title":"[Maintenance \u0026 Cleanup] Investigate uncovered code in multiplayer/server","description":"Coverage report shows significant gaps in multiplayer and server code.\n\nRun `npm run test:coverage` for full detailed report.\n\n**Current thresholds (67/82/77/67):**\n- statements: 67%\n- branches: 82%\n- functions: 77%\n- lines: 67%\n\n**Multiplayer (63.97% overall):**\n- `GameClient.ts` - 0% statements\n- `Socket.ts` - 0% all metrics\n- `index.ts` - 0% statements\n- `local.ts` - 0% statements\n- `protocol.ts` - 0% all metrics\n- `gameLifecycle.ts` - 49.2% statements\n\n**Server (64.66% overall):**\n- `Room.ts` - 61.25% statements\n- `HeadlessRoom.ts` - 78.33% statements\n\nInvestigate whether these need unit tests or if they're adequately covered by E2E tests. If unit tests are warranted, add them.","notes":"## Investigation Complete\n\n### Deleted Dead Code\n1. `src/game/ai/hand-strength-components.ts` - entire file (0 imports)\n2. `src/game/core/suit-analysis.ts` - `analyzeLeads()`, `isHighestUnplayed()`, `countPlayedTrump()`, `LeadAnalysis` interface (~230 lines)\n3. `src/game/core/action-resolution.ts` - `resolveActionId()` single-action variant (never imported)\n\n### Coverage Improved\n- Statements: 68.11% → 70.36% (+2.25%)\n- No test failures\n\n### Created Follow-up Issues\n- mk5-tailwind-if8: Monte Carlo AI pipeline tests (3-32% coverage)\n- mk5-tailwind-4vn: Multiplayer infrastructure tests (0% coverage)\n- t42-793: Room.ts error handling tests (61% coverage)\n- mk5-tailwind-adq: view-projection.ts tests (0% coverage)\n- mk5-tailwind-bdt: hints.ts and speed.ts layer tests (5-7% coverage)\n\n### Key Findings\n**Files with 0% coverage that are OK:**\n- `Socket.ts`, `protocol.ts`, `index.ts` - Type definitions/interfaces with no executable code\n- `view-projection.ts` - Tested via E2E (Playwright), not unit tests\n\n**Active code needing tests (filed issues):**\n- Monte Carlo pipeline (monte-carlo.ts, hand-sampler.ts, constraint-tracker.ts)\n- Multiplayer wiring (GameClient.ts, local.ts, stateLifecycle.ts)\n- Room error handling paths\n- Layer metadata generation (hints, speed)","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-27T01:09:10.802254965-06:00","updated_at":"2025-12-20T22:18:59.821882372-06:00","closed_at":"2025-11-29T12:51:57.274000455-06:00","dependencies":[{"issue_id":"t42-6hx","depends_on_id":"t42-xxi","type":"parent-child","created_at":"2025-11-28T10:14:53.4280338-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-6ir","title":"Investigate E2E redeal test failure - autoExecute behavior vs test expectations","description":"E2E test 'should progress through bidding round and allow redeal' failing at line 272:\nTest expects to see redeal action in available actions, but finds nothing.\n\nbasic-gameplay-new.spec.ts:272:\nexpect(actions.some(action =\u003e action.type === 'redeal')).toBe(true)\nExpected: true, Received: false\n\nINVESTIGATION NEEDED - DO NOT change test expectations without approval:\n1. Is redeal supposed to be visible to the user or auto-executed?\n2. Did autoExecute behavior change recently?\n3. Was this test passing before? What changed?\n4. Is the test expectation correct for the intended UX?\n\nInitial analysis suggests redeal has autoExecute: true flag and is processed by kernel before reaching UI. But WHY is the test expecting manual execution?\n\nThis could indicate:\n- Test was written with wrong expectations\n- autoExecute behavior changed\n- Kernel processing changed\n- Something broke in the action generation or auto-execution flow\n\nNeed to understand INTENDED behavior before fixing.","notes":"Fixed: Deleted broken E2E test that expected manual redeal execution. Added comprehensive auto-execute tests to gamehost-autoexec.test.ts that verify: 1) redeal auto-executes after all-pass, 2) redeal has system authority, 3) redeal works regardless of capabilities. Root cause: Test was written in same commit that added autoExecute flag, but with wrong expectations for manual execution.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-16T16:22:14.635460775-06:00","updated_at":"2025-12-20T22:18:59.791918259-06:00","closed_at":"2025-11-17T19:51:54.716326178-06:00"}
{"id":"t42-6nf","title":"Policy Network: neural net AI trained on self-play","description":"Use texas-42 skill.\n\nTrain a neural network to play Texas 42 directly from self-play games. Unlike MCTS (expected value) or CFR (Nash equilibrium), self-play can develop 'style' and learn to exploit.\n\n## Architecture\n\n### Input Features (~300 dimensions)\n- My hand: 28 bits (which dominoes)\n- Played cards: 28 bits  \n- Current trick: 4 × 28 bits\n- Trump: one-hot (9 values)\n- Trick number, position, scores\n- Void inference: 4 players × 7 suits\n- Bid info\n\n### Output\n- Policy: 28 probabilities (one per domino, mask illegal)\n- Optional: Value head for position evaluation\n\n### Network\n- Simple MLP: 300 → 256 → 256 → 28\n- ~100K parameters (tiny)\n\n## Training Pipeline\n\n1. Generate self-play games (can use current MCTS or random)\n2. Collect (state, action, outcome) tuples\n3. Train network to predict winning actions\n4. Optional: iterate (network plays itself, generates better data)\n\n## Infrastructure Needed\n\n- Python + PyTorch for training\n- Feature extraction in TypeScript\n- ONNX export for browser inference (or TF.js)\n\n## Effort Estimate\n\n- Lines of code: ~600-800\n- Training: 4-6 hours on RTX 3050\n- Data generation: ~1 hour (100K games)\n\n## Why This Could Be Fun\n\n- Self-play learns 'what wins', not just expected value\n- Can develop style, preferences, tendencies\n- May find non-obvious strategies\n- Has 'personality' that pure MCTS lacks\n\n## Files to Create\n\n- `src/game/ai/neural/features.ts` - state → tensor\n- `src/game/ai/neural/policy-net.ts` - network wrapper\n- `scripts/train-policy-net.py` - training script\n- `models/policy-net.onnx` - trained model\n\n## Depends On\n\nConsider doing mk5-tailwind-9ed (MCTS fixes) first for a working baseline.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-13T20:48:28.049272362-06:00","updated_at":"2025-12-27T20:58:58.89917628-06:00","closed_at":"2025-12-27T20:58:58.89917628-06:00","close_reason":"Obsolete - superseded by t42-vvvz (perfect-play policy network from solver2 data). Using solver2 ground truth is better than self-play.","dependencies":[{"issue_id":"t42-6nf","depends_on_id":"t42-9ed","type":"blocks","created_at":"2025-12-13T20:50:13.276289438-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-6nf","depends_on_id":"t42-liuw","type":"blocks","created_at":"2025-12-23T16:42:44.426404129-06:00","created_by":"jason"}]}
{"id":"t42-6pt","title":"Update special rulesets (nello/plunge/splash/sevens)","description":"Update 4 rulesets + helpers.ts: Change checkMustWinAllTricks to return HandOutcome (not | null). Update all checkHandOutcome overrides to use discriminated union. Depends on mk5-tailwind-2gg, mk5-tailwind-1v4.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-16T16:54:54.720514106-06:00","updated_at":"2025-12-20T22:18:59.668363172-06:00","closed_at":"2025-11-16T17:13:10.722571245-06:00"}
{"id":"t42-6zm","title":"[Future Features] AlphaGo-style neural network AI bootstrapping","description":"## Overview\n\nUse Monte Carlo simulation data to train a neural network for position evaluation, enabling an 'Expert' AI tier beyond the current Intermediate.\n\n## Approach (AlphaGo-inspired)\n\n1. **Data Generation**: Run many games with Intermediate AI, recording (state, outcome) pairs\n2. **Value Network**: Train NN to predict game outcome from position\n3. **Integration**: Replace/augment Monte Carlo rollouts with NN evaluation\n   - Instead of 50 rollouts to estimate position value\n   - Single NN forward pass gives estimated win probability\n4. **Iteration**: Use improved AI to generate better training data, retrain\n\n## Benefits\n\n- **Speed**: NN inference faster than 50 rollouts\n- **Quality**: Learns patterns Monte Carlo misses (reading opponent tendencies, positional nuances)\n- **Scalability**: Can improve indefinitely with more training\n\n## Technical Considerations\n\n- Feature encoding for domino hands + game state\n- Could use simple MLP or transformer architecture  \n- Training offline, inference in browser (ONNX.js or TensorFlow.js)\n- Would need validation against Intermediate to confirm improvement\n\n## Progression\n\nBeginner (heuristics) → Intermediate (Monte Carlo) → Expert (Neural Network)\n\n## References\n\n- AlphaGo: Monte Carlo + Value/Policy networks\n- Could also add Policy network for move selection (not just evaluation)","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-26T16:12:52.866566775-06:00","updated_at":"2025-12-27T20:58:59.292971151-06:00","closed_at":"2025-12-27T20:58:59.292971151-06:00","close_reason":"Obsolete - superseded by t42-vvvz (perfect-play policy network from solver2 data). Solver2 provides exact training data, no need for AlphaGo-style iteration.","dependencies":[{"issue_id":"t42-6zm","depends_on_id":"t42-e69","type":"parent-child","created_at":"2025-11-28T10:14:53.877664296-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-73a","title":"Refactor HandOutcome to discriminated union","description":"Replace HandOutcome | null pattern with discriminated union { determined: true/false }. Eliminates nulls, makes invalid states unrepresentable, aligns with FP principles and Result\u003cT\u003e pattern already in codebase.","status":"closed","priority":0,"issue_type":"epic","created_at":"2025-11-16T16:54:23.964793992-06:00","updated_at":"2025-12-20T22:18:59.671586373-06:00","closed_at":"2025-11-16T17:13:24.814979351-06:00"}
{"id":"t42-793","title":"Add unit tests for Room.ts error handling (61% coverage)","description":"Use texas-42 skill.\n\nRoom.ts has 61.25% coverage with gaps in error handling and lifecycle (lines 205-399, 405-419).\n\n## Uncovered areas:\n\n### Message handler error paths (lines 363-419)\n- `handleExecuteAction()` - error when client not associated with player\n- `handleJoin()` - validation errors (invalid player index, join failure)\n- `handleSetControl()` - validation errors (invalid index, control type changes)\n- Error response formatting\n\n### Destroy/lifecycle paths (lines 330-334)\n- `destroy()` method and cleanup\n- Operations on destroyed room (should throw/return early)\n- `isDestroyed` checks in public methods\n\n### Client connection tracking (lines 119-123, 150-153)\n- `handleConnect()` when room not destroyed\n- `handleDisconnect()` cleanup\n- Connected client set management\n\n## Note:\nThe happy path is well-covered by E2E tests. These unit tests target error conditions and edge cases that don't occur in normal gameplay.","status":"open","priority":3,"issue_type":"task","created_at":"2025-11-29T12:49:30.659258961-06:00","updated_at":"2025-12-20T22:18:59.799197499-06:00","labels":["server","testing"],"dependencies":[{"issue_id":"t42-793","depends_on_id":"t42-65p","type":"parent-child","created_at":"2025-11-30T10:44:27.897630134-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-793","depends_on_id":"t42-8d5","type":"blocks","created_at":"2025-12-20T09:12:02.237297081-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-79h0","title":"Profile PIMC simulator to identify bottlenecks","description":"Use texas-42 skill.\n\n## Goal\n\nBefore investing in apply/undo refactoring (t42-zkd), profile the PIMC simulator to identify actual bottlenecks with objective, measurable data.\n\n## Approach\n\nCreate a benchmark script that:\n1. Runs 100 PIMC evaluations on 3 fixed game states (early, mid, contested endgame)\n2. Uses `--cpu-prof` to capture V8 profile\n3. Instruments key functions with **call counters** (not timers):\n   - `search()` — recursion depth/count\n   - `getValidActions()` \n   - `orderMoves()`\n   - `calculateTrickWinner()`\n   - `executeAction()` / any deep copy calls\n\n4. Outputs summary:\n   ```\n   Total PIMC evals: 100\n   Total wall time: 4.2s (42ms/eval)\n   Call counts:\n     search: 48,000\n     calculateTrickWinner: 892,000  ← red flag if huge\n     getValidActions: 124,000\n     executeAction: 96,000\n   ```\n\n## Why Counters Matter\n\nProfiler self-time tells you \"this is slow.\" Call counts tell you \"this is called too many times.\" A function taking 1µs but called 900k times = 900ms. Fix the call count, not the per-call cost.\n\n## Key Insight We're Looking For\n\nEither:\n- **\"X function has 40% self-time\"** → optimize that function\n- **\"X is called 900k times per eval\"** → algorithmic issue, reduce calls\n- **\"Deep copies account for Y% via Array.slice/structuredClone\"** → validates t42-zkd\n- **\"GC is 15% of time\"** → memory allocation issue\n\n## If Inconclusive\n\nSee t42-8z4t for manual DevTools inspection as a follow-up.","acceptance_criteria":"- [ ] Benchmark script exists and runs via `node --cpu-prof scripts/profile-pimc.js` or similar\n- [ ] Script uses fixed random seed for reproducibility\n- [ ] Call counters instrumented for: search, getValidActions, orderMoves, calculateTrickWinner, executeAction\n- [ ] Output includes: wall time per eval, call counts per function\n- [ ] .cpuprofile file generated and saved to artifacts/ or noted in report\n- [ ] Report identifies at least one of:\n  - A function with \u003e15% self-time, OR\n  - A function with disproportionate call count (\u003e10x others), OR  \n  - Evidence that deep copies are/aren't the bottleneck\n- [ ] Recommendation for which optimization to pursue first (or \"none needed\" if already fast)","notes":"## Profiling Complete - Key Findings\n\n**Bottleneck identified:** `checkHandOutcome` + `calculateRemainingPoints` consume ~50% CPU\n\n### CPU Profile (Top Functions by Self-Time)\n1. `getAllPlayedDominoes` - 18.3%\n2. `checkHandOutcome` chain - ~20% total\n3. **GC** - 7.1% (memory pressure from allocations)\n4. `search` - 4.5%\n5. `calculateTrickWinner` - 4.1%\n6. `executeAction` - 3.5%\n\n### Root Cause\nOn every minimax node, `checkHandOutcome` creates:\n- A new Set from all played tricks\n- 28 new Domino objects via `createDominoes()`\n- Iterates all 28 dominoes\n\nWith 300K+ search nodes, this creates millions of allocations.\n\n### Recommendation\n**Priority 1:** Fix `calculateRemainingPoints` - it can be computed as `42 - team0Score - team1Score` (no iteration needed)\n\n**Deprioritize t42-zkd:** Deep copies (executeAction) are only 3.5% of time. The apply/undo refactoring is NOT the primary bottleneck.\n\n### Artifacts\n- `scripts/profile-pimc.ts` - Benchmark script\n- `artifacts/analyze-profile.cjs` - Profile analyzer\n- `docs/profiling-report-t42-79h0.md` - Full report","status":"closed","priority":2,"issue_type":"task","assignee":"claude","created_at":"2025-12-21T22:06:01.239213172-06:00","updated_at":"2025-12-23T16:49:18.522119718-06:00","closed_at":"2025-12-23T16:49:18.522119718-06:00","close_reason":"Profiling complete. Identified checkHandOutcome/calculateRemainingPoints as primary bottleneck (~50% CPU). Deep copies (t42-zkd target) are only 3.5%. Created benchmark script, CPU profile, and full report in docs/profiling-report-t42-79h0.md.","labels":["ai","performance"]}
{"id":"t42-7jm","title":"Phase 20: Documentation update","description":"**Title**: Phase 20: Update all documentation for Layer terminology","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T13:51:33.095495327-06:00","updated_at":"2025-12-20T22:18:59.764356594-06:00","closed_at":"2025-11-24T15:11:33.310659244-06:00","dependencies":[{"issue_id":"t42-7jm","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T13:52:08.815565881-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-7jm","depends_on_id":"t42-48w","type":"blocks","created_at":"2025-11-24T13:52:18.447719987-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-7kr","title":"Phase 21: Complete Layer Terminology Cleanup","description":"Final cleanup to eliminate ALL remaining 'RuleSet' and 'variant' terminology. The crystal palace must be pristine.\n\n## Scope:\n1. Rename layer exports: baseRuleSet→baseLayer, nelloRuleSet→nelloLayer, etc. (~8 files)\n2. Update all imports (~30+ files)\n3. Rename constants: RULESET_CODES→LAYER_CODES (url-compression.ts)\n4. Update comments in ~10 files (gameStore, sevens, types, etc.)\n5. Rename test files: *-ruleset.test.ts → *-layer.test.ts (8 files)\n6. Update test descriptions: 'X RuleSet' → 'X Layer'\n7. Remove 'variant' references (3 occurrences)\n\n## Estimated: ~50-60 files to modify\n\n## Success: Zero 'RuleSet' in src/, all exports named *Layer, tests pass","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T16:27:39.472041924-06:00","updated_at":"2025-12-20T22:18:59.758327505-06:00","closed_at":"2025-11-24T16:42:28.838288142-06:00","dependencies":[{"issue_id":"t42-7kr","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T16:27:45.985493912-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-7r2","title":"Apply dealConstraints to remaining ~40 test files","description":"Use texas-42 skill.\n\n## Context\n\nThe dealConstraints assessment (mk5-tailwind-jdb) confirmed the framework is viable for wider adoption. Successfully refactored 3 test files with improved readability and eliminated duplication.\n\n## Scope\n\nFrom the original survey of 97 test files:\n\n| Category | Files | Candidate for dealConstraints? |\n|----------|-------|-------------------------------|\n| Hard-coded domino arrays | 19 | YES - high value |\n| Seed-based dealing | 26 | YES - moderate value |\n| withPlayerHand() | 17 | MAYBE - case by case |\n| Hand-agnostic | 22 | NO - already optimal |\n| Already optimal | 13 | NO |\n\n**~45 files** could potentially benefit.\n\n## Recommended Approach\n\n### High Priority (hard-coded arrays → constraints)\nFiles with duplicated hard-coded hands get the most benefit:\n- Express semantic intent (`minDoubles`, `voidInSuit`) instead of domino lists\n- Eliminate duplication via shared `fillSeed`\n\n### Medium Priority (seed-based → constraints)  \nFiles using magic seeds for specific hands:\n- Convert to explicit constraints where intent is known\n- Keep seeds where constraints can't express the requirement\n\n### Low Priority (withPlayerHand → constraints)\nCase-by-case evaluation:\n- Some tests legitimately need exact hands (renege validation, specific trick sequences)\n- Others could benefit from semantic constraints\n\n## Exclusions\n\nDo NOT convert tests that need:\n- Game-suit precision (blocked by mk5-tailwind-lfy)\n- Exact trick sequences\n- Specific domino IDs for assertions\n\n## Success Criteria\n\n- Refactored tests pass\n- Improved readability (constraints express intent)\n- No loss of test coverage\n- Document any tests that should stay as-is","notes":"## Research Complete\n\n### Analysis Summary (32 files examined)\n\n| Recommendation | Count | Files |\n|----------------|-------|-------|\n| **YES** | 2 | `advanced-bidding.test.ts`, `action-generation.test.ts` |\n| **PARTIAL** | 3 | `trump-suit-following.test.ts`, `edge-cases.test.ts`, `special-scenarios.test.ts` |\n| **NO** | 27 | All others |\n\n### Refactors Applied\n1. **`advanced-bidding.test.ts`** - Replaced `HandBuilder.withDoubles(N)` + `withPlayerHand()` with `withPlayerDoubles(N)` + `withFillSeed()`\n2. **`action-generation.test.ts`** - Replaced hard-coded `threeDoubles`/`fourDoubles` arrays with `createBiddingStateWithDoubles()` helper using constraints\n\n### Key Finding: Most Files Should NOT Be Refactored\n\nThe overwhelming majority (84%) of candidate files should **not** use dealConstraints because:\n\n1. **Unit tests need exact inputs** - Tests for `determineTrickWinner()`, `analyzeSuits()`, `getDominoPoints()` need specific dominoes, not semantic constraints\n2. **Empty hands are intentional** - Many layer unit tests use `withHands([[], [], [], []])` because hand contents are irrelevant to what's being tested\n3. **Trick logic ≠ hand generation** - Tests with hard-coded domino arrays are often testing trick evaluation, not deal scenarios\n4. **Renege tests need game-suit precision** - Constraint system operates on pip values, but renege rules require trump-aware game-suit logic\n\n### Where dealConstraints DOES Excel\n\nThe framework is valuable for:\n- **Integration tests with bidding requirements**: \"Player needs 4 doubles for plunge\" → `withPlayerDoubles(0, 4)`\n- **Full game simulations**: `standard-game.test.ts`, `nello-three-player.test.ts`\n- **Tests where semantic intent \u003e exact composition**: \"Strong bidding hand\" vs listing 7 specific dominoes\n\n### Conclusion\n\nThe dealConstraints framework is **correctly scoped** - it's valuable for integration tests expressing semantic hand requirements, but should NOT replace explicit hand construction in unit tests. The original estimate of \"~45 files could benefit\" was optimistic; the actual number is closer to 5-8 files.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-28T22:37:01.618320719-06:00","updated_at":"2025-12-20T22:18:59.814192569-06:00","closed_at":"2025-11-29T10:53:50.202895846-06:00","labels":["dx","refactor","testing"]}
{"id":"t42-7y8","title":"Consensus layer not wired into multiplayer Room configuration","description":"## Observation\n\nThe consensus layer exists and works, but I didn't verify where/how multiplayer games configure their layers. \n\nFor the \"tap to continue\" UX to work in real multiplayer:\n- Room/GameHost needs to include `consensus` in its layer configuration\n- The UI needs to render agree-trick/agree-score actions as tappable buttons\n\n## To Verify\n\n1. Where does multiplayer configure layers? (likely in Room or GameHost setup)\n2. Is `consensus` layer included for multiplayer games?\n3. Does the UI know how to render agree-trick/agree-score actions?\n\n## Likely Files\n\n- `src/multiplayer/Room.ts` or similar\n- `src/components/` - action button rendering","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-27T12:28:39.333554624-06:00","updated_at":"2025-12-20T22:18:59.74450994-06:00","closed_at":"2025-11-27T18:46:41.20753325-06:00"}
{"id":"t42-84a","title":"Sparks: the planning tool Claude wants to use","description":"A lightweight issue tracker that LLMs use eagerly and enthusiastically with minimal prompting.\n\n## What Makes It Work\n\n**Breaking down complex work** — When facing a big task, create sparks for each piece. The structure helps you think.\n\n**Dependencies** — \"This blocks that.\" Know what's ready to work on, what's waiting. Never start something that can't finish.\n\n**discovered-from** — Working on spark A, find a bug? File it, link it back. Work sparks new work. Context preserved.\n\n**Low on context? File a spark.** — When you're running out of room to think, capture what you know in a spark. Future you (or future session) picks it up cleanly.\n\n**`ready`** — \"What can I work on?\" One command shows unblocked work. Empowering, not administrative.\n\n## Why Rebuild\n\nBeads nailed the UX. But SQLite + JSONL + daemon + sync = git surprises that interrupt flow.\n\nSparks: Same MCP interface, same mental model, but the storage just works. Commit sparks like code. No sync command. No daemon. No surprises.","design":"## Core: Same Interface, Simpler Storage\n\n```\n.sparks/\n  config.json                    # {\"prefix\": \"t42\"}\n  issues/{bucket}/{id}.json      # One file per spark\n```\n\nMCP server exposes identical tools:\n- `ready()` — unblocked work\n- `create(title, description, design, acceptance, deps, ...)` \n- `update(id, status, ...)` / `close(id)`\n- `show(id)` — full details with dependency graph\n- `dep(id, blocks_id, type)` — including `discovered-from`\n- `blocked()` — what's stuck and why\n\nLLM experience is identical. No relearning.\n\n## Dependency Types (Keep All)\n\n| Type | Meaning |\n|------|---------|\n| `blocks` | Hard blocker — must complete first |\n| `related` | Soft link — context, not blocking |\n| `parent-child` | Epic/subtask hierarchy |\n| `discovered-from` | \"Found this while working on that\" — work sparks new work |\n\n`discovered-from` is critical — it's how work ignites new work without losing the thread.\n\n## Why File-Per-Issue (Technical)\n\nSingle-file storage (JSONL/SQLite) fights git's merge model:\n\n**JSONL merge conflict:**\n```\n\u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD\n{\"id\":\"t42-5\",\"status\":\"closed\",\"notes\":\"Don't need X...\"}\n=======\n{\"id\":\"t42-5\",\"status\":\"in_progress\",\"notes\":\"X needs rethinking...\"}\n\u003e\u003e\u003e\u003e\u003e\u003e\u003e other\n```\nOne opaque line. Hard to see what differs. Easy to lose changes.\n\n**File-per-issue merge conflict:**\n```json\n\u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD\n  \"status\": \"closed\",\n  \"notes\": \"Don't need X...\"\n=======\n  \"status\": \"in_progress\",\n  \"notes\": \"X needs rethinking...\"\n\u003e\u003e\u003e\u003e\u003e\u003e\u003e other\n```\nScoped to one issue. You can *think* about the conflict. Other issues untouched.\n\nGit is designed for file-level merging. File-per-issue works *with* that grain. `bd sync` exists because JSONL/SQLite works *against* it.\n\n## Implementation\n\n~300 lines TypeScript MCP server. File I/O instead of SQLite. Same tool names, same parameters, same structured responses.\n\n## Migration\n\nOne-time script: read `.beads/issues.jsonl` → write `.sparks/issues/`","acceptance_criteria":"- [ ] MCP tools match beads: ready, list, show, create, update, close, dep, blocked, stats\n- [ ] All dependency types work, especially `discovered-from`\n- [ ] `ready` returns unblocked sparks (no open blockers)\n- [ ] LLM can use it exactly like beads — no prompting changes needed\n- [ ] Normal git workflow (add/commit/push) just works\n- [ ] Migration preserves all existing issues and dependencies\n- [ ] Workflow hooks prime context on session start","notes":"**2025-12-23 Review:**\n\nDiscussed with Claude whether this is worth building. \n\n**What's actually hard (the real product):**\n- The hooks — session priming, workflow guidance, context recovery\n- The friction-ablated API surface — Steve's \"ton of little tweaks\" are UX refinements, not bug fixes\n- The substantial prompting — teaching the LLM the workflow, making `ready` feel empowering not administrative\n- Getting the structured responses *just right* for LLM consumption\n\n**What's NOT hard (solved problems):**\n- Concurrent writes — atomic file writes, done\n- Partial write recovery — write-temp-then-rename, done\n- ID collision — deterministic generation, done\n- Bucketing for scale — minor\n- Invalid JSON recovery — minor\n\nThe insight: Sparks would be trivial to *build* but substantial to *refine*. The 300 lines of file I/O is real. The 100 commits of UX polish is also real.\n\n**Decision:** Keep using beads. It's slow and occasionally surprising, but the UX polish is already done. Texas 42 is the project car, not the task tracker.\n\nThis bead stays open as a \"someday maybe\" — if beads becomes unmaintained or the friction becomes blocking rather than annoying, revisit.","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-20T22:14:27.068505569-06:00","updated_at":"2025-12-23T15:52:37.447785837-06:00"}
{"id":"t42-864","title":"Refactor Room to new pattern","description":"Simplify Room to the new pattern where it takes a send function.\n\n**Reference**: docs/MULTIPLAYER.md\n\n**IMPORTANT**: This is roll forward / clean break / NO backwards compatibility whatsoever.\n\n**Changes to Room**:\n- Constructor takes `send: (clientId: string, message: ServerMessage) =\u003e void`\n- Remove all transport knowledge\n- Remove `players` Map cache (use mpState.players directly)\n- Remove `syncPlayersCache()`\n- Expose `handleConnect(clientId)`, `handleMessage(clientId, message)`, `handleDisconnect(clientId)` as primary API\n- Room doesn't know HOW to send - it just calls the send function\n\n**Result**: Room is transport-agnostic. Same code works for local and Cloudflare.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-25T14:54:43.268484797-06:00","updated_at":"2025-12-20T22:18:59.687015861-06:00","closed_at":"2025-11-25T15:36:58.52797438-06:00","dependencies":[{"issue_id":"t42-864","depends_on_id":"t42-don","type":"parent-child","created_at":"2025-11-25T14:55:14.269931345-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-864","depends_on_id":"t42-wdf","type":"blocks","created_at":"2025-11-25T14:55:15.135045236-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-8a66","title":"Minimax rollout is extremely slow (~21s per simulation)","description":"Use texas-42 skill.\n\n## Problem\n\nSingle minimax rollout during MCTS bid evaluation takes ~21 seconds. This makes the MCTS unusable for real-time play and prevents integration tests from running in reasonable time.\n\n## Evidence\n\n```\n$ npx tsx scratch/minimax-timing.ts\nEvaluating 1 bid action with 1 simulation...\nElapsed: 21192.66 ms\n```\n\nWith 14 bid options and 1 simulation each, that's ~5 minutes just for the bidding phase.\n\n## Root Cause\n\nThe `rolloutToHandEnd` function in `src/game/ai/monte-carlo.ts` uses full minimax search to terminal state:\n\n```typescript\nfunction rolloutToHandEnd(initialState, ctx) {\n  const result = minimaxEvaluate(initialState, ctx);\n  return createTerminalState(initialState, result);\n}\n```\n\nMinimax complexity is O(branching^depth) where:\n- Branching factor: ~4-5 legal plays per position\n- Depth: ~20-25 remaining actions per hand\n\n## Potential Solutions\n\n1. **Heuristic rollout** - Replace minimax with fast random/heuristic playouts (like traditional MCTS)\n2. **Depth-limited minimax** - Stop search at depth N and use evaluation function\n3. **Transposition table** - Cache evaluated positions\n4. **Move ordering** - Better alpha-beta pruning with killer moves\n5. **Parallel search** - Evaluate bid options concurrently\n\n## Blocked Issues\n\n- t42-b3h (Unskip slow MCTS test) - cannot run this test until perf is fixed","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-26T23:33:18.204832052-06:00","updated_at":"2025-12-26T23:33:18.204832052-06:00","labels":["ai","performance"]}
{"id":"t42-8d5","title":"Gate: Fix Code Coverage","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-20T09:11:44.010160018-06:00","updated_at":"2025-12-20T22:18:59.79425809-06:00"}
{"id":"t42-8ee","title":"Gate: Unleash Dijkstra's Principles","description":"Gate issue for the Dijkstra epic. When the team is ready to pursue architectural elegance over feature velocity, close this issue to unblock the refinement tasks.\n\nThis issue exists to prevent the Dijkstra issues from polluting the ready queue while preserving them for future consideration.","status":"open","priority":3,"issue_type":"task","created_at":"2025-11-29T12:10:04.880680757-06:00","updated_at":"2025-12-20T22:18:59.809389506-06:00"}
{"id":"t42-8it","title":"Code Duplication Elimination: Building a Crystal Palace","description":"Comprehensive refactoring to eliminate ~2,500 lines of code duplication across the codebase while preserving the pure functional architecture. This will reduce the codebase by 15-20% and dramatically improve maintainability. Total effort: 3-4 weeks.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-11-17T20:09:36.286303481-06:00","updated_at":"2025-12-20T22:18:59.700338027-06:00","closed_at":"2025-11-20T14:33:51.241928955-06:00","labels":["architecture","quality","refactoring"]}
{"id":"t42-8it.1","title":"Extract bidding completion logic from executeBid/executePass","description":"Eliminate 40+ lines of duplicated bidding completion logic in src/game/core/actions.ts between executeBid() (lines 102-159) and executePass() (lines 164-219). Create new bidding-utils.ts module with analyzeBiddingCompletion() function.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-17T20:09:45.088775155-06:00","updated_at":"2025-12-20T22:18:59.699417375-06:00","closed_at":"2025-11-19T21:32:37.247540959-06:00","labels":["core-logic","refactoring"]}
{"id":"t42-8it.10","title":"Consolidate test helpers and fixtures","description":"Merge duplicated test utilities from gameTestHelper.ts and game-states.ts. Extract common test patterns like executionContext creation, player setup, and domino creation into unified test helpers.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-17T20:10:50.307855765-06:00","updated_at":"2025-12-20T22:18:59.78937655-06:00","closed_at":"2025-11-20T11:46:32.849982113-06:00","labels":["refactoring","testing"]}
{"id":"t42-8it.11","title":"Extract AI hand strength calculation utilities","description":"Eliminate massive code duplication in hand-strength.ts (282 lines repeated in calculateHandStrength and analyze functions). Extract shared logic into reusable utilities.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-17T20:10:56.547616993-06:00","updated_at":"2025-12-20T22:18:59.69588946-06:00","closed_at":"2025-11-19T21:49:45.768435053-06:00","labels":["ai","refactoring"]}
{"id":"t42-8it.12","title":"Extract trump/suit validation patterns","description":"Consolidate repeated trump type checking patterns (trumpSuit \u003e= 0 \u0026\u0026 trumpSuit \u003c= 6) and domino suit checking (domino.high === suit || domino.low === suit) scattered across dominoes.ts, suit-analysis.ts, scoring.ts.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-17T20:11:04.91932542-06:00","updated_at":"2025-12-20T22:18:59.788664992-06:00","closed_at":"2025-11-20T08:12:58.888825368-06:00","labels":["core-logic","refactoring"]}
{"id":"t42-8it.2","title":"Create centralized played dominoes tracking utility","description":"Extract duplicated played domino tracking logic from handOutcome.ts (lines 17-29), suit-analysis.ts (lines 245-253), and domino-strength.ts (lines 78-84). Create new domino-tracking.ts module with DominoTracker class.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-17T20:09:52.111783302-06:00","updated_at":"2025-12-20T22:18:59.698576935-06:00","closed_at":"2025-11-19T21:39:04.38179101-06:00","labels":["core-logic","refactoring"]}
{"id":"t42-8it.3","title":"Consolidate game constants (suits, trumps, display names)","description":"Create centralized constants module for suit names, trump types, and display names. Currently duplicated in actions.ts, rules.ts, hints.ts and multiple other files. Create game-terms.ts with type-safe utilities.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-17T20:09:59.442173748-06:00","updated_at":"2025-12-20T22:18:59.791041972-06:00","closed_at":"2025-11-20T14:13:08.957567838-06:00","labels":["core-logic","refactoring"]}
{"id":"t42-8it.4","title":"Unify Plunge/Splash rulesets with factory pattern","description":"Eliminate 95% duplication (~150 lines each) between plunge.ts and splash.ts. Create doubles-bid-factory.ts with createDoublesBidRuleSet() factory that generates both rulesets from configuration.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-17T20:10:06.876148381-06:00","updated_at":"2025-12-20T22:18:59.697716547-06:00","closed_at":"2025-11-19T21:44:48.823294101-06:00","labels":["refactoring","rulesets"]}
{"id":"t42-8it.5","title":"Extract Sevens distance calculation helper","description":"Extract Math.abs(7 - (domino.high + domino.low)) calculation that appears 5 times in sevens.ts (lines 101, 108, 139, 141, 159). Create helper functions getDistanceFromSeven() and findClosestToSeven().","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-17T20:10:14.646613102-06:00","updated_at":"2025-12-20T22:18:59.830248826-06:00","closed_at":"2025-11-20T12:16:58.919878361-06:00","labels":["refactoring","rulesets"]}
{"id":"t42-8it.6","title":"Create unified test state factory (StateBuilder)","description":"Replace dozens of duplicated createTestState() functions across test files with a fluent StateBuilder API. Create state-builder.ts with preset methods for common scenarios (bidding, playing, withTricks).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-17T20:10:22.167090315-06:00","updated_at":"2025-12-20T22:18:59.696822976-06:00","closed_at":"2025-11-20T09:32:02.53718395-06:00","labels":["refactoring","testing"]}
{"id":"t42-8it.7","title":"Extract UI phase and trump display hooks","description":"Create Svelte 5 hooks for consistent phase/trump display across components. Currently duplicated in ActionPanel, Header, PlayingArea, and others. Create game-display.ts with createPhaseDisplay(), createTrumpDisplay() hooks.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-17T20:10:29.177479052-06:00","updated_at":"2025-12-20T22:18:59.790107274-06:00","closed_at":"2025-11-20T12:03:23.781889578-06:00","labels":["refactoring","ui"]}
{"id":"t42-8it.8","title":"Create domino sorting utility","description":"Extract duplicated domino sorting logic used in 3+ UI components. Create domino-sort.ts with sortDominoes() function supporting strategies: value, suit, doubles-first.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-17T20:10:36.211260455-06:00","updated_at":"2025-12-20T22:18:59.829519454-06:00","closed_at":"2025-11-20T12:17:00.112632479-06:00","labels":["refactoring","ui"]}
{"id":"t42-8it.9","title":"Create ActionTransformer meta object factory","description":"Extract duplicated meta object construction in ActionTransformers (oneHand.ts has 6+ instances, hints.ts, speed.ts). Create meta-utils.ts with MetaBuilder fluent API for type-safe meta creation.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-17T20:10:43.650457829-06:00","updated_at":"2025-12-20T22:18:59.828766949-06:00","closed_at":"2025-11-20T12:03:24.751635295-06:00","labels":["action-transformers","refactoring"]}
{"id":"t42-8mw","title":"Unify RuleSets and ActionTransformers into Layers","description":"Big bang migration to eliminate ActionTransformer redundancy and create unified Layer architecture. No backward compatibility - forward-only clean implementation.\n\n## Goals\n- Eliminate redundant ActionTransformer infrastructure\n- Unify RuleSet and ActionTransformer into single Layer concept\n- Merge split implementations (oneHand)\n- Clean, maintainable architecture with zero technical debt\n\n## Scope\n- ~50 files to modify\n- ~6 files to delete (entire action-transformers/ directory)\n- All tests must pass\n- No backward compatibility code","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-11-24T10:33:08.29406636-06:00","updated_at":"2025-12-20T22:18:59.690143714-06:00","closed_at":"2025-11-25T08:43:18.620638688-06:00"}
{"id":"t42-8mw.6","title":"Phase 22: Unify Layer Configuration + Rename composeActionGenerators","description":"Eliminate redundancy in layer configuration and clarify naming.\n\n## Goals\n1. Single unified `layers` field (delete `actionTransformers` and `enabledLayers`)\n2. Rename `composeActionGenerators` → `composeGetValidActions` (crystal clear)\n3. NO BACKWARD COMPAT - pure architecture\n\n## Tasks\n\n### 1. Rename Composition Function\n- `src/game/layers/compose.ts`: Rename `composeActionGenerators` → `composeGetValidActions`\n- Update JSDoc to clarify it composes Layer.getValidActions functions\n- Update all callers\n\n### 2. Unify Config Fields\n- `src/game/types/config.ts`: Replace `actionTransformers` and `enabledLayers` with single `layers?: string[]`\n- DELETE `ActionTransformerConfig` type entirely\n\n### 3. Simplify createExecutionContext\n- `src/game/types/execution.ts`: Use single `config.layers` field\n- Delete transformer/enabledLayers merging logic\n- Use `composeGetValidActions` (new name)\n\n### 4. Update URL Compression\n- `src/game/core/url-compression.ts`: DELETE `TRANSFORMER_CODES`\n- Single `l` parameter for all layers\n- DELETE `at` encoding/decoding\n\n### 5. Update All Usage Sites\n- `src/stores/gameStore.ts`: Use `layers: ['oneHand']`\n- ALL tests: Replace `enabledLayers`/`actionTransformers` with `layers`\n- Update exports in `src/game/layers/index.ts`\n\n### 6. Update Documentation\n- `docs/CONCEPTS.md`: Document unified `layers` field\n- Remove actionTransformer terminology\n\n## Success Criteria\n✅ `composeGetValidActions` name (clear)\n✅ Single `layers?: string[]` in GameConfig\n✅ oneHand specified ONCE\n✅ Clean URL encoding\n✅ All tests passing\n✅ Zero legacy code\n✅ Crystal palace pristine ✨","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T17:15:52.621265415-06:00","updated_at":"2025-12-20T22:18:59.757621978-06:00","closed_at":"2025-11-25T08:43:11.63549171-06:00"}
{"id":"t42-8qf","title":"Phase 5: Rename layer implementations","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.302953082-06:00","updated_at":"2025-12-20T22:18:59.777159082-06:00","closed_at":"2025-11-24T13:29:50.611361737-06:00","dependencies":[{"issue_id":"t42-8qf","depends_on_id":"t42-uf9","type":"blocks","created_at":"2025-11-24T10:35:46.170177894-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-8qf","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:50.517916488-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-8s1f","title":"Consolidate scoring helpers (avoid duplicate isGameComplete/getWinningTeam)","description":"Use texas-42 skill.\\n\\nThere are multiple similarly-named helpers for game completion/winner spread across modules (state.ts vs scoring.ts), with different signatures/semantics. This increases confusion and makes imports error-prone.\\n\\nEvidence:\\n- src/game/core/state.ts exports isGameComplete(state) + getWinningTeam(state)\\n- src/game/core/scoring.ts exports isGameComplete(teamMarks|team0, ...) + getWinningTeam(teamMarks, gameTarget)\\n- src/game/core/actions.ts imports isGameComplete from scoring, shadowing state.ts isGameComplete\\n\\nFix direction:\\n- Pick one naming scheme and one module of truth\\n- Rename one side (e.g., isMatchOver / isTargetReached) if needed\\n- Update exports in src/game/index.ts to avoid ambiguous names","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-27T00:30:23.943469328-06:00","updated_at":"2025-12-27T00:30:23.943469328-06:00","dependencies":[{"issue_id":"t42-8s1f","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:30:23.946820658-06:00","created_by":"jason"}]}
{"id":"t42-8v5","title":"Epic","description":"**ID**: mk5-tailwind-8mw","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T13:51:33.072224427-06:00","updated_at":"2025-12-20T22:18:59.768404377-06:00","closed_at":"2025-11-24T13:51:43.62778228-06:00"}
{"id":"t42-8z4t","title":"Profile PIMC: Manual DevTools inspection if automated pass inconclusive","description":"Use texas-42 skill.\n\n## Context\n\nDiscovered during t42-79h0. Only needed if automated profiling (call counters + summary stats) doesn't clearly identify the bottleneck.\n\n## When To Do This\n\n- Call counts from Phase 1 look reasonable but PIMC is still slow\n- Need to see where self-time is hiding within recursive `search()`\n- Want visual confirmation of bottleneck via flame chart\n\n## Steps\n\n1. Open the `.cpuprofile` generated by t42-79h0 in Chrome DevTools (F12 → Performance → Load profile)\n2. Go to **Bottom-up** tab, sort by **Self Time**\n3. Note any function with \u003e15% self-time\n4. Look at flame chart — screenshot the widest bars at the bottom of recursive towers\n5. Document findings\n\n## What You're Looking For\n\n- Fat bars at the leaf level of the flame chart (not `search` itself, but what it calls)\n- Functions with high self-time that didn't show up as high call-count in Phase 1\n- GC pauses visible as gaps in the flame chart\n\n## Acceptance Criteria\n\n- [ ] .cpuprofile from t42-79h0 opened in Chrome DevTools\n- [ ] Bottom-up view sorted by Self Time, top 5 functions noted\n- [ ] Flame chart screenshot saved showing the hot path\n- [ ] Findings documented: either confirms Phase 1 findings OR reveals new bottleneck","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-23T16:28:02.452680054-06:00","updated_at":"2025-12-23T16:28:02.452680054-06:00","labels":["ai","performance"],"dependencies":[{"issue_id":"t42-8z4t","depends_on_id":"t42-79h0","type":"discovered-from","created_at":"2025-12-23T16:28:22.692237789-06:00","created_by":"jason"}]}
{"id":"t42-8zpu","title":"GPU training data generator: complete regret tables (Python/CUDA)","description":"Use texas-42 skill.\n\nBuild a Python/CUDA solver that generates exhaustive training data for neural network training. Unlike the TypeScript solver (which only tracks optimal moves), this captures the **value of every legal move at every reachable state** - enabling exact regret computation for ML supervision.\n\n## Goal\n\nFor each (seed, declaration) pair, output a complete table:\n```\nFor every reachable state s:\n  For every legal domino d at s:\n    regret(s, d) = |V*(s) - V(apply(s, d))|\n```\n\nThis gives a neural network exact supervision: \"playing domino X in state S has regret Y.\"\n\n## Why Complete Coverage\n\n1. **No sampling bias**: Every situation the network might encounter is represented\n2. **Exact regrets**: No Monte Carlo estimation error\n3. **Rare positions**: Unusual game states are fully covered\n4. **Suboptimal play**: Learn what happens when opponents make mistakes\n\n## Output Schema\n\n### Parquet Format\n\n```python\nSCHEMA = {\n    'seed': uint32,           # Deal seed\n    'decl_id': uint8,         # 0-9 declaration type\n    'state_id': uint64,       # Packed state\n    'local_idx': uint8,       # 0-6 which domino\n    'regret': uint8,          # 0-84 cost of this move\n    'move_value': int8,       # -42 to +42 value after move\n    'optimal_value': int8,    # -42 to +42 best achievable\n    \n    # State features for direct ML input\n    'remaining_0': uint8,     # Player 0's hand (7-bit mask)\n    'remaining_1': uint8,\n    'remaining_2': uint8,\n    'remaining_3': uint8,\n    'team0_points': uint8,    # 0-42\n    'trick_leader': uint8,    # 0-3\n    'trick_len': uint8,       # 0-3\n}\n```\n\n### Example Rows\n\n```\nseed=12345, decl=3, local_idx=2, regret=0,  move_value=14, optimal=14  # Best move\nseed=12345, decl=3, local_idx=5, regret=6,  move_value=8,  optimal=14  # 6 points suboptimal\nseed=12345, decl=3, local_idx=6, regret=12, move_value=2,  optimal=14  # 12 points suboptimal\n```\n\n## Core Algorithm\n\n### Global Tables (constant memory, ~3 KB)\n\n```python\n# Same as TypeScript solver, precomputed once\nEFFECTIVE_SUIT[28][9]    # dominoId × absorptionId → led suit (0-7)\nSUIT_MASK[9][8]          # absorptionId × ledSuit → 28-bit follow mask\nTAU[10][8][28]           # declId × ledSuit × dominoId → τ value (6-bit)\nPOINTS[28]               # dominoId → {0, 5, 10}\n```\n\n### Per-Seed Tables (shared memory, ~20 KB)\n\n```python\nL[4][7]                  # playerId × localIdx → global dominoId\nFOLLOW_LOCAL[4][8]       # playerId × ledSuit → 7-bit local follow mask\nTRICK_WINNER[4][7][7][7][7]  # leader × i0 × i1 × i2 × i3 → winner playerId\nTRICK_POINTS[4][7][7][7][7]  # leader × i0 × i1 × i2 × i3 → points\n```\n\n### State Representation\n\n```python\n@dataclass\nclass State:\n    remaining: Tuple[int, int, int, int]  # 4 × 7-bit masks\n    team0_points: int                      # 0-42\n    leader: int                            # 0-3\n    current_player: int                    # 0-3\n    trick_len: int                         # 0-3\n    trick: Tuple[int, int, int, int]       # local indices in play order\n\ndef pack_state(s: State) -\u003e int:\n    \"\"\"Pack to 52-bit integer for array indexing.\"\"\"\n    return (\n        s.remaining[0] |\n        (s.remaining[1] \u003c\u003c 7) |\n        (s.remaining[2] \u003c\u003c 14) |\n        (s.remaining[3] \u003c\u003c 21) |\n        (s.team0_points \u003c\u003c 28) |\n        (s.leader \u003c\u003c 34) |\n        (s.current_player \u003c\u003c 36) |\n        (s.trick_len \u003c\u003c 38) |\n        (s.trick[0] \u003c\u003c 40) |\n        (s.trick[1] \u003c\u003c 43) |\n        (s.trick[2] \u003c\u003c 46) |\n        (s.trick[3] \u003c\u003c 49)\n    )\n```\n\n### Backward Induction with Full Move Values\n\n```python\ndef solve_seed(seed: int, decl_id: int) -\u003e Dict[int, Tuple[int, List[int]]]:\n    \"\"\"\n    Returns: {packed_state: (optimal_value, [move_values for local 0-6])}\n    \"\"\"\n    ctx = build_seed_context(seed, decl_id)\n    states_by_level = enumerate_reachable_states(ctx)\n    \n    V = {}           # packed_state → optimal value\n    MoveValues = {}  # packed_state → [value for each of 7 local indices]\n    \n    # Terminal states (level 0: no dominoes remaining)\n    for s in states_by_level[0]:\n        key = pack_state(s)\n        V[key] = 2 * s.team0_points - 42\n        MoveValues[key] = [-128] * 7  # No moves at terminal\n    \n    # Backward from level 1 to 28\n    for level in range(1, 29):\n        for s in states_by_level.get(level, []):\n            key = pack_state(s)\n            legal = get_legal_mask(s, ctx)\n            team0_turn = s.current_player % 2 == 0\n            \n            move_vals = [-128] * 7  # -128 = illegal\n            best = -43 if team0_turn else +43\n            \n            for local_idx in range(7):\n                if not (legal \u003e\u003e local_idx) \u0026 1:\n                    continue\n                    \n                child = apply_move(s, local_idx, ctx)\n                child_val = V[pack_state(child)]\n                move_vals[local_idx] = child_val\n                \n                if team0_turn:\n                    best = max(best, child_val)\n                else:\n                    best = min(best, child_val)\n            \n            V[key] = best\n            MoveValues[key] = move_vals\n    \n    return {k: (V[k], MoveValues[k]) for k in V}\n```\n\n## GPU Parallelism\n\n### Three Levels of Parallelism\n\n1. **Across seeds**: Each seed independent → different GPU blocks\n2. **By level**: All states at same level processed in parallel\n3. **Per state**: All 7 move values computed simultaneously\n\n### CUDA Kernel Structure\n\n```cuda\n__global__ void backward_induction_level(\n    const uint64_t* states,       // States at this level\n    int num_states,\n    const int8_t* V_prev,         // Values from lower levels (already computed)\n    int8_t* V_out,                // Output values for this level\n    int8_t* move_values_out,      // Output: 7 values per state\n    const uint8_t* ctx            // Seed context in constant/shared memory\n) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx \u003e= num_states) return;\n    \n    State s = unpack_state(states[idx]);\n    int legal = get_legal_mask(s, ctx);\n    bool team0 = s.current_player % 2 == 0;\n    int8_t best = team0 ? -43 : 43;\n    \n    for (int m = 0; m \u003c 7; m++) {\n        if (!((legal \u003e\u003e m) \u0026 1)) {\n            move_values_out[idx * 7 + m] = -128;\n            continue;\n        }\n        \n        State child = apply_move(s, m, ctx);\n        int8_t cv = V_prev[pack_state(child)];\n        move_values_out[idx * 7 + m] = cv;\n        \n        best = team0 ? max(best, cv) : min(best, cv);\n    }\n    \n    V_out[pack_state(s)] = best;\n}\n```\n\n### Memory Layout\n\nPer seed during solve:\n- Value table: ~3M states × 1 byte = 3 MB\n- Move values: ~3M states × 7 bytes = 21 MB\n- Seed context: ~20 KB\n- **Total: ~25 MB per seed**\n\nWith 24 GB GPU: ~100 seeds in parallel with headroom\n\n## Performance Targets\n\n| Metric | Target |\n|--------|--------|\n| Time per seed | \u003c 20 ms |\n| Seeds in parallel | 100+ |\n| Throughput | 500+ seeds/second |\n| 1M seeds × 10 declarations | \u003c 6 hours |\n\n## Storage Estimates\n\n| Scale | Compressed Size |\n|-------|-----------------|\n| 1 seed | ~5 MB |\n| 1K seeds | ~5 GB |\n| 1M seeds | ~5 TB |\n| 1M seeds × 10 declarations | ~50 TB |\n\n## Implementation Structure\n\n```\npython/\n├── solver/\n│   ├── __init__.py\n│   ├── tables.py           # Global table generation\n│   ├── context.py          # Per-seed context building\n│   ├── enumerate.py        # State enumeration\n│   ├── kernels.cu          # CUDA kernels\n│   ├── solve.py            # Main solve logic\n│   └── io.py               # Parquet I/O\n├── generate.py             # CLI for batch generation\n└── analyze.py              # Regret distribution analysis\n```\n\n## CLI Interface\n\n```bash\n# Generate training data\npython generate.py --start-seed 0 --num-seeds 10000 --output-dir ./data\n\n# Analyze regret distributions\npython analyze.py ./data/batch_*.parquet\n\n# Verify against TypeScript solver\npython verify.py --seed 12345 --decl 3\n```\n\n## Verification\n\n1. Compare root values against TypeScript solver for sample seeds\n2. Verify regret=0 for optimal moves matches TypeScript's Move table\n3. Check that sum of move counts equals expected (legal moves per state)\n4. Validate parquet schema and compression ratios","design":"## Architecture\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                    Host (Python)                         │\n├─────────────────────────────────────────────────────────┤\n│  generate.py                                             │\n│    └── for batch in batches:                            │\n│          seeds = load_batch_seeds()                     │\n│          results = solve_batch_gpu(seeds)               │\n│          write_parquet(results)                         │\n└─────────────────────────────────────────────────────────┘\n                          │\n                          ▼\n┌─────────────────────────────────────────────────────────┐\n│                    GPU (CUDA)                            │\n├─────────────────────────────────────────────────────────┤\n│  Constant Memory: EFFECTIVE_SUIT, SUIT_MASK, TAU, POINTS│\n│                                                          │\n│  Per-Seed (Shared Memory):                              │\n│    L, FOLLOW_LOCAL, TRICK_WINNER, TRICK_POINTS          │\n│                                                          │\n│  Global Memory (per seed):                              │\n│    V[3M] - optimal values                               │\n│    MoveValues[3M][7] - all move values                  │\n└─────────────────────────────────────────────────────────┘\n                          │\n                          ▼\n┌─────────────────────────────────────────────────────────┐\n│                    Output                                │\n├─────────────────────────────────────────────────────────┤\n│  batches/                                                │\n│    batch_00000000.parquet  (100 seeds × 10 decls)       │\n│    batch_00000100.parquet                               │\n│    ...                                                   │\n└─────────────────────────────────────────────────────────┘\n```\n\n## Key Differences from TypeScript Solver\n\n| Aspect | TypeScript | Python/GPU |\n|--------|-----------|------------|\n| Output | Best move only | All 7 move values |\n| Purpose | Real-time AI | Training data |\n| Speed | ~5s/seed | ~15ms/seed |\n| Parallelism | Single-threaded | 100+ seeds |\n| Language | TypeScript | Python + CUDA |\n\n## Data Flow\n\n```\nSeed + Declaration\n        │\n        ▼\n┌───────────────────┐\n│ build_context()   │  → L, FOLLOW_LOCAL, TRICK_WINNER, TRICK_POINTS\n└───────────────────┘\n        │\n        ▼\n┌───────────────────┐\n│ enumerate_states()│  → states_by_level[0..28]\n└───────────────────┘\n        │\n        ▼\n┌───────────────────┐\n│ backward_induction│  → V[state], MoveValues[state][0..6]\n│ (GPU kernel)      │\n└───────────────────┘\n        │\n        ▼\n┌───────────────────┐\n│ flatten_to_rows() │  → (state, local_idx, regret, move_value, optimal)\n└───────────────────┘\n        │\n        ▼\n┌───────────────────┐\n│ write_parquet()   │  → batch_XXXXXXXX.parquet\n└───────────────────┘\n```","acceptance_criteria":"- [ ] Global tables (TAU, POINTS) generated correctly, match TypeScript\n- [ ] Per-seed context (TRICK_WINNER, TRICK_POINTS) matches TypeScript solver\n- [ ] State enumeration covers all reachable states\n- [ ] Backward induction produces correct optimal values (verified against TS)\n- [ ] All 7 move values stored per state (not just optimal)\n- [ ] Regret = |optimal - move_value| computed correctly\n- [ ] Parquet output with correct schema\n- [ ] GPU kernel runs without errors\n- [ ] Throughput \u003e 500 seeds/second on RTX 3090/4090\n- [ ] Memory usage \u003c 25 MB per seed\n- [ ] Handles all 10 declaration types\n- [ ] Nello support (3-player tricks, partner skip)\n- [ ] CLI for batch generation works\n- [ ] Verification script confirms parity with TypeScript solver","notes":"## CRITICAL: GPU-ONLY SOLVER\n\n**This is a GPU solver. Not CPU. If GPU doesn't work, we STOP and change the plan.**\n\nNo CPU fallback. No \"run overnight on CPU\". Either it works on GPU or we reassess the approach entirely.\n\n---\n\n## Key Findings\n\n### State Count: ~90M (not ~3M as documented)\n- Doc estimated ~3M states per seed\n- Reality: ~90M states (includes mid-trick states)\n- This changes memory requirements significantly\n\n### Memory Reality (RTX 3050, 4GB VRAM)\n- 90M states × 1 byte (value) = 90MB\n- 90M states × 7 bytes (move values) = 630MB\n- Total: ~720MB for values alone - **fits in 4GB**\n- Plus state enumeration structures\n\n### Architecture: Bottom-Up DP (per docs/SOLVER_GPU_TRAINING.md)\nThe doc correctly describes level-by-level backward induction:\n```python\nfor level in range(28, -1, -1):\n    parallel_for state in states_at_level[level]:\n        compute_values(state)  # GPU kernel\n```\n\nThis is NOT minimax. Children are already solved before processing their parents.\n\n---\n\n## Implementation Requirements\n\n### 1. Crash Resistance (MANDATORY)\n- Enumerate states to disk FIRST (sharded files)\n- Checkpoint after each level completes\n- Can resume from any level on restart\n- Never lose more than one level's work\n\n### 2. GPU Kernel Design\n- One kernel launch per level\n- All states at level N processed in parallel\n- Child values already in GPU memory (levels 0..N-1)\n- No hash tables - contiguous array indexing only\n\n### 3. Memory Management\n- Load one level at a time if needed\n- Write completed levels to disk\n- GPU memory: current level + child values lookup\n\n### 4. Output Format\n- Sharded output files (one per level or fixed size)\n- Combinable after completion\n- JSON or Parquet, gzip compressed\n\n---\n\n## Files Created (reference only, may need rewrite)\n```\nscripts/solver/\n├── tables.py         ✓ Global tables (reusable)\n├── deal.py           ✓ Seeded RNG (reusable)\n├── context.py        ✓ Per-seed precomputation (reusable)\n├── state.py          ✓ 52-bit packed state (reusable)\n├── solve.py          ✗ CPU recursive - NOT USED\n├── solve_*.py        ✗ CPU variants - NOT USED\n└── solve_gpu.py      ✗ TODO: proper GPU DP solver\n```\n\n---\n\n## Next Steps\n\n1. **Enumerate all states to disk** (sharded, checkpointed)\n2. **Build level index** (group states by dominoes remaining)\n3. **Write CuPy GPU kernel** for level-by-level solve\n4. **Test one seed end-to-end** on GPU\n5. **Verify against known values**\n\n---\n\n## Failure Mode\n\nIf GPU approach fails (memory, performance, correctness):\n- STOP\n- Do NOT fall back to CPU\n- Reassess: different algorithm, different hardware, or abandon","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-27T00:41:20.387862773-06:00","updated_at":"2025-12-27T09:56:28.567393819-06:00","closed_at":"2025-12-27T09:56:28.567393819-06:00","close_reason":"Superseded by t42-fe6f (PyTorch-native fully-GPU approach)"}
{"id":"t42-911","title":"Unify renege-validation tests with dealConstraints after pip/suit fix","description":"Use texas-42 skill.\n\n## Context\n\nDuring the dealConstraints assessment (mk5-tailwind-jdb), renege-validation.test.ts could not be refactored to use constraints because the constraint system operates on pip values while renege rules need game-suit awareness.\n\n## Task\n\nAfter mk5-tailwind-lfy (pip-value vs game-suit fix) is resolved:\n\n1. Revisit `src/tests/rules/renege-validation.test.ts`\n2. Assess whether constraints can now express renege test scenarios\n3. If yes, refactor tests to use `.withPlayerConstraint()` for consistency\n4. If no (design decision to keep distinction), document why exact hands are necessary\n\n## Success Criteria\n\n- All renege tests use the most appropriate pattern (constraints OR exact hands)\n- Decision is documented in code comments\n- Test suite remains green\n\n## Related\n\n- Blocked by: mk5-tailwind-lfy (pip/suit fix)\n- Context: mk5-tailwind-jdb (original assessment)","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-28T22:35:42.709713336-06:00","updated_at":"2025-12-20T22:18:59.8150649-06:00","closed_at":"2025-11-29T10:10:29.179373367-06:00","labels":["dx","followup","testing"],"dependencies":[{"issue_id":"t42-911","depends_on_id":"t42-lfy","type":"blocks","created_at":"2025-11-28T22:35:42.712629522-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"t42-9an8","title":"Make actionToId/actionToLabel exhaustive (fix URL 'unknown' events)","description":"Use texas-42 skill.\\n\\nactionToId() and actionToLabel() are not exhaustive for the GameAction union. Missing IDs lead to 'unknown' action IDs, which then become '~?' in URL compression and 'unknown' during decode, breaking replay determinism and UI keying.\\n\\nEvidence:\\n- src/game/types.ts includes 'retry-one-hand' and 'new-one-hand' actions\\n- src/game/core/actions.ts executeAction() handles them\\n- src/game/core/actions.ts actionToId/actionToLabel do not handle them (fall through to 'unknown')\\n- src/game/core/url-compression.ts compressEvents warns on unknown event and emits '~?'\\n\\nFix direction:\\n- Make actionToId/actionToLabel exhaustive over GameAction (ideally switch + assertNever)\\n- Extend URL compression mapping or explicitly error for non-serializable actions\\n- Update any callers that assume action ids are always in EVENT_TO_CHAR","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-27T00:30:00.621858102-06:00","updated_at":"2025-12-27T00:30:00.621858102-06:00","dependencies":[{"issue_id":"t42-9an8","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:30:00.626491134-06:00","created_by":"jason"}]}
{"id":"t42-9bz","title":"[Architecture \u0026 Code Quality] Investigate why we have a backwards-compatibility test","description":"The file `src/tests/layers/edge-cases/backward-compatibility.test.ts` exists to test \"layer interface stability\", \"rule method signatures\", \"action structure\", etc.\n\nPer CLAUDE.md philosophy, this is a greenfield project with \"no legacy\" - everything should be unified. A backwards-compatibility test seems counter to that philosophy.\n\nInvestigate:\n1. What is this test trying to preserve compatibility with?\n2. Should it be deleted entirely, or absorbed into other tests?\n3. Is this just testing the public API shape (which other tests already cover)?","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-27T00:47:12.235758274-06:00","updated_at":"2025-12-20T22:18:59.748818172-06:00","closed_at":"2025-11-29T10:50:33.642032308-06:00","dependencies":[{"issue_id":"t42-9bz","depends_on_id":"t42-ade","type":"parent-child","created_at":"2025-11-28T10:14:52.330535963-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-9cg","title":"Integrate MCCFR training into build pipeline with named difficulty models","description":"Use texas-42 skill.\n\n## Goal\nMake MCCFR model training a formal part of the build pipeline with support for multiple named models at different difficulty levels.\n\n## Requirements\n\n### Named Models\n- Models have a name (e.g., \"beginner\", \"intermediate\", \"expert\", \"master\")\n- Name is an input to the training pipeline: `npm run train:mccfr -- --name expert --iterations 1000000`\n- Each model has its own iteration count and potentially other config\n\n### File Structure\n```\nmodels/\n  .gitignore           # Ignore training artifacts\n  beginner.cfd2.gz     # Checked in - final compressed model\n  intermediate.cfd2.gz\n  expert.cfd2.gz\n  \nscratch/               # Already gitignored\n  beginner-training.json    # Full training data (not checked in)\n  intermediate-training.json\n  expert-training.json\n```\n\n### Build Pipeline Integration\n\n1. **Training script** (`scripts/train-model.ts`):\n   - `--name \u003cmodel-name\u003e` - Required model name\n   - `--iterations \u003cn\u003e` - Training iterations\n   - `--output-dir models/` - Where to save final model\n   - Saves intermediate checkpoints to scratch/\n   - Converts final output to CFD2 format automatically\n\n2. **npm scripts**:\n   ```json\n   {\n     \"train:model\": \"npx tsx scripts/train-model.ts\",\n     \"train:beginner\": \"npm run train:model -- --name beginner --iterations 10000\",\n     \"train:intermediate\": \"npm run train:model -- --name intermediate --iterations 100000\",\n     \"train:expert\": \"npm run train:model -- --name expert --iterations 1000000\"\n   }\n   ```\n\n3. **Opt-in training**: Training is manual, not part of `npm run build`\n   - Models are pre-trained and checked into git\n   - Developers only retrain if they change the training algorithm\n\n### Model Loading at Runtime\n- Load models by name: `loadStrategy('expert')`\n- Fall back to lower difficulty if model not found\n- Support browser loading (fetch from public assets)\n\n## Success Criteria\n- [ ] Named model support in training pipeline\n- [ ] Training artifacts (full JSON) gitignored, only CFD2 checked in\n- [ ] npm scripts for common difficulty levels\n- [ ] Runtime model loading by name\n- [ ] Documentation for adding new difficulty levels","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-08T19:02:05.511735067-06:00","updated_at":"2025-12-20T22:18:59.718453028-06:00","closed_at":"2025-12-20T22:05:59.926320552-06:00","close_reason":"MCCFR removed from codebase","dependencies":[{"issue_id":"t42-9cg","depends_on_id":"t42-d6g","type":"parent-child","created_at":"2025-12-20T08:52:15.138382039-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-9cg","depends_on_id":"t42-tgr","type":"blocks","created_at":"2025-12-20T08:53:18.101861206-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-9ed","title":"Fix PIMC: eliminate 'depressed android' play","description":"Use texas-42 skill.\n\nThe Monte Carlo AI (PIMC) makes defeatist plays when losing - dumping count because 'we're losing anyway.' Fix this by replacing heuristic rollouts with minimax.\n\n## Correct Terminology\n\nThis is **PIMC (Perfect Information Monte Carlo)**, NOT MCTS:\n- Determinizes hidden opponent hands via constraint-based sampling\n- Evaluates candidate plays by simulating to hand completion\n- Currently uses **heuristic rollouts** (greedy per-trick decisions)\n\n## Problem\n\nHeuristic rollout (rollout-strategy.ts) is greedy:\n- If partner winning: dump highest points\n- If opponent winning: try to win, or dump lowest\n\nThis can't see future tricks. When losing:\n- Option A (fight): avg 18 pts, lose 80%\n- Option B (give up): avg 15 pts, lose 95%\n\nBoth look similarly bad → AI might pick \"give up\".\n\n## Solution: PIMC + Minimax\n\nReplace heuristic rollouts with **full minimax to hand completion**:\n1. Alpha-beta pruning for efficiency\n2. Searches all remaining tricks (no depth limit)\n3. Returns game-theoretic optimal outcome\n4. No heuristic evaluation function - searches to terminal state\n\n## Files to Change\n\n- NEW: `src/game/ai/minimax.ts` - Core minimax with alpha-beta\n- MODIFY: `src/game/ai/monte-carlo.ts` - Use minimax instead of heuristic rollout\n- DELETE: `src/game/ai/rollout-strategy.ts` - No longer needed\n- NEW: `src/tests/ai/minimax.test.ts` - Unit tests\n\n## Implementation Details\n\n### minimax.ts Interface\n\n```typescript\nexport interface MinimaxConfig {\n  maxDepth?: number;        // Default: Infinity (to hand end)\n  alphaBeta?: boolean;      // Default: true\n  moveOrdering?: 'none' | 'points-first' | 'trump-first';\n}\n\nexport interface MinimaxResult {\n  team0Points: number;\n  team1Points: number;\n  nodesExplored: number;\n}\n\nexport function minimaxEvaluate(\n  state: GameState,\n  ctx: ExecutionContext,\n  config?: MinimaxConfig\n): MinimaxResult;\n```\n\n### Core Algorithm\n\n4-player partnership minimax:\n- Players 0,2 (Team 0) = MAX\n- Players 1,3 (Team 1) = MIN (from Team 0's perspective)\n\n```\nminimaxSearch(state, alpha, beta, isMaximizing):\n  if hand complete:\n    return state.teamScores[0]  // Actual points, no heuristic\n  \n  // Handle auto-execute actions (complete-trick, etc.)\n  if autoAction exists:\n    return minimaxSearch(executeAction(state, autoAction), ...)\n  \n  // Early termination\n  if ctx.rules.checkHandOutcome(state).isDetermined:\n    return state.teamScores[0]\n  \n  orderedActions = orderMoves(playActions, state)\n  \n  if isMaximizing:\n    maxEval = -Infinity\n    for action in orderedActions:\n      eval = minimaxSearch(executeAction(state, action), ...)\n      maxEval = max(maxEval, eval)\n      alpha = max(alpha, eval)\n      if beta \u003c= alpha: break  // Prune\n    return maxEval\n  else:\n    minEval = Infinity\n    for action in orderedActions:\n      eval = minimaxSearch(executeAction(state, action), ...)\n      minEval = min(minEval, eval)\n      beta = min(beta, eval)\n      if beta \u003c= alpha: break  // Prune\n    return minEval\n```\n\n### Move Ordering (for pruning efficiency)\n\n```\nWhen leading: non-count dominoes first (save count)\nWhen following:\n  1. Winning plays first (can beat current trick)\n  2. Among winners: lower value first (efficient win)\n  3. Among losers: lower points first (minimize loss)\n```\n\n### Integration with monte-carlo.ts\n\nReplace `rolloutToHandEnd()` body:\n\n```typescript\nfunction rolloutToHandEnd(initialState, ctx) {\n  const result = minimaxEvaluate(initialState, ctx);\n  return {\n    ...initialState,\n    phase: 'scoring',\n    teamScores: [result.team0Points, result.team1Points],\n    currentTrick: [],\n    players: initialState.players.map(p =\u003e ({ ...p, hand: [] })),\n  };\n}\n```\n\nRemove `getRolloutStrategy` import.\n\n## Performance\n\n- Per minimax call: 0.5-5ms (7 tricks, ~3-7 branching, alpha-beta prunes)\n- Per PIMC decision: ~3-30 seconds (vs ~600ms currently)\n- Acceptable for \"thinking\" AI tier\n\n## Test Cases\n\n1. Trivial endgame (1 trick remaining) - verify correct winner\n2. Position where heuristic loses but minimax wins\n3. Alpha-beta verification (compare node counts with/without)\n4. Special contracts (nello, sevens) work correctly\n5. Performance benchmark (~100-500 nodes per call expected)\n\n## Success Criteria\n\n- AI doesn't dump count when losing\n- AI 'fights' even when behind (finds lines that could win)\n- Minimax returns provably optimal play within each sampled world","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T20:48:12.489576218-06:00","updated_at":"2025-12-21T21:16:30.268697621-06:00","closed_at":"2025-12-21T21:16:30.268697621-06:00","close_reason":"Implemented minimax with alpha-beta pruning to replace heuristic rollouts in PIMC. All tests pass.","dependencies":[{"issue_id":"t42-9ed","depends_on_id":"t42-d6g","type":"blocks","created_at":"2025-12-20T08:58:29.473982834-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-9re","title":"Priority","description":"P2 - Polish work, non-breaking but important for codebase clarity","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T16:24:26.902690059-06:00","updated_at":"2025-12-20T22:18:59.759810224-06:00","closed_at":"2025-11-25T08:55:05.391014546-06:00"}
{"id":"t42-9wn","title":"Extract action generator from base layer","description":"Use texas-42 skill.\n\nbase.ts has circular self-reference: composeRules([baseLayer]) called within generateStructuralActions. The base layer is both a layer definition AND an action generator.\n\nFiles: src/game/layers/base.ts","design":"## The Circular Dependency: A Dijkstra Analysis\n\n### I. THE CRIME: EXACT LOCATION OF CIRCULARITY\n\n**File:** `src/game/layers/base.ts`\n**Lines:** 35-61, specifically line 139\n\nThe offense:\n```typescript\n// Line 35-38: Function signature\nexport function generateStructuralActions(\n  state: GameState,\n  rules?: GameRules\n): GameAction[] {\n\n// Line 139: The circular self-reference\nconst threadedRules = rules || composeRules([baseLayer]);\n```\n\nThis is a *self-referential definition*. The `baseLayer` constant (defined at line 211) contains a reference to `generateStructuralActions` through the composition chain, and `generateStructuralActions` contains a reference back to `baseLayer`. The symbol `baseLayer` is defined in terms of a function that references `baseLayer` itself.\n\nIn mathematical terms: Let B = baseLayer, G = generateStructuralActions\n- B contains G (implicitly, through the composition system)\n- G contains B (explicitly, line 139)\n- Therefore: B contains B\n\nThis is precisely what Dijkstra would call an \"architectural failure\" - a tangled knot that violates the principle of hierarchical composition.\n\n### II. WHY THE CIRCULARITY EXISTS: ROOT CAUSE ANALYSIS\n\nThe circularity exists because `generateStructuralActions` has a *dual responsibility*:\n\n1. **Structural action generation** (its primary purpose): Generate the skeleton of available actions (pass, redeal, trump selections, plays)\n2. **Play validation** (line 120-150): Determine which dominoes are valid plays for the current player\n\nThe problem occurs in `getPlayingActions`:\n```typescript\n// Lines 120-150\nfunction getPlayingActions(state: GameState, rules?: GameRules): GameAction[] {\n  // ...\n  const isTrickComplete = rules ? rules.isTrickComplete(state) : state.currentTrick.length === 4;\n  \n  if (isTrickComplete) {\n    // Simple structural action\n    actions.push({ type: 'complete-trick', ... });\n    return actions;\n  }\n\n  // HERE IS THE PROBLEM:\n  // To generate play actions, we need to validate which dominoes are legal\n  const threadedRules = rules || composeRules([baseLayer]);\n  const validPlays = threadedRules.getValidPlays(state, state.currentPlayer);\n  \n  // Convert valid dominoes to play actions\n  validPlays.forEach((domino: Domino) =\u003e {\n    actions.push({ type: 'play', player: state.currentPlayer, dominoId: domino.id.toString() });\n  });\n}\n```\n\n**The essential question:** Why does action generation need composed rules?\n\n**Answer:** Because determining which play actions are valid requires consulting the rule system's `getValidPlays` method. But `getValidPlays` is defined *inside the very layer we're trying to compose*.\n\n### III. THE DEPENDENCY INVERSION\n\nThe composition system creates this flow:\n\n```\ncreateExecutionContext (execution.ts:38)\n  ├─\u003e composeRules([baseLayer, ...]) (execution.ts:56)\n  │     └─\u003e Creates GameRules with baseLayer.rules.getValidPlays\n  │\n  └─\u003e generateStructuralActions(state, rules) (execution.ts:59)\n        └─\u003e When called, needs rules.getValidPlays\n              └─\u003e Falls back to composeRules([baseLayer]) if rules not provided\n                    └─\u003e CIRCULAR REFERENCE\n```\n\nNotice the asymmetry: \n- When called FROM `createExecutionContext`, `rules` is provided (line 59)\n- When called FROM other contexts (tests, AI utilities), `rules` may be undefined\n- The fallback `composeRules([baseLayer])` creates the circle\n\n### IV. THE ARCHITECTURAL FAILURE\n\nDijkstra would identify this as a violation of the **Separation of Concerns** principle:\n\n**Current (WRONG):**\n```\ngenerateStructuralActions\n  ├─\u003e Generate skeleton actions (PRIMARY CONCERN)\n  └─\u003e Validate play legality (SECONDARY CONCERN - should be elsewhere)\n        └─\u003e Requires composed rules (CIRCULAR)\n```\n\nThe action generator should be **pure structural logic**:\n- \"There exists a set of possible actions\"\n- \"The set includes: pass, bids, trump selections, plays, trick completion\"\n\nIt should NOT:\n- \"Determine which specific plays are valid\" (this is validation logic)\n- \"Consult the rule system\" (this is execution logic)\n\n**Dijkstra's Principle:** *\"Separation of concerns is the key to managing complexity.\"*\n\nThe generator has leaked into the validator's domain.\n\n### V. PROPOSED EXTRACTION: CLEAN SEPARATION\n\n**Principle:** Action generation is structurally simple and should not depend on validation rules.\n\n**Solution:** Extract play validation OUT of `generateStructuralActions`.\n\n#### Before (Current):\n```typescript\ngenerateStructuralActions(state, rules?) → GameAction[]\n  ├─\u003e Uses rules.getValidPlays() to filter plays\n  └─\u003e Fallback: composeRules([baseLayer]) 【CIRCULAR】\n```\n\n#### After (Proposed):\n```typescript\n// LAYER 1: Pure structural generation (NO validation, NO rules)\ngenerateStructuralActions(state) → GameAction[]\n  ├─\u003e Bidding: [{ type: 'pass' }]  // Bids added by layers\n  ├─\u003e Trump selection: [all trump options]  // Layers filter\n  ├─\u003e Playing: [ALL dominoes in hand]  // Validation happens elsewhere\n  └─\u003e Scoring: [{ type: 'score-hand' }]\n\n// LAYER 2: Validation (uses composed rules)\nfilterValidActions(state, actions, rules) → GameAction[]\n  └─\u003e For play actions: use rules.getValidPlays() to filter\n\n// COMPOSITION (in execution.ts)\nconst base = (state) =\u003e generateStructuralActions(state);  // No rules needed\nconst validated = (state) =\u003e filterValidActions(state, base(state), rules);\nconst final = composeGetValidActions(layers, validated);\n```\n\n### VI. THE NEW STRUCTURE\n\n**File structure:**\n```\nsrc/game/layers/\n  ├─ base.ts\n  │   ├─ baseLayer (Layer definition with rules)\n  │   └─ [NO generateStructuralActions - moved out]\n  │\n  ├─ structural-actions.ts [NEW]\n  │   └─ generateStructuralActions(state) → GameAction[]\n  │        • Pure, no rules dependency\n  │        • Generates ALL possible structural actions\n  │        • No validation logic\n  │\n  └─ compose.ts\n      ├─ composeRules(layers) → GameRules\n      ├─ composeGetValidActions(layers, base)\n      └─ filterValidActions(state, actions, rules) [NEW]\n           • Applies validation rules to filter actions\n           • Uses rules.getValidPlays for play actions\n           • Uses rules.isValidBid for bid actions\n```\n\n**Dependency flow (no circles):**\n```\nstructural-actions.ts  (NO dependencies on layers)\n        ↓\nbase.ts  (imports structural-actions? NO - doesn't need it)\n        ↓\ncompose.ts  (imports base.ts, creates rules)\n        ↓\nexecution.ts  (imports structural-actions, compose)\n        ↓\n    Creates flow:\n    generateStructuralActions → filterValidActions(rules) → layerTransforms\n```\n\n### VII. IMPLEMENTATION STEPS\n\n1. **Create `src/game/layers/structural-actions.ts`**\n   - Move `generateStructuralActions` and helper functions\n   - Remove `rules` parameter entirely\n   - For playing phase: generate play actions for ALL dominoes in current player's hand\n   - No validation, no filtering\n\n2. **Update `src/game/layers/compose.ts`**\n   - Add `filterValidActions(state, actions, rules)` helper\n   - For each action type, apply appropriate validation:\n     * `play`: Filter using `rules.getValidPlays()`\n     * `bid`: Filter using `rules.isValidBid()`\n     * Others: Pass through unchanged\n\n3. **Update `src/game/types/execution.ts`**\n   - Import from `structural-actions.ts` instead of `base.ts`\n   - Compose validation into the pipeline:\n     ```typescript\n     const base = (state) =\u003e generateStructuralActions(state);\n     const validated = (state) =\u003e filterValidActions(state, base(state), rules);\n     const final = composeGetValidActions(layers, validated);\n     ```\n\n4. **Update all imports**\n   - Change `import { generateStructuralActions } from './layers/base'`\n   - To: `import { generateStructuralActions } from './layers/structural-actions'`\n\n5. **Remove from `base.ts`**\n   - Delete `generateStructuralActions` and helpers\n   - The baseLayer definition remains, but is now purely a Layer definition\n\n### VIII. VERIFICATION OF CORRECTNESS\n\nAfter extraction, verify:\n\n1. **No circular dependencies:**\n   ```bash\n   npx madge --circular src/game/layers/\n   ```\n\n2. **Structural purity:**\n   - `generateStructuralActions` has NO dependency on any Layer\n   - It can be called with state alone\n   - All validation is deferred to composition pipeline\n\n3. **Functional equivalence:**\n   - All existing tests pass\n   - Action generation produces same results\n   - The pipeline now has explicit stages: generate → validate → transform\n\n### IX. THE DIJKSTRA PRINCIPLE\n\n*\"The purpose of abstraction is not to be vague, but to create a new semantic level in which one can be absolutely precise.\"*\n\nCurrent code is vague about responsibility boundaries:\n- Is `generateStructuralActions` a generator or a validator?\n- Does it need rules or not?\n- Where does validation happen?\n\nAfter extraction:\n- `generateStructuralActions`: Pure generator. Input: state. Output: structural actions. Period.\n- `filterValidActions`: Pure validator. Input: state + actions + rules. Output: valid actions. Period.\n- `composeGetValidActions`: Pure compositor. Input: base function + layers. Output: composed function. Period.\n\nEach function has ONE responsibility, expressed with precision.\n\n### X. CONCLUSION\n\nThis circular dependency is not a mere inconvenience - it is a symptom of **conceptual confusion** about what action generation means. By extracting structural generation from validation, we restore clarity:\n\n- **Structure** is what CAN exist (skeleton of possibilities)\n- **Validation** is what IS legal (filtered by rules)\n- **Transformation** is what SHOULD appear (modified by layers)\n\nThree concerns, three stages, zero circles.\n\nThe extraction is not just possible - it is *necessary* for architectural integrity.","status":"open","priority":3,"issue_type":"chore","created_at":"2025-11-29T12:10:08.567846258-06:00","updated_at":"2025-12-20T22:18:59.801406103-06:00","dependencies":[{"issue_id":"t42-9wn","depends_on_id":"t42-8ee","type":"blocks","created_at":"2025-11-29T12:10:24.168018986-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-9wn","depends_on_id":"t42-4b9","type":"parent-child","created_at":"2025-11-29T12:10:38.52155258-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"t42-9xy3","title":"ClaudeAI Import: Factored Algebraic Model for Dominoes","description":"**Status:** research-complete  \n**Created:** 2025-12-23  \n**Supersedes:** BEAD-domino-algebra.md  \n**Discovered-from:** group-theory-42-conversation (continued)  \n**Blocks:** GPU training pipeline, PIMC optimization, clean AI implementation  \n\n---\n\n## Evolution\n\nPrevious bead (BEAD-domino-algebra.md) identified that dominoes should be indices and rules should be lookup tables. But it encoded trump as a single value 0-8, which entangled two independent concepts. This refinement factors them cleanly.\n\n---\n\n## The Core Insight\n\n**Trump conflates two independent operations:**\n\n1. **Absorption**: Restructures which dominoes belong to which suit\n2. **Power**: Determines which dominoes beat others\n\nThese usually align (\"5s are trump\" means 5s absorb AND 5s beat), but they're independent:\n\n| Variant | Absorption | Power |\n|---------|------------|-------|\n| 5s trump | pip=5 absorbs | dominoes with 5 beat |\n| Doubles trump | doubles separate | doubles beat |\n| Nello | doubles separate | nothing beats |\n\nNello proves they're independent: same absorption as doubles-trump, different power.\n\n---\n\n## The Mathematical Model\n\n### Layer 1: The Base Set\n\nThe 28 dominoes are the upper triangle of a 7×7 matrix:\n\n```\nD = { (i, j) : 0 ≤ i ≤ j ≤ 6 }\n```\n\nRepresented as indices 0-27. The pip values are only needed for precomputation.\n\n```typescript\ntype DominoId = number;  // 0-27\ntype Pip = 0 | 1 | 2 | 3 | 4 | 5 | 6;\n\nconst DOMINO_PIPS: readonly [Pip, Pip][] = (() =\u003e {\n  const result: [Pip, Pip][] = [];\n  for (let j = 0; j \u003c= 6; j++) {\n    for (let i = 0; i \u003c= j; i++) {\n      result.push([i as Pip, j as Pip]);\n    }\n  }\n  return result;  // [0,0], [0,1], [1,1], [0,2], [1,2], [2,2], ...\n})();\n\n// Convert Domino object to table index\nfunction dominoToId(d: Domino): DominoId {\n  const lo = Math.min(d.high, d.low);\n  const hi = Math.max(d.high, d.low);\n  return (hi * (hi + 1)) / 2 + lo;\n}\n```\n\n### Layer 2: Suits as Sets\n\nA **suit** is a subset of D. The **natural suits** (before any trump configuration) are:\n\n```\nNaturalSuit(k) = { d ∈ D : k ∈ d }  for k ∈ {0..6}\n```\n\nProperties:\n- Each NaturalSuit has 7 dominoes\n- Doubles belong to exactly 1 natural suit\n- Non-doubles belong to exactly 2 natural suits\n- NaturalSuit(k) ∩ NaturalSuit(m) = { {k,m} } for k ≠ m\n\nThis is a **covering**, not a partition.\n\n### Layer 3: Absorption\n\n**Absorption** restructures the covering into an **effective suit structure** for gameplay.\n\n```typescript\ntype Absorption = \n  | { kind: 'pip', pip: Pip }   // all dominoes containing pip form one suit\n  | { kind: 'doubles' }         // all doubles form one suit\n  | { kind: 'none' };           // no restructuring (theoretical)\n```\n\n**Effect of pip absorption (e.g., pip=5):**\n\n- Dominoes containing 5 are **removed** from their other natural suit\n- They now belong **only** to the absorbed suit\n- Result: a **partition** of D into 8 suits (7 residual pip suits + 1 absorbed suit)\n\n**Effect of doubles absorption:**\n\n- Doubles form their own suit (7 dominoes)\n- Non-doubles remain in their natural suits (21 dominoes, each in 2 suits)\n- Result: a **covering** with 8 suits (7 pip suits + 1 doubles suit)\n\n### Layer 4: Power\n\n**Power** determines which dominoes beat others in trick-taking.\n\n```typescript\n// PowerId parallels AbsorptionId - answers \"which dominoes have power?\"\n// 0-6: dominoes containing that pip have power\n// 7: doubles have power  \n// 8: nothing has power\ntype PowerId = number;  // 0-8\n\nfunction hasPower(d: DominoId, powerId: PowerId): boolean {\n  if (powerId === 8) return false;\n  if (powerId === 7) return DOMINO_PIPS[d][0] === DOMINO_PIPS[d][1];\n  const [lo, hi] = DOMINO_PIPS[d];\n  return lo === powerId || hi === powerId;\n}\n```\n\nPower is **independent** of absorption. They usually coincide, but don't have to:\n- Standard pip trump: `absorptionId = powerId = trumpPip`\n- Doubles trump: `absorptionId = powerId = 7`\n- Nello: `absorptionId = 7, powerId = 8`\n\nThe parallelism is the point. Same question shape, different consequences.\n\n### Layer 5: Rank\n\nWithin a suit, dominoes have **rank** determining which beats which.\n\nFor pip suits: rank by pip sum (6-5 \u003e 6-4 \u003e 6-3 \u003e ...)\nFor absorbed/trump suit: double of absorbing pip is highest, then by pip sum\n\n```typescript\ntype RankFunction = (d: DominoId) =\u003e number;\n```\n\n---\n\n## The S₇ Symmetry\n\n**Key insight: All 7 pip absorptions are isomorphic.**\n\nThe symmetric group S₇ acts on pips. A permutation σ ∈ S₇ induces:\n- σ(domino {i,j}) = {σ(i), σ(j)}\n- σ(NaturalSuit(k)) = NaturalSuit(σ(k))\n- σ(Absorption pip=k) = Absorption pip=σ(k)\n\nThe permutation (5 3) transforms \"5s trump\" into \"3s trump\" perfectly. Same structure, different labels.\n\n**Implication:** There's ONE pip-absorption pattern, instantiated 7 ways. Code should reflect this:\n\n```typescript\n// ONE function parameterized by pip, not 7 cases\nfunction getEffectiveSuit(d: DominoId, absorbedPip: Pip): SuitId {\n  const [lo, hi] = DOMINO_PIPS[d];\n  if (lo === absorbedPip || hi === absorbedPip) {\n    return ABSORBED_SUIT;  // constant: 7\n  }\n  return hi;  // high pip = suit\n}\n```\n\n---\n\n## The Full Configuration\n\nA game configuration for trick-taking:\n\n```typescript\ntype TrickConfig = {\n  absorptionId: AbsorptionId;  // 0-8\n  powerId: PowerId;            // 0-8\n};\n\n// Standard pip trump (e.g., 5s trump)\nfunction pipTrump(pip: Pip): TrickConfig {\n  return { absorptionId: pip, powerId: pip };\n}\n\n// Doubles trump\nconst doublesTrump: TrickConfig = {\n  absorptionId: 7,\n  powerId: 7,\n};\n\n// Nello (doubles separate, no power)\nconst nello: TrickConfig = {\n  absorptionId: 7,\n  powerId: 8,\n};\n```\n\n---\n\n## The Factored Tables\n\n### Table 1: Effective Suit (depends on Absorption only)\n\n```typescript\n// AbsorptionId: 0-6 = pip absorption, 7 = doubles, 8 = none\ntype AbsorptionId = number;  // 0-8\n\nconst EFFECTIVE_SUIT: readonly number[][] = precompute();\n// EFFECTIVE_SUIT[d][absorptionId] -\u003e SuitId (0-7)\n// 28 × 9 = 252 entries\n\nfunction precomputeEffectiveSuit(): number[][] {\n  const result: number[][] = [];\n  \n  for (let d = 0; d \u003c 28; d++) {\n    result[d] = [];\n    const [lo, hi] = DOMINO_PIPS[d];\n    \n    // Pip absorptions (0-6)\n    for (let pip = 0; pip \u003c= 6; pip++) {\n      if (lo === pip || hi === pip) {\n        result[d][pip] = 7;  // absorbed suit\n      } else {\n        result[d][pip] = hi;  // high pip\n      }\n    }\n    \n    // Doubles absorption (7)\n    if (lo === hi) {\n      result[d][7] = 7;  // doubles suit\n    } else {\n      result[d][7] = hi;  // high pip\n    }\n    \n    // No absorption (8) - theoretical\n    result[d][8] = hi;\n  }\n  \n  return result;\n}\n```\n\n### Table 2: Suit Masks (for fast legal play lookup)\n\n```typescript\nconst SUIT_MASK: readonly number[][] = precompute();\n// SUIT_MASK[absorptionId][suit] -\u003e bitmask of dominoes in that suit\n// 9 × 8 = 72 entries\n\nfunction precomputeSuitMask(): number[][] {\n  const result: number[][] = [];\n  \n  for (let abs = 0; abs \u003c 9; abs++) {\n    result[abs] = [];\n    for (let suit = 0; suit \u003c 8; suit++) {\n      let mask = 0;\n      for (let d = 0; d \u003c 28; d++) {\n        const [lo, hi] = DOMINO_PIPS[d];\n        const effectiveSuit = EFFECTIVE_SUIT[d][abs];\n        const isAbsorbed = (effectiveSuit === 7);\n        \n        let canFollow: boolean;\n        if (suit === 7) {\n          canFollow = isAbsorbed;\n        } else if (isAbsorbed) {\n          canFollow = false;\n        } else {\n          canFollow = (lo === suit || hi === suit);\n        }\n        \n        if (canFollow) {\n          mask |= (1 \u003c\u003c d);\n        }\n      }\n      result[abs][suit] = mask;\n    }\n  }\n  \n  return result;\n}\n```\n\n### Table 3: Rank (depends on Power only)\n\n```typescript\nconst RANK: readonly number[][] = precompute();\n// RANK[d][powerId] -\u003e number (higher wins)\n// 28 × 9 = 252 entries\n\nfunction precomputeRank(): number[][] {\n  const result: number[][] = [];\n  \n  for (let d = 0; d \u003c 28; d++) {\n    result[d] = [];\n    const [lo, hi] = DOMINO_PIPS[d];\n    const isDouble = lo === hi;\n    const pipSum = lo + hi;\n    \n    for (let power = 0; power \u003c 9; power++) {\n      if (power \u003c= 6) {\n        // Pip power: dominoes containing that pip beat others\n        const hasPower = (lo === power || hi === power);\n        if (hasPower) {\n          // Trump rank: double of power pip highest, then pip sum\n          if (isDouble \u0026\u0026 lo === power) {\n            result[d][power] = 100;  // highest trump\n          } else {\n            result[d][power] = 50 + pipSum;\n          }\n        } else {\n          // Off-suit rank: just pip sum\n          result[d][power] = pipSum;\n        }\n      } else if (power === 7) {\n        // Doubles power\n        if (isDouble) {\n          result[d][power] = 50 + pipSum;  // doubles beat\n        } else {\n          result[d][power] = pipSum;\n        }\n      } else {\n        // No power (power === 8): everyone ranks by pip sum only\n        result[d][power] = pipSum;\n      }\n    }\n  }\n  \n  return result;\n}\n```\n\n### Table 4: Has Power (for trick winner eligibility)\n\n```typescript\nconst HAS_POWER: readonly boolean[][] = precompute();\n// HAS_POWER[d][powerId] -\u003e boolean\n// 28 × 9 = 252 entries\n\nfunction precomputeHasPower(): boolean[][] {\n  const result: boolean[][] = [];\n  \n  for (let d = 0; d \u003c 28; d++) {\n    result[d] = [];\n    const [lo, hi] = DOMINO_PIPS[d];\n    const isDouble = lo === hi;\n    \n    for (let power = 0; power \u003c 9; power++) {\n      if (power === 8) {\n        result[d][power] = false;\n      } else if (power === 7) {\n        result[d][power] = isDouble;\n      } else {\n        result[d][power] = (lo === power || hi === power);\n      }\n    }\n  }\n  \n  return result;\n}\n```\n\n---\n\n## Game Logic\n\n```typescript\nfunction getLedSuit(d: DominoId, absorptionId: AbsorptionId): SuitId {\n  return EFFECTIVE_SUIT[d][absorptionId];\n}\n\nfunction getLegalPlays(\n  hand: Hand,              // bitmask\n  absorptionId: AbsorptionId,\n  leadDomino: DominoId | null\n): Hand {\n  if (leadDomino === null) return hand;  // leading: any\n  \n  const ledSuit = EFFECTIVE_SUIT[leadDomino][absorptionId];\n  const canFollow = hand \u0026 SUIT_MASK[absorptionId][ledSuit];\n  return canFollow !== 0 ? canFollow : hand;  // must follow if able\n}\n\nfunction getTrickWinner(\n  trick: readonly DominoId[],\n  absorptionId: AbsorptionId,\n  powerId: PowerId,\n  leadPlayer: number\n): number {\n  const ledSuit = EFFECTIVE_SUIT[trick[0]][absorptionId];\n  \n  let winner = 0;\n  let maxRank = RANK[trick[0]][powerId];\n  \n  for (let i = 1; i \u003c trick.length; i++) {\n    const domino = trick[i];\n    const dominoSuit = EFFECTIVE_SUIT[domino][absorptionId];\n    \n    // Only dominoes in led suit OR with power can win\n    const inLedSuit = (dominoSuit === ledSuit);\n    const hasPower = HAS_POWER[domino][powerId];\n    \n    if (!inLedSuit \u0026\u0026 !hasPower) {\n      continue;  // played off, can't win\n    }\n    \n    const rank = RANK[domino][powerId];\n    if (rank \u003e maxRank) {\n      maxRank = rank;\n      winner = i;\n    }\n  }\n  \n  return (leadPlayer + winner) % 4;\n}\n```\n\n---\n\n## Layer System Integration\n\nThis model implements the **Crystal Palace** (`rules-base.ts`) - the single source of truth for base game logic. The existing layer composition mechanism remains unchanged.\n\n### Mapping to GameRules Interface\n\n| GameRules Method | Table Implementation |\n|------------------|---------------------|\n| `getLedSuit(state, domino)` | `EFFECTIVE_SUIT[dominoToId(domino)][getAbsorptionId(state)]` |\n| `canFollow(state, led, domino)` | `(SUIT_MASK[abs][ledSuit] \u0026 (1 \u003c\u003c dominoToId(domino))) !== 0` |\n| `rankInTrick(state, led, domino)` | `RANK[dominoToId(domino)][getPowerId(state)]` |\n| `isTrump(state, domino)` | `HAS_POWER[dominoToId(domino)][getPowerId(state)]` |\n| `calculateTrickWinner(state, trick)` | `getTrickWinner(...)` with table lookups |\n\n### State-to-Config Mapping\n\n```typescript\nfunction getAbsorptionId(state: GameState): AbsorptionId {\n  if (!state.trump) return 8;\n  if (state.trump.type === 'nello') return 7;\n  if (state.trump.type === 'doubles') return 7;\n  if (state.trump.type === 'suit') return state.trump.suit;\n  return 8;\n}\n\nfunction getPowerId(state: GameState): PowerId {\n  if (!state.trump) return 8;\n  if (state.trump.type === 'nello') return 8;\n  if (state.trump.type === 'doubles') return 7;\n  if (state.trump.type === 'suit') return state.trump.suit;\n  return 8;\n}\n```\n\n### What Changes, What Stays\n\n| Aspect | Status |\n|--------|--------|\n| Layer composition (`composeRules`) | Unchanged |\n| Layer overrides (check `state.trump.type`) | Unchanged |\n| Executor code (calls `rules.method()`) | Unchanged |\n| Invariant #6 (parametric polymorphism) | Preserved |\n| Base implementation (`rules-base.ts`) | **Replaced with table lookups** |\n\n### Example: Base Rules with Tables\n\n```typescript\n// rules-base.ts - the Crystal Palace\nexport const baseRules: GameRules = {\n  getLedSuit: (state, domino) =\u003e {\n    const d = dominoToId(domino);\n    const absorptionId = getAbsorptionId(state);\n    return EFFECTIVE_SUIT[d][absorptionId];\n  },\n  \n  canFollow: (state, led, domino) =\u003e {\n    const absorptionId = getAbsorptionId(state);\n    const ledSuit = EFFECTIVE_SUIT[dominoToId(led)][absorptionId];\n    return (SUIT_MASK[absorptionId][ledSuit] \u0026 (1 \u003c\u003c dominoToId(domino))) !== 0;\n  },\n  \n  isTrump: (state, domino) =\u003e {\n    return HAS_POWER[dominoToId(domino)][getPowerId(state)];\n  },\n  \n  rankInTrick: (state, led, domino) =\u003e {\n    return RANK[dominoToId(domino)][getPowerId(state)];\n  },\n  \n  // ... other methods delegate to tables\n};\n```\n\nLayers continue to override specific behaviors exactly as before:\n\n```typescript\n// nello.ts - unchanged pattern\nexport const nelloLayer: Layer = {\n  name: 'nello',\n  rules: {\n    isTrickComplete: (state, prev) =\u003e\n      state.trump?.type === 'nello'\n        ? state.currentTrick.length === 3\n        : prev,\n  }\n};\n```\n\n---\n\n## The Payoff\n\n1. **No conditionals** in game logic. Absorption and power are table indices.\n\n2. **Independence preserved**. SUIT_MASK uses only absorption. RANK/HAS_POWER use only power.\n\n3. **S₇ symmetry explicit**. Pip absorptions 0-6 are the same code path with different parameters.\n\n4. **GPU-ready**. Four small constant tables. Game loop is pure lookups and bitwise ops.\n\n5. **Testable**. 252 + 72 + 252 + 252 = 828 entries. Exhaustively verify.\n\n6. **Composable**. Game logic is variant-agnostic. Layer system unchanged.\n\n7. **Crystal Palace**. Tables become the single source of truth for base rules.\n\n---\n\n## Work Breakdown\n\n### Phase 1: Build and Verify Tables\n- [ ] Implement DOMINO_PIPS and dominoToId\n- [ ] Implement precomputeEffectiveSuit\n- [ ] Implement precomputeSuitMask\n- [ ] Implement precomputeRank\n- [ ] Implement precomputeHasPower\n- [ ] Write exhaustive tests against current rules-base.ts behavior\n- [ ] Handle edge cases: 6-1/5-0 special rules (if any)\n\n### Phase 2: Replace rules-base.ts\n- [ ] Add getAbsorptionId/getPowerId helpers\n- [ ] Replace getLedSuit with table lookup\n- [ ] Replace canFollow with table lookup\n- [ ] Replace isTrump with table lookup\n- [ ] Replace rankInTrick with table lookup\n- [ ] Replace calculateTrickWinner with table version\n- [ ] Verify all existing tests pass\n\n### Phase 3: GPU Port\n- [ ] Tables as WebGPU constant buffers\n- [ ] Game simulation as compute shader\n- [ ] Benchmark parallel MCTS sampling\n\n---\n\n## Open Questions\n\n1. **6-1 and 5-0 as special trumps?** Some variants have these as always-second and always-third highest trump. If so, RANK table needs adjustment.\n\n2. **Sevens variant?** Different rank function entirely (closest to 7 wins). Separate power kind?\n\n3. **Table compression?** 828 entries is tiny. But could exploit S₇ symmetry to store ONE pip-absorption pattern and derive others. Probably not worth it.","notes":"**Implementation Status (as of 2025-12-25):**\n\n### Phase 1: Build and Verify Tables ✓ COMPLETE\n- `src/game/core/domino-tables.ts` implements all tables\n- `src/tests/unit/domino-tables.test.ts` verifies against rules-base.ts\n- All tests pass\n\n### Phase 2: Replace rules-base.ts ✓ COMPLETE\n- `rules-base.ts` now delegates to table lookups:\n  - `getLedSuitBase` → `getLedSuitFromTable`\n  - `suitsWithTrumpBase` → `getSuitsForDomino`\n  - `canFollowBase` → `canFollowFromTable`\n  - `isTrumpBase` → `isTrumpFromTable`\n  - `rankInTrickBase` → Uses `isTrumpFromTable` + `canFollowFromTable` for three-tier ranking\n\n- **Key design decision**: `rankInTrickBase` still computes the three-tier ranking (trump 200+, follows 50+, slough 0-12) dynamically because the \"follows suit\" tier depends on what was led. The RANK table encodes power-only ranking; the led-suit-dependent tier is computed at call time using `canFollowFromTable`.\n\n### Phase 3: GPU Port - NOT STARTED\n\n### Naming\nThe constant `CALLED` = 7 is used throughout:\n- `CALLED = 7` in types.ts\n- `CALLED_SUIT = 7` in domino-tables.ts\n- `led-called` in strength table keys\n\n### Files Changed\n- `src/game/layers/rules-base.ts` - Now delegates to table lookups\n- `src/tests/layers/composition/compose-rules.test.ts` - Fixed malformed domino in test","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-25T18:23:08.911188122-06:00","updated_at":"2025-12-25T21:18:15.406973215-06:00","closed_at":"2025-12-25T21:18:15.406973215-06:00","close_reason":"Phase 2 complete: rules-base.ts now delegates to table lookups. All tests pass."}
{"id":"t42-9yi","title":"Phase 14: Update documentation","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.340911618-06:00","updated_at":"2025-12-20T22:18:59.769892015-06:00","closed_at":"2025-11-24T13:56:31.938549734-06:00","dependencies":[{"issue_id":"t42-9yi","depends_on_id":"t42-3jb","type":"blocks","created_at":"2025-11-24T10:35:53.780105237-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-9yi","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:58.181246269-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-9yj0","title":"Rename DOUBLES_AS_TRUMP to CALLED","description":"Use texas-42 skill.\n\n## Summary\n\nRename `DOUBLES_AS_TRUMP = 7` to `CALLED = 7` throughout the codebase and update documentation to explain the naming.\n\n## Background: The Naming Challenge\n\nSuit 7 is the 8th suit - the one that's NOT defined by a pip value. Its contents depend on what you declare:\n\n| Declaration | What goes to suit 7 |\n|-------------|---------------------|\n| \"5s are trump\" | All dominoes containing 5 |\n| \"Doubles are trump\" | All 7 doubles |\n| \"Nello\" | All 7 doubles (but no power) |\n| \"No-trump\" | Nothing (empty) |\n\n### Why existing names failed:\n\n- **DOUBLES_AS_TRUMP**: Wrong for pip-trump (6-5 isn't a double when 5s are trump)\n- **TRUMPS**: Doesn't work for nello (doubles separate but have no power)\n- **ABSORBED_SUIT**: Invented metaphor, not grounded in game language\n- **Rules terminology**: Rules describe behavior (\"form their own suit\", \"cannot follow\") but never name the destination\n\n### Why CALLED works:\n\n- \"Called\" = \"the suit you called into existence when you declared trump\"\n- Works for pip-trump: \"I called 5s\" → 5s are in the called suit\n- Works for doubles-trump: \"I called doubles\" → doubles are in the called suit  \n- Works for nello: doubles are called together (just without power)\n- Simple, from game vocabulary (\"call trump\")\n\n## Examples\n\nStrength table entries become clearer:\n```\n// Before (actively wrong when trump isn't doubles):\n\"5-0|trump-blanks|led-doubles\": { beatenBy: [\"6-0\", \"0-0\"], ...\n\n// After (accurate):\n\"5-0|trump-blanks|led-called\": { beatenBy: [\"6-0\", \"0-0\"], ...\n```\n\nReading: \"When I have 5-0, blanks are trump, and the called suit was led...\"\n\nIn conversation:\n- \"I led the called suit\"\n- \"Follow with something from the called suit\"\n- \"The called suit was led, and I can't follow\"\n\n## Files to update\n\n1. `src/game/types.ts` - Rename constant\n2. `src/game/core/domino-tables.ts` - Update references\n3. `src/game/layers/rules-base.ts` - Update references  \n4. `src/game/layers/*.ts` - Update any layer references\n5. `src/tests/**/*.ts` - Update test references\n6. `scripts/generate-strength-table.ts` - Update to generate `led-called`\n7. Regenerate strength table after script update\n8. `docs/ORIENTATION.md` - Add section explaining suit 7 / \"called suit\" concept\n\n## Documentation to add\n\nAdd a section to ORIENTATION.md explaining:\n- The 7 natural suits (pip-defined, 0-6)\n- The called suit (suit 7) - membership determined by declaration\n- Why \"called\" - you call dominoes into this suit when you declare trump\n- Examples showing how the same suit 7 holds different dominoes based on declaration","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T20:35:17.097291792-06:00","updated_at":"2025-12-25T20:56:24.5543365-06:00","closed_at":"2025-12-25T20:56:24.5543365-06:00","close_reason":"Renamed DOUBLES_AS_TRUMP to CALLED throughout codebase, updated strength table to use led-called, added documentation to ORIENTATION.md explaining the suit system, and fixed pre-existing type safety issues in domino-tables.ts","dependencies":[{"issue_id":"t42-9yj0","depends_on_id":"t42-vwnt","type":"blocks","created_at":"2025-12-25T20:35:17.102326251-06:00","created_by":"jason"}]}
{"id":"t42-a4q","title":"[User-Facing Features] Add landing page with Start and One Hand buttons","description":"Currently the game instantly starts which is awkward. Add a landing page that shows two buttons:\n- **Start** - begins a full game (default behavior today)\n- **One Hand** - plays a single hand (existing `oneHand` layer)","design":"## Implementation Approach\n\n### New Component: `LandingPage.svelte`\nCreate a new component at `src/lib/components/LandingPage.svelte` with:\n- Two prominent buttons: \"Start Game\" and \"One Hand\"\n- Simple, clean design matching existing DaisyUI theme\n\n### App.svelte Changes\n- Add new state: `showLanding` (default: `true`)\n- Conditionally render `LandingPage` or the game UI based on state\n- Wire up button handlers:\n  - \"Start Game\" → `game.resetGame()` + `showLanding = false`\n  - \"One Hand\" → `modes.oneHand.start()` + `showLanding = false`\n\n### GameStore Changes\n- Modify `initializeFromURL()` to NOT auto-start a game when there's no URL state\n- Add a way to detect \"no game started yet\" state (could use a special `phase` or separate flag)\n- When URL has game state (seed, actions), skip landing page and load directly\n\n### URL Parameter Handling\n- Existing `?onehand=auto` parameter should bypass landing page\n- URL with `?s=...` (seed) should bypass landing page and load that game\n- Clean URL with no params → show landing page\n\n### Existing Infrastructure to Leverage\n- `modes.oneHand.start()` already exists in gameStore\n- `game.resetGame()` creates a new game with random seed\n- Theme system already applied at App level\n\n## Acceptance Criteria\n- Landing page appears on fresh load (no URL params)\n- \"Start Game\" button begins normal game\n- \"One Hand\" button begins one-hand mode\n- URL with game state (`?s=...`) bypasses landing page\n- `?onehand=auto` bypasses landing page\n- Responsive design works on mobile\n- Theme colors apply correctly to landing page","status":"open","priority":1,"issue_type":"feature","created_at":"2025-11-27T17:37:23.188609704-06:00","updated_at":"2025-12-20T22:18:59.680898286-06:00","dependencies":[{"issue_id":"t42-a4q","depends_on_id":"t42-cni","type":"parent-child","created_at":"2025-11-28T10:14:52.111443215-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-a7y","title":"Carry descriptions on actions instead of computing in view projection","description":"Use texas-42 skill.\n\ngetDominoTooltip is a 60-line conditional tree. Each valid action should carry its own description.\n\nFiles: src/game/view-projection.ts","design":"# On the Absence of Abstraction: A Case Study in Conditional Trees\n\n*In the spirit of E.W. Dijkstra*\n\n## The Problem: Computation Disguised as Projection\n\nIn `src/game/view-projection.ts`, the function `getDominoTooltip` (lines 321-382) is a 62-line conditional tree. This is not accidental complexity - it is essential complexity that has been placed in the wrong location.\n\n### The Structure of getDominoTooltip's Conditionals\n\nThe function branches on seven distinct conditions:\n\n```\n1. IF phase !== 'playing' → return dominoStr\n2. IF currentPlayer !== 0 → return \"Waiting for P{n}'s turn\"\n3. IF currentTrick.length === 0:\n   → IF playable: \"Click to lead this domino\"\n   → ELSE: dominoStr\n4. IF leadSuit === -1:\n   → IF playable: \"Click to play\"\n   → ELSE: dominoStr\n5. IF playable:\n   5a. IF leadSuit === DOUBLES and is double → \"Double, follows {suit}\"\n   5b. IF has leadSuit → \"Has {suit}, follows suit\"\n   5c. ELSE:\n       5c-i.  IF trump.type === 'doubles' and is double → \"Trump (double)\"\n       5c-ii. IF trump.type === 'suit' and has trump → \"Trump\"\n       5c-iii. ELSE → \"Can't follow {suit}\"\n6. ELSE (not playable):\n   6a. IF leadSuit === DOUBLES → \"Not a double, can't follow {suit}\"\n   6b. ELSE:\n       6b-i.  IF player has led suit → \"Must follow {suit}\"\n       6b-ii. ELSE → \"Invalid play\"\n```\n\nThis tree has **11 leaf nodes** (distinct tooltip messages) and encodes **game rule knowledge** (what makes a play valid/invalid).\n\n### What Information Does It Need?\n\nThe tooltip computation requires:\n1. **The domino itself** - already available\n2. **Game phase** - already in state\n3. **Playability** - computed from `playableDominoIds` set\n4. **Current game context** - trump, led suit, trick state\n5. **The REASON for playability/unplayability** - NOT AVAILABLE\n\nThis is the crux: **the tooltip reconstructs the reasoning that already occurred during action generation**.\n\n## The Source of Truth: Action Generation\n\nIn `src/game/layers/base.ts`, `generateStructuralActions()` (lines 35-61) creates play actions:\n\n```typescript\nfunction getPlayingActions(state: GameState, rules?: GameRules): GameAction[] {\n  // ...\n  const validPlays = threadedRules.getValidPlays(state, state.currentPlayer);\n  validPlays.forEach((domino: Domino) =\u003e {\n    actions.push({\n      type: 'play',\n      player: state.currentPlayer,\n      dominoId: domino.id.toString()\n    });\n  });\n  return actions;\n}\n```\n\nThe rules engine has ALREADY determined:\n- Which dominoes are valid\n- WHY they are valid (follows suit, trump, can't follow, etc.)\n- The game context (led suit, trump selection, etc.)\n\nBut this reasoning is **discarded**. The tooltip must **recompute it**.\n\n## The StateTransition Type: A Missed Opportunity\n\nFrom `src/game/types.ts` (lines 213-218):\n\n```typescript\nexport interface StateTransition {\n  id: string;\n  label: string;           // Generic action label\n  action: GameAction;      // The action data\n  newState: GameState;     // Result state\n}\n```\n\nCurrently `label` comes from `actionToLabel()` which for play actions returns:\n```typescript\ncase 'play':\n  return `Play domino ${action.dominoId}`;  // Useless!\n```\n\nThe label is **action-centric** (\"what I'm doing\") not **reason-centric** (\"why this is valid/invalid\").\n\n## The Dijkstrian Solution: Carry The Why\n\n**Observation**: An action represents not just WHAT is possible, but WHY it is possible in THIS game state.\n\n**Principle**: Information computed during action generation should flow forward, not be recomputed during projection.\n\n### Proposed Action Metadata Structure\n\nExtend `GameAction` with optional `meta` field (already exists!) to carry descriptive metadata:\n\n```typescript\ntype PlayReason =\n  | { type: 'lead'; message: \"Click to lead this domino\" }\n  | { type: 'follows-suit'; suit: string; message: \"Has {suit}, follows suit\" }\n  | { type: 'follows-doubles'; message: \"Double, follows {suit}\" }\n  | { type: 'trump-play'; trumpType: 'double' | 'suit'; message: \"Trump (double)\" | \"Trump\" }\n  | { type: 'cant-follow'; suit: string; message: \"Can't follow {suit}\" };\n\ntype UnplayableReason =\n  | { type: 'must-follow'; suit: string; message: \"Must follow {suit}\" }\n  | { type: 'not-double'; suit: string; message: \"Not a double, can't follow {suit}\" }\n  | { type: 'invalid'; message: \"Invalid play\" };\n\n// Extended GameAction\ntype GameAction = \n  | { \n      type: 'play'; \n      player: number; \n      dominoId: string; \n      meta?: { \n        tooltip?: string;  // Pre-computed during action generation\n        reason?: PlayReason;\n      }\n    }\n  | ...\n```\n\n### Action Generation With Context\n\nModify `getPlayingActions()` to compute tooltips:\n\n```typescript\nfunction getPlayingActions(state: GameState, rules?: GameRules): GameAction[] {\n  const validPlays = threadedRules.getValidPlays(state, state.currentPlayer);\n  \n  validPlays.forEach((domino: Domino) =\u003e {\n    const tooltip = computePlayTooltip(domino, state);  // New helper\n    actions.push({\n      type: 'play',\n      player: state.currentPlayer,\n      dominoId: domino.id.toString(),\n      meta: { tooltip }\n    });\n  });\n  \n  return actions;\n}\n```\n\n### Simplified View Projection\n\nThe `getDominoTooltip()` function collapses to:\n\n```typescript\nfunction getDominoTooltip(\n  domino: Domino,\n  gameState: FilteredGameState,\n  availableActions: StateTransition[]  // Changed parameter!\n): string {\n  const dominoStr = `${domino.high}-${domino.low}`;\n  \n  // Not playing? Just show domino\n  if (gameState.phase !== 'playing') {\n    return dominoStr;\n  }\n  \n  // Not our turn? Show wait message\n  if (gameState.currentPlayer !== 0) {\n    return `${dominoStr} - Waiting for P${gameState.currentPlayer}'s turn`;\n  }\n  \n  // Find matching action\n  const playAction = availableActions.find(a =\u003e \n    a.action.type === 'play' \u0026\u0026 \n    (a.action.dominoId === `${domino.high}-${domino.low}` ||\n     a.action.dominoId === `${domino.low}-${domino.high}`)\n  );\n  \n  // Return pre-computed tooltip or default\n  return playAction?.action.meta?.tooltip ?? dominoStr;\n}\n```\n\nFrom **62 lines with 11 branches** to **~20 lines with 2 branches**.\n\n## Advantages\n\n1. **Single Computation**: Tooltip logic runs once (during action generation), not once per domino per render\n2. **Co-location**: Tooltip reasoning lives next to playability reasoning\n3. **Testability**: Action generation tests verify both validity AND descriptions\n4. **Separation of Concerns**: View projection becomes pure projection, no game rule knowledge\n5. **Extensibility**: Special contracts (nello, sevens) can provide custom tooltips via their layers\n\n## Philosophical Note\n\nThe conditional tree in `getDominoTooltip` is not a programming error - it is an **architectural error**. It exists because we separated two computations that should have been unified:\n\n1. \"Is this domino playable?\" (action generation)\n2. \"Why is this domino playable/unplayable?\" (tooltip generation)\n\nThese are not separate questions - they are two facets of the same question. The answer should be computed once and carried forward.\n\n**\"Simplicity is prerequisite for reliability.\"** - E.W. Dijkstra\n\nThe conditional tree is the absence of the abstraction that should unite these facets. By carrying descriptions on actions, we eliminate the tree not through clever optimization, but through correct decomposition.\n\n## Implementation Path\n\n1. Add `tooltip?: string` to `GameAction['meta']` for play actions\n2. Create `computePlayTooltip(domino, state)` helper in `src/game/layers/base.ts`\n3. Modify `getPlayingActions()` to attach tooltips\n4. Simplify `getDominoTooltip()` to lookup pre-computed tooltips\n5. Update tests to verify tooltip accuracy\n6. Consider extending to ALL actions (bids, trump selection, etc.)\n\nThe path forward is clear. The conditional tree awaits its dissolution.","status":"open","priority":3,"issue_type":"chore","created_at":"2025-11-29T12:10:07.49865174-06:00","updated_at":"2025-12-20T22:18:59.803805105-06:00","dependencies":[{"issue_id":"t42-a7y","depends_on_id":"t42-8ee","type":"blocks","created_at":"2025-11-29T12:10:23.644889838-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-a7y","depends_on_id":"t42-4b9","type":"parent-child","created_at":"2025-11-29T12:10:37.940217249-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"t42-aay","title":"Persist layers in GameState.initialConfig for URL roundtrip","description":"Currently, layers are part of GameConfig but createInitialState() doesn't copy them to initialConfig. This means stateToUrl() can't include layers in the generated URL.\n\nThe fix: Update createInitialState() in src/game/core/state.ts to include layers in initialConfig when provided in options.\n\nImpact: Without this, games with layers (nello, plunge, etc.) can be shared via URL but the layer info is lost. The URL encode/decode functions handle layers correctly - it's just the state → URL direction that's missing this data.\n\nRelated: URL system restoration work (mk5-tailwind-1vw)","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-11-25T19:01:46.763004951-06:00","updated_at":"2025-12-20T22:18:59.756083224-06:00","closed_at":"2025-11-25T19:22:23.51038067-06:00"}
{"id":"t42-ade","title":"Architecture \u0026 Code Quality","description":"Enforce greenfield philosophy - no legacy, no backwards compatibility. Keep the codebase clean and unified.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-11-28T10:14:25.302791015-06:00","updated_at":"2025-12-20T22:18:59.742703052-06:00","closed_at":"2025-11-28T10:21:24.348530899-06:00"}
{"id":"t42-adq","title":"Add unit tests for view-projection.ts (0% coverage)","description":"Use texas-42 skill.\n\n`src/game/view-projection.ts` has 0% coverage (lines 2-474) despite being actively used in gameStore.\n\nThe file provides critical UI projection logic - transforming game state into renderable views.\n\n## Functions to test:\n\n### createViewProjection()\n- Transforms FilteredGameState + actions into ViewProjection\n- Tests for each game phase (bidding, playing, scoring)\n\n### getDominoTooltip()\n- Tooltip generation for different contexts\n- Leading, following suit, trump play scenarios\n\n### calculateTeamPoints()\n- Team point aggregation from tricks\n- Edge cases: empty tricks, partial tricks\n\n### calculateHandResults()\n- Perspective-aware win/loss messages\n- Emoji inclusion in messages\n- Different player perspectives\n\n## Why 0% coverage:\nThe gameStore is tested via E2E (Playwright), not unit tests. Coverage measurement only tracks Vitest. These pure functions deserve dedicated unit tests.","status":"open","priority":3,"issue_type":"task","created_at":"2025-11-29T12:49:30.838835614-06:00","updated_at":"2025-12-20T22:18:59.79840037-06:00","labels":["testing","ui"],"dependencies":[{"issue_id":"t42-adq","depends_on_id":"t42-65p","type":"parent-child","created_at":"2025-11-30T10:44:27.974500134-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-adq","depends_on_id":"t42-8d5","type":"blocks","created_at":"2025-12-20T09:12:02.380439221-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-ajiy","title":"JS AI lookup table integration: load solver output for play validation","description":"Use texas-42 skill.\n\nIntegrate the Python solver output into the JavaScript game so AI players can use precomputed optimal move values.\n\n## Goal\n\nLoad a solved seed's complete state→move_values table into the JS game, allowing AI to query \"what's the value of each legal move in this state?\"\n\n## Approach\n\n1. Define export format from Python solver (JSON or binary)\n2. Create JS loader that reads the solved seed data\n3. Add lookup function: `getMovesValues(packedState) → {localIdx: value, ...}`\n4. Wire into AI player for testing/validation\n\n## Use Cases\n\n- Validate solver correctness by watching AI play optimally\n- Debug specific game states\n- Compare AI decisions against perfect play\n\n## Dependencies\n\nRequires t42-8zpu (GPU solver) to produce the data first.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-27T01:03:40.546583875-06:00","updated_at":"2025-12-27T01:03:40.546583875-06:00","dependencies":[{"issue_id":"t42-ajiy","depends_on_id":"t42-8zpu","type":"blocks","created_at":"2025-12-27T01:03:40.550155989-06:00","created_by":"jason"},{"issue_id":"t42-ajiy","depends_on_id":"t42-fe6f","type":"blocks","created_at":"2025-12-27T09:56:35.676035868-06:00","created_by":"jason"}]}
{"id":"t42-akb","title":"[Future Features] Generic voting mechanism (vote kick, vote restart)","description":"## Overview\n\nAdd a generic consensus/voting mechanism for multiplayer actions that require player agreement:\n- Vote to kick a player\n- Vote to restart the game\n- Vote on rule changes\n- Other future voting needs\n\n## Depends On\n\n**mk5-tailwind-dkn** (Extract consensus into optional layer) - The clean layer architecture from that refactor provides the foundation for this feature.\n\n## Proposed Design (from original issue)\n\n```typescript\ninterface GameState {\n  pendingConsensus: ConsensusRequest | null;\n}\n\ninterface ConsensusRequest {\n  id: string;\n  action: GameAction;                        // What executes on approval\n  requiredVoters: number[];                  // Who can vote\n  votes: Record\u003cnumber, boolean\u003e;            // playerId -\u003e approved?\n  threshold: ConsensusThreshold;             // unanimous, majority, atLeast(n)\n  createdAt: number;\n  expiresAt: number | null;                  // For timeout (Durable Object alarm)\n  initiatedBy: number;\n  reason?: string;\n}\n```\n\n## New Actions\n\n- `initiate-consensus` - Player starts a vote\n- `vote` - Player casts approve/reject  \n- `consensus-resolved` - System action when threshold met or expired\n\n## Configurable via ConsensusConfig\n\n- Which actions can be voted on\n- Threshold per action type (unanimous, majority, atLeast)\n- Timeout per action type\n\n## Durable Object Compatibility\n\n- All state serializable (Record instead of Set, no functions)\n- Timeouts via Durable Object alarms\n- Pure executors, side effects in Room orchestrator\n\n## Benefits\n\n- Generic and configurable voting system\n- Easy to add new voteable actions\n- Durable Object ready","status":"open","priority":3,"issue_type":"feature","created_at":"2025-11-27T10:33:17.659336897-06:00","updated_at":"2025-12-20T22:18:59.820368765-06:00","dependencies":[{"issue_id":"t42-akb","depends_on_id":"t42-dkn","type":"blocks","created_at":"2025-11-27T10:33:17.660930902-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-akb","depends_on_id":"t42-e69","type":"parent-child","created_at":"2025-11-28T10:14:54.106083935-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-akl","title":"Investigate registry test failures - oneHand ruleset integration vs test expectations","description":"Registry tests expect 6 rulesets but find 7. Tests failing:\n- registry.test.ts:65 - expect(keys).toHaveLength(6)\n- registry.test.ts:233 - expect(originalKeys.length).toBe(6)\n\nThe 7th ruleset is 'oneHand' (recently added per ADR-20251112).\n\nINVESTIGATION NEEDED - DO NOT just update test expectations:\n1. Was oneHand supposed to be in the registry?\n2. Is it properly documented and integrated?\n3. Are tests missing coverage for oneHand behavior?\n4. Should oneHand be treated differently than other rulesets?\n5. What's the relationship between oneHandRuleSet and oneHandActionTransformer?\n\nThe feature may be legitimate, but tests need PROPER coverage, not just count updates.\n\nRelated to mk5-tailwind-0mt - one-hand integration appears incomplete across multiple systems.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-16T16:21:57.1652809-06:00","updated_at":"2025-12-20T22:18:59.705229737-06:00","closed_at":"2025-11-17T16:03:55.976030447-06:00"}
{"id":"t42-am3","title":"Phase 1: Preparation and baseline","description":"Establish baseline before migration begins.\n\n## Steps\n1. Run full test suite: npm run test:all (expect all pass)\n2. Run E2E tests: npm run test:e2e (expect 4 specs pass)\n3. Run production build: npm run build (must succeed)\n4. Document baseline results\n\n## Acceptance Criteria\n- [ ] All tests passing before any changes\n- [ ] Baseline documented\n\n## Close Condition\nnpm run test:all passes","acceptance_criteria":"- [ ] All tests passing before any changes\n- [ ] Baseline documented","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.291566759-06:00","updated_at":"2025-12-20T22:18:59.786789855-06:00","closed_at":"2025-11-24T11:42:47.332851109-06:00","dependencies":[{"issue_id":"t42-am3","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:47.156212712-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-atk","title":"Phase 3: Delete action-transformers infrastructure","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.2951841-06:00","updated_at":"2025-12-20T22:18:59.778826258-06:00","closed_at":"2025-11-24T12:17:45.815805518-06:00","dependencies":[{"issue_id":"t42-atk","depends_on_id":"t42-xwx","type":"blocks","created_at":"2025-11-24T10:35:44.503470771-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-atk","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:48.851741948-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-azl","title":"Type","description":"task","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T16:24:26.907407114-06:00","updated_at":"2025-12-20T22:18:59.759099938-06:00","closed_at":"2025-11-25T08:55:06.191214963-06:00"}
{"id":"t42-b11","title":"Update documentation for HandOutcome pattern","description":"Update 3 docs: ARCHITECTURE_PRINCIPLES (change 'Base returns null'), CONCEPTS (update signature), ORIENTATION (add discriminated union example). Depends on mk5-tailwind-2gg through mk5-tailwind-61x.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-16T16:55:14.976965245-06:00","updated_at":"2025-12-20T22:18:59.70446061-06:00","closed_at":"2025-11-16T17:13:10.724402906-06:00"}
{"id":"t42-b3b","title":"Remove or suppress daisyUI startup message in tests","description":"The daisyUI initialization message clutters test output:\n\n```\n🌼   daisyUI 4.12.24\n├─ ✔︎ 20 themes added            https://daisyui.com/docs/themes\n╰─ ★ Star daisyUI on GitHub     https://github.com/saadeghi/daisyui\n```\n\nOptions:\n- Check if daisyUI has a config option to suppress the message\n- Conditionally disable in test environment\n- Filter stdout in test runner config","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-27T01:10:40.335306547-06:00","updated_at":"2025-12-20T22:18:59.821134646-06:00","closed_at":"2025-11-27T09:35:49.793075017-06:00"}
{"id":"t42-b3h","title":"Unskip slow MCTS test","description":"Use texas-42 skill.\n\nRe-enable the slow MCTS test that was skipped for faster CI:\n\n## Skipped Test\n\n**src/tests/integration/complete-game-flow.test.ts**:\n- 'should complete game with beginner MCTS strategy' (line 390)\n\n## Why Skipped\n\nThis test runs Monte Carlo simulations, taking 30+ seconds. It was skipped to keep CI fast.\n\n## Options\n\n1. **Keep skipped** - run manually before releases\n2. **Optimize test** - reduce simulations for faster test\n3. **Separate test suite** - create `test:slow` npm script\n4. **CI matrix** - run slow tests in parallel CI job\n\n## Note\n\nMCCFR tests were removed when MCCFR was deleted from the codebase (see docs/archive/MCCFR-EXPLORATION.md).","notes":"2025-12-26: Investigation revealed minimax rollout takes ~21s per simulation. Even with minimal config (1 sim, 1 hand), test would take \u003e5 minutes due to 14 bid options. Created t42-8a66 to track the perf issue. Test remains skipped until perf is fixed.","status":"blocked","priority":2,"issue_type":"task","created_at":"2025-12-13T19:23:29.087993171-06:00","updated_at":"2025-12-26T23:33:38.523562327-06:00","dependencies":[{"issue_id":"t42-b3h","depends_on_id":"t42-d6g","type":"parent-child","created_at":"2025-12-20T08:52:14.860309224-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-b3h","depends_on_id":"t42-tgr","type":"blocks","created_at":"2025-12-20T08:53:18.280950723-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-b3h","depends_on_id":"t42-e92","type":"parent-child","created_at":"2025-12-21T21:00:41.493169298-06:00","created_by":"jason"},{"issue_id":"t42-b3h","depends_on_id":"t42-8a66","type":"blocks","created_at":"2025-12-26T23:33:31.885745257-06:00","created_by":"jason"}]}
{"id":"t42-bdt","title":"Add unit tests for hints.ts and speed.ts layers (5-7% coverage)","description":"Use texas-42 skill.\n\nTwo layers have very low coverage despite being active in the layer system:\n\n- `hints.ts` - 5.61% (lines 29-45, 51-157)\n- `speed.ts` - 7.14% (lines 28-93)\n\n## hints.ts - Educational Hints Layer\nAnnotates actions with strategy hints for learning.\n\n### Functions to test:\n- `generateHint()` - hint text generation\n- Bidding hints (pass vs bid decisions)\n- Trump selection hints\n- Play phase hints (lead vs follow)\n- Capability filtering (only players with 'see-hints')\n\n## speed.ts - Auto-Execute Layer\nMarks forced moves for auto-execution to speed up gameplay.\n\n### Functions to test:\n- Single-action detection\n- `autoExecute: true` flag setting\n- Player-specific vs neutral actions\n- Consensus action handling\n\n## Test approach:\nUnit test each layer's `getValidActions` with mock state and verify output metadata.","status":"open","priority":3,"issue_type":"task","created_at":"2025-11-29T12:49:31.027070591-06:00","updated_at":"2025-12-20T22:18:59.79758692-06:00","labels":["layers","testing"],"dependencies":[{"issue_id":"t42-bdt","depends_on_id":"t42-65p","type":"parent-child","created_at":"2025-11-30T10:44:28.054972302-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-bdt","depends_on_id":"t42-8d5","type":"blocks","created_at":"2025-12-20T09:12:02.52549915-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-bj0","title":"Implement MCCFR with count-centric abstraction","description":"Use texas-42 skill.\n\nImplement Monte Carlo Counterfactual Regret Minimization (MCCFR) using the count-centric abstraction discovered in CFR metrics analysis.\n\n## Why MCCFR (Not Full CFR)\n\n**Full tree traversal proves MCCFR is necessary:**\n- Single deal: \u003e10M nodes (hit limit in 25 seconds at ~400K nodes/sec)\n- Max depth: 35 (7 tricks × 4 plays + complete-trick actions)\n- Full enumeration is completely infeasible\n- Must use Monte Carlo sampling\n\n## Count-Centric Abstraction Results (50K games)\n\n| Metric | Canonical | Count-Centric |\n|--------|-----------|---------------|\n| Unique states | 1,223,043 | 37,659 |\n| Compression | 1.18x | 32.5x |\n| Singleton rate | 94.9% | 32.3% |\n| Growth/game | ~24.5 | ~0.8 |\n\n## Branching Factor\n\n| Stat | Value |\n|------|-------|\n| Min | 1 |\n| Max | 7 |\n| Mean | 3.53 |\n| Median | 2 |\n\nDistribution: 30.5% have 1 choice, 22.6% have 2, 28.9% have 7 (full hand).\n\n## Key Insight\n\nTexas 42 is fundamentally about the 5 count dominoes (5-0, 5-5, 6-4, 3-2, 4-1 = 35 points). Non-count distinctions collapse when strategically equivalent.\n\nThe count-centric hash captures:\n- Which count dominoes are in hand\n- Points captured by each team (us vs them)\n- Points at stake in current trick\n- Trump control (my trump count, who leads)\n- Game progress (trick number, position)\n- Non-count hand size (control cards)\n\n## Implementation Plan\n\n1. **Regret table**: Map count-centric hash -\u003e action -\u003e cumulative regret\n2. **Strategy table**: Map count-centric hash -\u003e action -\u003e cumulative strategy\n3. **MCCFR sampling**: External sampling (sample opponent chance, traverse all player actions) or outcome sampling (sample single trajectory)\n4. **Training loop**: Self-play iterations updating regret/strategy\n5. **Strategy extraction**: Average strategy from cumulative values\n\n## Files\n\n- `src/game/ai/cfr-metrics.ts` - Contains `computeCountCentricHash()` function\n- `scripts/tree-traversal-timing.ts` - Full tree traversal timing script\n- `scripts/collect-cfr-metrics.ts` - Metrics collection script\n- `src/game/ai/mccfr.ts` - New file for MCCFR implementation\n\n## Performance Baseline\n\n- Tree traversal: ~400K nodes/sec\n- Metrics collection: ~310 games/sec (random rollout)\n- Target: Train on 100K+ iterations for convergence","design":"## Implementation Plan (External Sampling MCCFR)\n\n**Scope**: Trick-taking phase only (skip bidding initially)\n\n### File Structure\n```\nsrc/game/ai/cfr/\n  types.ts              # InfoSetKey, ActionKey, CFRNode, MCCFRConfig\n  regret-table.ts       # Storage with getStrategy(), updateRegrets(), serialize()\n  action-abstraction.ts # actionToKey(), sampleAction()\n  mccfr-trainer.ts      # MCCFRTrainer class with train() method\n  mccfr-strategy.ts     # AIStrategy implementation\n  index.ts              # Public exports\n\nscripts/train-mccfr.ts  # CLI training script\nsrc/tests/ai/cfr/       # Unit and integration tests\n```\n\n### Algorithm: External Sampling MCCFR\n- Sample opponent actions according to current strategy\n- Traverse ALL actions for traversing player\n- Update regrets: regret = (actionValue - expectedValue) * opponentReachProb\n- Uses existing computeCountCentricHash() for information set abstraction\n\n### Implementation Phases\n1. **Core Infrastructure**: types, regret-table, action-abstraction + unit tests\n2. **Training Loop**: MCCFRTrainer + scripts/train-mccfr.ts + integration tests\n3. **Strategy Integration**: MCCFRStrategy + actionSelector.ts update\n4. **Training \u0026 Tuning**: 100K+ iterations, convergence analysis\n\n### Key Dependencies\n- src/game/ai/cfr-metrics.ts:352 - computeCountCentricHash()\n- src/game/ai/strategies.ts:35 - AIStrategy interface\n- src/server/HeadlessRoom.ts - Game simulation\n- src/game/ai/hand-sampler.ts - createSeededRng()\n\n### Design Decisions\n- Action keys: Domino ID directly (e.g. 6-4)\n- Team utility: myTeamScore - oppTeamScore\n- Persistence: JSON with version field\n- Performance target: 1000+ iter/sec training, \u003c10ms inference","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-07T21:14:18.535595916-06:00","updated_at":"2025-12-20T22:18:59.721502554-06:00","closed_at":"2025-12-07T22:07:51.887025071-06:00"}
{"id":"t42-bncj","title":"Nello support in GPU solver: 3-player tricks and partner skip","description":"Use texas-42 skill.\n\nAdd nello (doubles-suit, declId=8) support to the Python/CUDA solver.\n\n## Nello Differences\n\n1. **3-player tricks**: Partner of winning bidder sits out\n2. **Turn order**: Skip partner in play order (depends on winningBidder identity)\n3. **Smaller state space**: 7³ = 343 trick combinations vs 7⁴ = 2401\n4. **Win condition**: Bidder's team must win NO tricks (inverse of normal)\n\n## Implementation Changes\n\n- `TRICK_WINNER[leader][i0][i1][i2]` - 3 indices instead of 4\n- `TRICK_POINTS[leader][i0][i1][i2]` - same\n- `nextPlayer[]` must skip partner\n- State packing: `trick_len` max is 2 instead of 3\n- Terminal condition: bidder wins ANY trick = instant loss\n\n## Context Required\n\nSolver context must include `winningBidder` to determine which player is partner (bidder + 2 mod 4).\n\n## Dependencies\n\nRequires t42-8zpu base solver working first.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-27T01:03:40.781606349-06:00","updated_at":"2025-12-27T01:03:40.781606349-06:00","dependencies":[{"issue_id":"t42-bncj","depends_on_id":"t42-8zpu","type":"blocks","created_at":"2025-12-27T01:03:40.788254017-06:00","created_by":"jason"},{"issue_id":"t42-bncj","depends_on_id":"t42-fe6f","type":"blocks","created_at":"2025-12-27T09:56:35.84709156-06:00","created_by":"jason"}]}
{"id":"t42-bs2c","title":"Refactor minimax.test.ts to use HeadlessRoom pattern","description":"Use texas-42 skill.\n\nThe minimax tests currently use `createTestContext` which is the unit test helper. This led to confusion when I needed to simulate full games - I didn't discover that HeadlessRoom with explicit layers (no consensus) is the canonical pattern.\n\nRefactor minimax.test.ts to use HeadlessRoom, making it a better example for future simulation code.","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-24T10:52:52.468885142-06:00","updated_at":"2025-12-24T10:57:35.219885164-06:00","closed_at":"2025-12-24T10:57:35.219885164-06:00","close_reason":"Added createSimulationContext helper with clear documentation. Refactored minimax.test.ts to use it. All tests pass."}
{"id":"t42-bue","title":"Audit for dead code and redundant logic","description":"Scan the codebase for clearly dead code or obviously redundant logic and suggest removal. This includes:\n- Unused functions, classes, or variables\n- Commented-out code blocks\n- Duplicate logic that could be consolidated\n- Unreachable code paths\n- Unused imports or exports","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-26T22:24:18.355156108-06:00","updated_at":"2025-12-20T22:18:59.825080096-06:00","closed_at":"2025-11-27T00:01:49.851705388-06:00"}
{"id":"t42-bwxy","title":"Document symmetry analysis for hand shapes and bidding","description":"Use texas-42 skill.\n\nWrite a document (docs/SYMMETRY_ANALYSIS.md) summarizing the symmetry exploration we conducted:\n\n## Key Findings to Document\n\n### Hand Shape Enumeration\n- 1,184,040 total hands (C(28,7))\n- 177,950 unique hand shapes under S₇ symmetry\n- 6.7× reduction factor\n- Computed via degree-preserving permutation canonicalization\n\n### Opposing Configuration Space\n- Given your hand shape, 400M raw partitions of remaining 21 dominoes\n- Sampling shows nearly all partitions yield unique (partner_shape, opp_shapes) triples\n- ~10× reduction at best (still ~40M configs per hand shape)\n- S₇ symmetry is \"used up\" by canonicalizing your hand - opposing hands have fixed pip labels\n\n### Implications for Bidding\n- Cannot enumerate all opposing configurations\n- Sampling approach is correct: solve random deals, average by your_shape\n- Bidding table: 178K shapes × 4 decl types = 712K entries (~2.8 MB)\n- 1M solved deals → ~5-6 samples per (shape, decl) entry\n\n### Scripts Created\n- scratch/count-hand-shapes-fast.ts - enumerates all 178K shapes\n- scratch/count_opposing_configs.py - samples opposing configs\n\n## Document Structure\n1. The Question: How much does symmetry reduce the bidding problem?\n2. Hand Shapes: S₇ equivalence, canonicalization, 178K result\n3. Opposing Configurations: why they don't collapse as much\n4. Practical Implications: sampling-based bidding table\n5. Connection to SUIT_ALGEBRA_SOLVER.md","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T00:10:24.201228068-06:00","updated_at":"2025-12-27T00:10:24.201228068-06:00"}
{"id":"t42-bxxp","title":"Remove ad-hoc minimal GameState constructors with magic defaults","description":"Use texas-42 skill.\\n\\nThere are multiple helpers that construct partial/minimal GameState objects by hand (theme 'coffee', gameTarget 250, etc.). This duplicates GameState shape, is easy to drift as fields evolve, and conflicts with 'correct by construction'.\\n\\nEvidence:\\n- src/game/core/rules.ts getTrickWinner() creates a manual minimal GameState\\n- src/game/ai/utilities.ts createMinimalAnalysisState() creates another manual GameState\\n\\nFix direction:\\n- Replace with createSetupState/createInitialState + overrides, OR introduce a single minimalState factory in core/state.ts\\n- Avoid hard-coded theme/gameTarget values in analysis helpers unless required","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-27T00:30:45.737895067-06:00","updated_at":"2025-12-27T00:30:45.737895067-06:00","dependencies":[{"issue_id":"t42-bxxp","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:30:45.741416836-06:00","created_by":"jason"}]}
{"id":"t42-c1f","title":"Use seedfinder to find seeds with biddable hands for slow tests","description":"Use texas-42 skill.\n\nThe slow integration tests (like complete-game-flow) can get stuck in redeal loops when all 4 players have mediocre hands and pass. This makes tests slow and flaky.\n\n## Problem\n- Random seeds may produce hands where no player has a 50%+ make rate\n- All players pass → redeal → repeat (sometimes 5-10+ times)\n- Tests become slow and potentially flaky\n\n## Solution\nUse the seedfinder to pre-select seeds that produce at least one biddable hand:\n1. Run seedfinder with criteria: \"at least one player has make rate \u003e= 50% for bid 30\"\n2. Store good seeds as constants in test fixtures\n3. Use these seeds in slow/integration tests\n\n## Relevant code\n- `src/game/ai/gameSimulator.ts` - has `findCompetitiveSeed()` \n- `src/tests/integration/complete-game-flow.test.ts` - uses random seeds currently","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-02T23:30:06.028397013-06:00","updated_at":"2025-12-20T22:18:59.796869241-06:00","labels":["performance","testing"]}
{"id":"t42-c84","title":"[Maintenance \u0026 Cleanup] Fix bid-validation.ts script - update strength ranges for lexicographic system","description":"The `scripts/bid-validation.ts` script was patched during the dead code cleanup (mk5-tailwind-bue) to use the new `calculateLexicographicStrength` function instead of the removed `calculateHandStrengthWithTrump`.\n\nHowever, the script's analysis logic still uses strength ranges designed for the old numeric system (0-150 range):\n\n```typescript\nconst strengthRanges = [\n  { min: 0, max: 25, label: '0-25' },\n  { min: 25, max: 35, label: '25-35' },\n  { min: 35, max: 45, label: '35-45' },\n  { min: 45, max: 60, label: '45-60' },\n  { min: 60, max: 80, label: '60-80' },\n  { min: 80, max: 100, label: '80-100' },\n  { min: 100, max: 999, label: '100+' }\n];\n```\n\nThe lexicographic system returns scores in the ~10^13 range, so:\n1. These strength ranges need to be updated for the new scale\n2. The laydown detection (`handStrength === 999`) may need updating\n3. The analysis output will be meaningless until ranges are calibrated\n\nThis is related to mk5-tailwind-oqd (AI Bidding System Overhaul) which addresses the broader lexicographic transition.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-27T00:01:42.400688637-06:00","updated_at":"2025-12-20T22:18:59.822735667-06:00","closed_at":"2025-11-29T11:17:30.031001904-06:00","dependencies":[{"issue_id":"t42-c84","depends_on_id":"t42-xxi","type":"parent-child","created_at":"2025-11-28T10:14:53.201593096-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-c9o","title":"Phase 16: Rename internal variables and comments (non-breaking)","description":"**Title**: Phase 16: Rename internal variables and comments to use \"layer\" terminology","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T13:51:33.07855279-06:00","updated_at":"2025-12-20T22:18:59.767627586-06:00","closed_at":"2025-11-24T14:16:45.044264044-06:00","dependencies":[{"issue_id":"t42-c9o","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T13:51:58.964629893-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-cfb","title":"Integrate MCCFR strategy into playable game","description":"Use texas-42 skill.\n\nMake the trained MCCFR strategy available as a playable AI opponent in the game.\n\n## Current State (Updated 2025-12-13)\n\n- MCCFR training infrastructure complete (`src/game/ai/cfr/`)\n- **Raw JSON strategy exists**: `trained-strategy.json` (172MB, 250k iterations)\n- `MCCFRStrategy` class implements `AIStrategy` interface\n- Strategy uses heuristics for bidding/trump, trained regrets for playing phase\n- CFD2 compact format available for production deployment\n\n## Minimum Integration (see mk5-tailwind-NEW)\n\nJust 3 changes to actionSelector.ts:\n1. Import MCCFRStrategy and trained-strategy.json\n2. Add 'mccfr' to AIStrategyType\n3. Add mccfr instance to strategies map\n\n## Future Work\n\n### Production optimization\n- Use CFD2 format (~1.3MB vs 172MB JSON)\n- Lazy loading / code splitting\n- UI for AI difficulty selection\n\n### Full MCCFR (depends on i2s)\n- Train bidding phase (currently uses heuristics)\n- Train trump selection (currently uses hand-strength heuristics)\n\n## Files\n\n- `src/game/ai/actionSelector.ts` - Strategy registry\n- `src/game/ai/cfr/mccfr-strategy.ts` - MCCFRStrategy class\n- `trained-strategy.json` - 250k iteration trained model (root dir)\n- `src/game/ai/cfr/compact-format-v2.ts` - CFD2 for production","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-07T22:28:56.031779779-06:00","updated_at":"2025-12-20T22:18:59.720428564-06:00","closed_at":"2025-12-20T22:05:59.384551278-06:00","close_reason":"MCCFR removed from codebase","dependencies":[{"issue_id":"t42-cfb","depends_on_id":"t42-i2s","type":"blocks","created_at":"2025-12-07T22:28:56.057245708-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-cfb","depends_on_id":"t42-l4t","type":"blocks","created_at":"2025-12-13T19:03:50.516380057-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-cfb","depends_on_id":"t42-d6g","type":"parent-child","created_at":"2025-12-20T08:52:15.282411102-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-cfb","depends_on_id":"t42-tgr","type":"blocks","created_at":"2025-12-20T08:53:18.441085388-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-cjw","title":"Simulation hot path optimizations (quick wins)","description":"Use texas-42 skill.\n\n## Context\n\nMonte Carlo AI runs millions of `executeAction` calls. Analysis found several low-hanging optimizations.\n\n## Quick Wins\n\n### 1. Cache `ALL_DOMINOES` Array\n**Location**: `src/game/core/dominoes.ts:15`\n**Problem**: `createDominoes()` creates 28 new Domino objects on every call\n**Fix**: Export frozen singleton array\n**Impact**: ~30% allocation reduction\n\n### 2. Skip `actionHistory` in Simulation\n**Location**: `src/game/core/actions.ts:27-30`\n**Problem**: Every `executeAction` copies growing array (useless in rollouts)\n**Fix**: Add `executeActionFast` variant or flag\n**Impact**: Eliminates 30 array copies per hand\n\n### 3. Move Candidate Computation Outside Loop\n**Location**: `src/game/ai/monte-carlo.ts` (evaluatePlayActions)\n**Problem**: `getCandidateDominoes` rebuilds for each of 50 simulations\n**Fix**: Compute once before loop\n**Impact**: ~20% faster sampling\n\n### 4. Memoize `canFollow` Results\n**Location**: `src/game/ai/hand-sampler.ts:90`\n**Problem**: Same (domino, suit) pairs checked repeatedly\n**Fix**: Build lookup map once per evaluation\n**Impact**: ~15% fewer rule evaluations\n\n## These Are Independent of Suit Refactoring\n\nCan be done before or after the suitAnalysis lazy refactor.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T17:56:13.152518987-06:00","updated_at":"2025-12-21T22:05:38.551850481-06:00","closed_at":"2025-12-21T22:05:38.551850481-06:00","close_reason":"Implemented 3 of 4 quick wins: (1) cached ALL_DOMINOES at module level in constraint-tracker.ts, (2) added skipHistory option to executeAction used in minimax/monte-carlo, (4) built canFollow lookup cache once per PIMC evaluation. Item 3 (hoist candidate computation) was partially addressed - candidates still computed per simulation but now using cached canFollow lookups making it much faster.","labels":["ai","performance"],"dependencies":[{"issue_id":"t42-cjw","depends_on_id":"t42-e92","type":"parent-child","created_at":"2025-12-20T17:56:18.434023661-06:00","created_by":"jason"}]}
{"id":"t42-cni","title":"User-Facing Features","description":"User-facing features that improve the player experience and entry points.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-11-28T10:14:25.084849865-06:00","updated_at":"2025-12-20T22:18:59.679809268-06:00","closed_at":"2025-11-28T10:21:24.279578377-06:00"}
{"id":"t42-d1z","title":"Stale comment in gameSimulator.ts claims 'ALWAYS beginner strategy'","description":"## Problem\n\nIn `src/game/ai/gameSimulator.ts:187`, there's a misleading comment:\n\n```typescript\n// For AI players, select action using AI selector (ALWAYS beginner strategy)\nif (playerTypes[currentPlayer] === 'ai') {\n  const selected = selectAIAction(state, currentPlayer, playerActions);\n```\n\nThe comment says \"ALWAYS beginner strategy\" but `selectAIAction` actually uses whatever strategy is set via `setDefaultAIStrategy()`. This is how intermediate AI games work - you set the default strategy and `simulateGame` respects it.\n\n## Impact\n\nLow - just confusing for developers reading the code.\n\n## Suggested Fix\n\nUpdate the comment to reflect reality:\n\n```typescript\n// For AI players, select action using the current default AI strategy\n// (set via setDefaultAIStrategy, defaults to 'beginner')\n```","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-25T21:12:04.229027137-06:00","updated_at":"2025-12-20T22:18:59.827409426-06:00","closed_at":"2025-11-26T22:23:48.21477463-06:00"}
{"id":"t42-d2ia","title":"Sevens Variant: Algebraic Model Extension","description":"**Status:** pending  \n**Discovered-from:** t42-9xy3 (Factored Algebraic Model for Dominoes)\n\n---\n\n## Context\n\nThe factored algebraic model (t42-9xy3) handles standard trick-taking where:\n- **Rank** = pip sum (higher wins)\n- **Power** = trump dominoes beat non-trump\n\nSevens uses a completely different rank function: **closest to 7 pips wins**.\n\n---\n\n## Sevens Rules (from docs/rules.md)\n\n- Domino closest to 7 total pips wins trick\n- 3-4 (exactly 7 pips) is unbeatable\n- Equidistant ties (e.g., 6 pips vs 8 pips) → first played wins\n- Must win all tricks (like plunge/splash)\n- Requires 1+ mark bid\n\n---\n\n## The Question\n\nHow does Sevens fit the absorption/power model?\n\n### Absorption\nSevens likely uses `absorptionId = 8` (no absorption) or possibly doubles-separate. Need to verify against rules - can you follow suit in Sevens, or is it pure \"play anything\"?\n\n### Power\nSevens doesn't have a \"power suit\" - no dominoes trump others based on suit membership. But it does have a different **rank function**.\n\n### Rank\nThis is where Sevens diverges. Instead of:\n```typescript\nRANK[d][powerId] = pipSum + (hasPower ? 50 : 0) + (isTopTrump ? 50 : 0)\n```\n\nSevens needs:\n```typescript\nSEVENS_RANK[d] = -Math.abs(pipSum - 7)  // closer to 7 = higher rank\n// 3-4 (7 pips) → 0 (highest)\n// 2-4, 3-3, 1-5, 0-6 (6 pips) → -1\n// etc.\n```\n\n---\n\n## Options\n\n### Option A: Separate Rank Table\nAdd `SEVENS_RANK[d]` as a separate 28-entry table. The `rankInTrick` rule checks trump type:\n\n```typescript\nrankInTrick: (state, led, domino) =\u003e {\n  if (state.trump?.type === 'sevens') {\n    return SEVENS_RANK[dominoToId(domino)];\n  }\n  return RANK[dominoToId(domino)][getPowerId(state)];\n}\n```\n\n### Option B: Extend PowerId\nAdd `powerId = 9` for Sevens mode. Extend RANK table to 28 × 10 = 280 entries.\n\n```typescript\nRANK[d][9] = -Math.abs(pipSum - 7);\n```\n\n### Option C: Layer Override\nKeep tables as-is. Sevens layer overrides `rankInTrick` with its own logic:\n\n```typescript\n// sevens.ts\nexport const sevensLayer: Layer = {\n  name: 'sevens',\n  rules: {\n    rankInTrick: (state, led, domino, prev) =\u003e\n      state.trump?.type === 'sevens'\n        ? -Math.abs(domino.high + domino.low - 7)\n        : prev,\n  }\n};\n```\n\n---\n\n## Recommendation\n\n**Option C (Layer Override)** seems cleanest:\n- Sevens is rare (\"rarely accepted in serious play\" per rules.md)\n- Keeps the core tables focused on the common case\n- Sevens layer already exists and overrides other behaviors\n- No need to complicate the absorption/power model for an edge case\n\nBut if GPU simulation of Sevens matters, Option B keeps everything table-driven.\n\n---\n\n## Work Items\n\n- [ ] Verify Sevens follow-suit rules (is there a led suit concept?)\n- [ ] Decide: layer override vs table extension\n- [ ] Implement chosen approach\n- [ ] Add tests for Sevens ranking edge cases (ties at equidistant)","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-25T18:58:20.115005116-06:00","updated_at":"2025-12-25T18:58:20.115005116-06:00","dependencies":[{"issue_id":"t42-d2ia","depends_on_id":"t42-9xy3","type":"discovered-from","created_at":"2025-12-25T18:58:26.414594639-06:00","created_by":"jason"}]}
{"id":"t42-d6g","title":"Remove MCCFR and Document Learnings","description":"MCCFR was an interesting exploration but is being removed from the codebase. This epic tracks the cleanup work and ensures lessons learned are documented for posterity.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T08:51:58.188261434-06:00","updated_at":"2025-12-20T22:18:59.712081095-06:00","closed_at":"2025-12-20T22:06:00.644741274-06:00","close_reason":"Epic complete - MCCFR removed and documented","dependencies":[{"issue_id":"t42-d6g","depends_on_id":"t42-tgr","type":"blocks","created_at":"2025-12-20T09:34:49.590936089-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-dkn","title":"Extract consensus into optional layer","description":"## Overview\n\nExtract consensus logic from core engine into a **composable `consensus` layer**. This makes consensus optional:\n\n- **Without consensus layer** (AI, simulations, URL replay, tests): Game flows instantly\n- **With consensus layer** (real multiplayer games): Same \"tap to continue\" UI as today\n\n## Key Insight\n\n**Consensus is PACING, not GAME LOGIC.** Agree actions don't affect game outcome - they just gate when `complete-trick` becomes available. They shouldn't be in GameState or URLs.\n\n## Current Architecture (Problem)\n\nConsensus is deeply coupled:\n1. `base.ts` generates agree actions directly\n2. `types.ts` has `consensus` state in GameState\n3. `actions.ts:316` - `executeCompleteTrick` **validates** consensus\n4. `actions.ts:394` - `executeScoreHand` **validates** consensus\n5. `url-compression.ts` includes agree actions in URLs\n6. Every AI strategy has hardcoded consensus prioritization\n\n## Target Architecture\n\n1. **Remove consensus validation from executors** - pure game logic\n2. **Remove `consensus` from GameState** - no state pollution\n3. **Create `consensus` layer** - derives acks from `state.actionHistory`\n4. **URLs become cleaner** - no pacing actions, old URLs filtered for backward compat\n\n### Layer Composition\n```typescript\n// AI/simulations/URL replay - no consensus layer\nlayers: ['speed']  // complete-trick executes immediately\n\n// Real multiplayer games - with consensus layer\nlayers: ['consensus', 'speed']  // UI pacing via agree actions\n```\n\n## Consensus Layer Design\n\nLayer derives acknowledgments from `state.actionHistory` - pure function, no GameState pollution:\n\n```typescript\nexport const consensusLayer: Layer = {\n  name: 'consensus',\n  getValidActions: (state: GameState, prev: GameAction[]): GameAction[] =\u003e {\n    const hasCompleteTrick = prev.some(a =\u003e a.type === 'complete-trick');\n    if (hasCompleteTrick) {\n      const trickAcks = countAcksSinceLastAction(state.actionHistory, 'agree-complete-trick', 'complete-trick');\n      if (trickAcks.size \u003c 4) {\n        // Gate: replace complete-trick with agree actions\n        const filtered = prev.filter(a =\u003e a.type !== 'complete-trick');\n        for (let p = 0; p \u003c 4; p++) {\n          if (!trickAcks.has(p)) {\n            filtered.push({ type: 'agree-complete-trick', player: p });\n          }\n        }\n        return filtered;\n      }\n    }\n    // Similar for score-hand...\n    return prev;\n  }\n};\n```\n\n## URL Strategy\n\n- Agree actions are **ephemeral** - exist in live sessions, not persisted to URLs\n- Old URLs with agree actions → filtered during decompression (backward compat)\n- New URLs → just meaningful actions\n\n## Files Affected (20 source files)\n\n### New\n- `src/game/layers/consensus.ts` - The new layer\n- `src/tests/layers/consensus.test.ts` - Layer tests\n\n### Core Engine - REMOVE consensus\n- `src/game/types.ts` - Remove `consensus` from GameState, remove agree action types\n- `src/game/core/state.ts` - Remove `consensus` initialization\n- `src/game/core/actions.ts` - Remove `executeAgreement()`, remove consensus validation (lines 314-318, 393-396)\n- `src/game/layers/base.ts` - Remove agree action generation\n- `src/game/layers/registry.ts` - Register new consensus layer\n- `src/game/layers/index.ts` - Export new layer\n\n### URL Compression\n- `src/game/core/url-compression.ts` - Remove agree compression chars, add backward-compat filter\n\n### AI Cleanup\n- `src/game/ai/actionSelector.ts` - Remove consensus check (lines 73-80)\n- `src/game/ai/strategies.ts` - Remove consensus handling\n- `src/game/ai/strategies/intermediate.ts` - Remove consensus handling\n- `src/game/ai/gameSimulator.ts` - Simplify\n- `src/game/ai/monte-carlo.ts` - Remove action labels (lines 340-343)\n\n### Kernel/View\n- `src/kernel/kernel.ts` - Remove `isRecommendedAction` agree check (line 281)\n- `src/game/view-projection.ts` - Update consensus filtering (lines 193, 242, 250)\n\n### Tests\n- `src/tests/helpers/consensusHelpers.ts` - **DELETE**\n- `src/tests/layers/integration/*.test.ts` - Simplify (no consensus loops)\n- `src/tests/fixtures/game-states.ts` - Remove mock consensus states\n- `src/tests/unit/authorization.test.ts` - Update\n- `src/tests/unit/trick-winner-leads.test.ts` - Check/update\n- `src/tests/e2e/helpers/game-helper.ts` - Update selectors (lines 86, 771-772, 829)\n\n### Scripts\n- `scripts/bid-validation.ts` - Update (line 229)\n\n## Implementation Order\n\n1. Decouple core engine (remove consensus validation from executors)\n2. Create consensus layer\n3. Update URL compression (backward compat filter)\n4. Update AI (remove consensus handling)\n5. Update tests (simplify, delete consensusHelpers)\n6. Verify with `npm run test:all`","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-27T10:33:00.188005715-06:00","updated_at":"2025-12-20T22:18:59.74529178-06:00","closed_at":"2025-11-27T11:15:30.158304807-06:00"}
{"id":"t42-dlx","title":"Overview","description":"Final cleanup to eliminate ALL remaining \"RuleSet\" and \"variant\" terminology from the codebase. The crystal palace must be pristine.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T16:24:26.886848679-06:00","updated_at":"2025-12-20T22:18:59.762905335-06:00","closed_at":"2025-11-25T08:55:02.174378197-06:00"}
{"id":"t42-dmze","title":"Remove vestigial ranking code and fix test expectations","description":"Use texas-42 skill.\n\nFollow-up from t42-y27y (unify ranking to SUIT_ALGEBRA.md).\n\n## Test Failures to Fix\n\n3 tests fail due to encoding change from old (200+/50+/pipSum) to algebra (32-46/16-30/0):\n\n### 1. doubles-trump-bug.test.ts (2 failures)\n- Lines 40, 90: Tests expect `rank \u003e= 200` for trump\n- Fix: Update to expect `rank \u003e= 32` (Tier 2 encoding)\n- The test logic is correct, just the threshold value changed\n\n### 2. dominoes.test.ts (1 failure)\n- Line 135: `expect(fiveDouble \u003e zeroDouble)` when sixes trump\n- Bug in test: 5-5 and 0-0 are BOTH sloughs when 6s are trump (they don't contain 6)\n- Old behavior: sloughs ranked by pipSum (10 \u003e 0)\n- New behavior: sloughs all return 0 (per algebra §8)\n- Fix: Either remove this assertion or test a meaningful case\n\n## Vestigial Code to Assess\n\n### domino-tables.ts exports\n- `getTrickWinnerFromTable()` - Uses RANK table directly, doesn't compute full τ\n- `getRankFromTable()` - Returns raw RANK value, not the 3-tier τ\n\nThese functions encode the OLD ranking semantics. Options:\n1. Remove them if unused elsewhere\n2. Update them to use proper τ computation\n3. Document they return raw power rank, not trick rank\n\n## Completed in t42-y27y\n\n- ✅ Nello now delegates rankInTrick to base (uses κ(δ) = D° condition)\n- ✅ SUIT_ALGEBRA.md updated with doubles-trump vs doubles-suit terminology","acceptance_criteria":"- [ ] All 3 failing tests fixed and passing\n- [ ] Assess getTrickWinnerFromTable and getRankFromTable usage/removal\n- [ ] SUIT_ALGEBRA.md updated with nello ranking note\n- [ ] npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T18:23:15.411080629-06:00","updated_at":"2025-12-26T18:54:04.307305454-06:00","closed_at":"2025-12-26T18:54:04.307305454-06:00","close_reason":"Fixed 3 failing tests, removed unused vestigial functions, updated SUIT_ALGEBRA.md with nello note","dependencies":[{"issue_id":"t42-dmze","depends_on_id":"t42-y27y","type":"discovered-from","created_at":"2025-12-26T18:23:21.369696764-06:00","created_by":"jason"}]}
{"id":"t42-don","title":"Simplify Multiplayer Architecture","description":"Replace overcomplicated multiplayer code with simple, industry-standard patterns inspired by PartyKit/Colyseus/boardgame.io.\n\nSee docs/MULTIPLAYER.md for the complete architecture specification.\n\n**Approach**: Roll forward / clean break / NO backwards compatibility whatsoever.\n\n**Core changes**:\n- Room takes a `send` function, doesn't know about transport\n- GameClient is ~40 lines, wraps Socket, subscribes to state\n- AI clients are just GameClients with AI behavior attached\n- Socket interface: `send()`, `onMessage()`, `close()`\n\n**Success metrics**:\n- NetworkGameClient: 550 lines → 40 lines\n- Total multiplayer code: ~50% reduction\n- Concepts: Transport, Connection, NetworkGameClient, AIManager → Socket, GameClient, Room","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-11-25T14:49:14.536581253-06:00","updated_at":"2025-12-20T22:18:59.756772381-06:00","closed_at":"2025-11-25T16:20:29.593447197-06:00"}
{"id":"t42-dpp","title":"[Maintenance \u0026 Cleanup] Create skill from test conversation patterns","description":"Look back at the test conversation and extract reusable patterns into a skill. This could capture effective testing workflows, debugging approaches, or other patterns worth codifying.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-27T20:55:18.318497056-06:00","updated_at":"2025-12-20T22:18:59.818146686-06:00","closed_at":"2025-11-29T10:48:40.194074649-06:00"}
{"id":"t42-dt2","title":"Phase 7: Migrate speed and hints to Layers","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.311722304-06:00","updated_at":"2025-12-20T22:18:59.775564423-06:00","closed_at":"2025-11-24T13:30:03.98902356-06:00","dependencies":[{"issue_id":"t42-dt2","depends_on_id":"t42-ygk","type":"blocks","created_at":"2025-11-24T10:35:47.833148941-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-dt2","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:52.205586211-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-e69","title":"Future Features","description":"Ambitious future work - neural network AI, voting mechanisms, and other enhancements.","status":"closed","priority":3,"issue_type":"epic","created_at":"2025-11-28T10:14:25.942703619-06:00","updated_at":"2025-12-20T22:18:59.815858162-06:00","closed_at":"2025-11-28T10:21:24.573234593-06:00"}
{"id":"t42-e92","title":"Epic: Suit system consolidation + simulation performance","description":"Use texas-42 skill.\n\n## Vision\n\nUnify the scattered suit-related code and eliminate performance waste in simulation hot paths. This is a recurring problem area that keeps biting us.\n\n## Background\n\nAnalysis of Monte Carlo simulation revealed:\n- **~834 object allocations per hand rollout**\n- **~292,000 allocations per Monte Carlo evaluation**\n- **~50% of allocations** are for `suitAnalysis` which is **never read by AI**\n\nThe `suitAnalysis` field is:\n- Computed on every play action (~15 allocations each)\n- Computed for all 4 players on trump selection (~60 allocations)\n- Never read by `determineBestTrump` (parameter is `_suitAnalysis` = ignored)\n- Never read by `HeuristicRolloutStrategy` (uses its own `analyzeHand`)\n- Only consumed by UI stores\n\n## This Epic Combines\n\n1. **mk5-tailwind-ofy** - Complete canFollow consolidation (3 implementations → 1)\n2. **mk5-tailwind-v17** - Make suitAnalysis lazy/derived (already has design)\n3. New: Simulation-mode optimizations (skip actionHistory, cache dominoes)\n\n## Expected Outcomes\n\n- Single source of truth for suit-following logic\n- suitAnalysis computed on-demand (impossible to be stale)\n- 50-70% fewer allocations in simulation hot path\n- Foundation for future FastSimulator if needed","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-20T17:55:42.031017994-06:00","updated_at":"2025-12-20T22:18:59.708620978-06:00","labels":["core","performance","refactor"]}
{"id":"t42-ecj","title":"Fix types.ts GameRules comment: says 13 but there are 14 methods","description":"The comment in `src/game/layers/types.ts` line 20 says \"13 composable rules\" but there are actually 14 methods in the interface.\n\nThe LIFECYCLE category with `getPhaseAfterHandComplete` was added later and the comment wasn't updated.\n\nFix:\n1. Change \"13 composable rules\" to \"14 composable rules\" on line 20\n2. Add LIFECYCLE to the category list in the comment (lines 22-27) to show all 6 categories","status":"closed","priority":3,"issue_type":"bug","created_at":"2025-11-26T23:17:07.645199806-06:00","updated_at":"2025-12-20T22:18:59.823519531-06:00","closed_at":"2025-11-26T23:31:07.602919119-06:00","labels":["docs","types"]}
{"id":"t42-f26","title":"Delete Perfects feature completely","description":"Use texas-42 skill.\n\n## Task\nCompletely eradicate the Perfects feature from the codebase, keeping only:\n- `docs/archive/perfects-feature.md` (the documentation we created)\n- Git history (naturally preserved)\n\n## Files to Delete\n\n### UI Components\n- `src/PerfectsApp.svelte`\n- `src/lib/components/PerfectHandDisplay.svelte`\n\n### UI Utilities (contain game logic that violates client boundary)\n- `src/lib/utils/dominoHelpers.ts`\n- `src/lib/utils/domino-sort.ts`\n\n### Scripts\n- `scripts/find-perfect-hands.ts`\n- `scripts/find-perfect-partition.ts`\n- `scripts/find-3hand-leftover.ts`\n\n### Data Files\n- `data/perfect-hands.json`\n- `data/3hand-partitions.json`\n\n### Tests\n- `src/tests/e2e/perfects-page.spec.ts`\n\n### Scratch/Output\n- `scratch/perfect-hands-output.txt` (if exists)\n\n## Also Check For\n- Any vite/svelte config entries for PerfectsApp\n- Any routes pointing to /perfects\n- Any imports of dominoHelpers or domino-sort elsewhere\n- Any references to PerfectHandDisplay\n\n## Verification\nAfter deletion, run:\n- `npm run typecheck` - no errors\n- `npm run test:all` - all pass\n- Grep for \"Perfect\" and \"dominoHelper\" to ensure nothing remains","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T10:44:29.380467173-06:00","updated_at":"2025-12-21T11:20:08.043008839-06:00","closed_at":"2025-12-21T11:20:08.043008839-06:00","close_reason":"Deleted all Perfects feature files, cleaned up main.ts routing, removed package.json scripts. All tests pass.","dependencies":[{"issue_id":"t42-f26","depends_on_id":"t42-g4y","type":"parent-child","created_at":"2025-12-21T10:44:37.327491216-06:00","created_by":"jason"}]}
{"id":"t42-f79","title":"[Architecture \u0026 Code Quality] Architecture guard: Detect and prevent backwards compatibility code","description":"Subagents frequently introduce backwards compatibility patterns that then need manual removal. This is a greenfield project with no external users - backwards compat is never needed.\n\n**Problem patterns commonly introduced:**\n1. `@deprecated` functions that wrap new functions (e.g., `trumpToNumber`, `getDominoSuit`, `canDominoFollowSuit`)\n2. \"Legacy fields for test/backward compatibility\" comments\n3. Re-exports or aliases for renamed functions\n4. `// for compatibility` or `// maintain compatibility` comments\n5. `_old`, `_legacy`, `_deprecated` suffixed variables/functions\n6. Functions/types that just delegate to newer versions\n7. Renamed-but-kept-old-name patterns\n\n**Existing patterns to follow:**\n- `src/tests/architecture/composition.test.ts` - Uses grep + allowlist pattern for architectural invariants\n- `eslint.config.js` - Uses `no-restricted-imports` for preventing bad imports\n\n**Proposed solution:**\nCreate `src/tests/architecture/no-backwards-compat.test.ts` that:\n1. Greps for backwards compat indicator patterns\n2. Has an explicit allowlist file for any legitimate exceptions\n3. Runs as part of `npm run test:all` (already includes vitest)\n\n**Patterns to detect:**\n```typescript\n// Code patterns\n/@deprecated/\n/legacy.*compat/i\n/backward.*compat/i\n/for.*compat/i\n/maintain.*compat/i\n/_legacy|_old|_deprecated/\n\n// Comment patterns (more targeted)\n/\\/\\/.*legacy/i  \n/\\/\\/.*compat/i\n/\\/\\/.*renamed/i\n/\\/\\*\\*[\\s\\S]*@deprecated/\n```\n\n**Allowlist format** (e.g., `.no-backwards-compat-allowlist`):\n```\n# Each line is file:pattern that's allowed\n# Empty lines and # comments ignored\nsrc/game/types.ts:@deprecated  # Semantic constants note\n```\n\n**Example test structure:**\n```typescript\ndescribe('Architecture: No Backwards Compatibility', () =\u003e {\n  it('no @deprecated annotations', () =\u003e {\n    const violations = grepForPattern(/@deprecated/, ALLOWLIST);\n    expect(violations).toHaveLength(0);\n  });\n\n  it('no legacy compatibility comments', () =\u003e {\n    const patterns = [/legacy.*compat/i, /backward.*compat/i];\n    const violations = patterns.flatMap(p =\u003e grepForPattern(p, ALLOWLIST));\n    expect(violations).toHaveLength(0);\n  });\n});\n```\n\n**Current violations to clean up:**\n- `src/game/core/dominoes.ts:78` - `trumpToNumber` @deprecated\n- `src/game/core/dominoes.ts:211` - `getDominoSuit` @deprecated  \n- `src/game/core/dominoes.ts:259` - `canDominoFollowSuit` @deprecated\n- `src/game/ai/gameSimulator.ts:33` - Legacy fields comment\n- `src/game/types.ts:29` - @deprecated comment (may be legitimate)\n- `src/tests/e2e/helpers/game-helper.ts:633` - DEPRECATED navigateTo","acceptance_criteria":"- [ ] Architecture test exists at `src/tests/architecture/no-backwards-compat.test.ts`\n- [ ] Test detects @deprecated, legacy compat comments, _legacy/_old suffixes\n- [ ] Allowlist mechanism exists for legitimate exceptions\n- [ ] All current violations either cleaned up or explicitly allowlisted with justification\n- [ ] Test passes as part of `npm run test:all`\n- [ ] CLAUDE.md updated to mention this guard","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-27T10:22:38.144799903-06:00","updated_at":"2025-12-20T22:18:59.746160674-06:00","closed_at":"2025-11-29T12:25:40.714824504-06:00","labels":["architecture","dx"],"dependencies":[{"issue_id":"t42-f79","depends_on_id":"t42-ade","type":"parent-child","created_at":"2025-11-28T10:14:52.541331247-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-f8l","title":"Fix 'Unknown event' warnings for consensus actions in URL compression","description":"Use texas-42 skill.\n\n## Problem\n\nConsole logs show repeated warnings during gameplay:\n```\nUnknown event: agree-score-p0\nUnknown event: agree-trick-p0\n```\n\n## Source\n\nThe warning comes from `url-compression.ts:224` in `compressEvents()` function.\n\nStack trace shows:\n```\ncompressEvents @ url-compression.ts:216\nencodeGameUrl @ url-compression.ts:369\nstateToUrl @ url-compression.ts:588\n(anonymous) @ gameStore.ts:157  (URL sync subscription)\n```\n\n## Root Cause (likely)\n\nThe URL compression system doesn't recognize consensus layer actions (`agree-trick`, `agree-score`) that include player suffixes like `-p0`.\n\nThe consensus layer adds these actions (see `src/game/layers/consensus.ts`) but the URL compression event mapping probably only handles base action types.\n\n## Files to Investigate\n\n- `src/game/core/url-compression.ts` - Where the warning is logged\n- `src/game/layers/consensus.ts` - Source of agree-trick/agree-score actions\n- Check how action IDs are constructed vs how they're parsed\n\n## Impact\n\n- Console spam during normal gameplay\n- May affect URL state restoration for games with consensus actions\n\n## Completion Checklist\n\n1. Run `npm run test:all` and fix ANY issues (including pre-existing failures)\n2. Commit changes to git (do NOT push or bd sync)","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-13T19:38:49.913040422-06:00","updated_at":"2025-12-20T22:18:59.676445692-06:00","closed_at":"2025-12-20T10:23:53.390951281-06:00","close_reason":"Closed"}
{"id":"t42-fe6f","title":"GPU solver: PyTorch backward induction","description":"Use texas-42 skill.\n\nPyTorch GPU solver for Texas 42. Fully GPU - no CPU enumeration.\n\n## Implementation Status (as of 2025-12-27)\n\n**DONE:**\n- All modules implemented: tables.py, rng.py, state.py, context.py, expand.py, solve.py, output.py, main.py, validate.py\n- 95 unit tests passing\n- Full solve works: seed=100 decl=0 → 10.3M states in 22s\n\n**KNOWN ISSUES:**\n- t42-1a6e: 1-point cross-validation discrepancy with TS minimax\n- t42-q86b: Performance 22s vs target 2-3s (context tables not cached on device)\n\n---\n\n## LESSONS LEARNED (Critical!)\n\n### 1. Initial Leader is Player 1 (NOT 0)\nThe player left of dealer leads first. With dealer=0, that's player 1.\n\n\n### 2. State Space is ~10M (NOT 3M)\nActual state counts vary dramatically by seed:\n- seed=100: 10.3M states\n- seed=101: even larger (OOM)\n- Some seeds: only 240K states\n\nThe 3M estimate was optimistic. Budget for 10-20M.\n\n### 3. Memory-Optimized Expand Required\nOriginal expand_gpu created (N,4,7) tensor → 2.2GB for 10M states → OOM.\nFixed by processing one move at a time:\n\n\n### 4. Root Value is NOT at Index 0\nStates are sorted by packed value. Initial state (level 28) has LARGE value.\nTerminal states (level 0) are at the beginning.\n\n\n### 5. Context Tables Must Be Cached on Device\nexpand.py was doing .to(device) on 4 tensors every call (29+ times per solve).\nThis is the main perf issue. Fix: cache tables on device once in solve_seed.\n\n### 6. TypeScript Minimax Has Early Termination\nTS minimax ends early based on bid outcome (e.g., defending team sets bid).\nPython solver plays all 7 tricks. For cross-validation, wrote custom\nminimax-eval.ts that plays full games.\n\n---\n\n## What This Solver Does\n\n**Solves**: Maximize final point differential (team0 - team1) given a declaration\n**Input**: (seed, decl_id) where decl_id specifies trump\n**Output**: Minimax value for every reachable state (~10M per seed)\n\nThis produces training data for \"optimal trick-taking\" given a trump selection. The solver does NOT include bid value or contract-correct early termination - those are separate concerns.\n\n## Scope: MVP (Pip Trump Only)\n\nThis bead covers **pip trump declarations only** (absorption/power IDs 0-6).\nDoubles-trump, nello, sevens, no-trump are deferred to t42-bncj.\n\n---\n\n## File Structure\n\n```\nscripts/solver/\n├── __init__.py\n├── tables.py       # Matches TS domino-tables.ts (verified)\n├── rng.py          # Park-Miller LCG matching TS (verified)\n├── state.py        # 47-bit pack/unpack (verified)\n├── context.py      # SeedContext with L, LOCAL_FOLLOW, TRICK_WINNER, TRICK_POINTS\n├── expand.py       # Memory-optimized state expansion\n├── solve.py        # enumerate_gpu, build_child_index, solve_gpu, solve_seed\n├── output.py       # Parquet/JSON with atomic writes\n├── main.py         # CLI entry point\n├── validate.py     # Cross-validation vs TS minimax\n├── conftest.py     # pytest fixtures\n└── test_*.py       # 95 passing tests\nscripts/export-tables.ts   # TS table export for comparison\nscripts/minimax-eval.ts    # TS minimax for cross-validation (full game, no early term)\n```\n\n---\n\n## Acceptance Criteria\n\n- [x] tables.py matches TS domino-tables.ts (verified by JSON comparison)\n- [x] RNG produces identical deals to TS\n- [x] state.py pack/unpack round-trips correctly\n- [x] TRICK_POINTS uses correct range 1-31\n- [x] build_child_index includes searchsorted verification\n- [ ] Cross-validate 100+ seeds vs TS minimax (blocked by t42-1a6e: 1-point discrepancy)\n- [ ] ~2-3 seconds per seed (blocked by t42-q86b: currently 22s)\n- [ ] Crash recovery works (skip existing files)","status":"open","priority":1,"issue_type":"feature","created_at":"2025-12-27T09:49:26.156226051-06:00","updated_at":"2025-12-27T15:04:59.986282213-06:00"}
{"id":"t42-fka","title":"Consolidate layers tests with TestLayer isolation pattern","description":"Refactor the layers test suite from ~8,556 lines to ~2,090 lines (75% reduction) while maintaining comprehensive coverage.\n\n## The Problem\n\nCurrent tests conflate three concerns and test passthrough behavior redundantly:\n- plunge.ts: 18 lines → plunge-layer.test.ts: 532 lines (29:1 ratio!)\n- splash.ts: 18 lines → splash-layer.test.ts: 601 lines (33:1 ratio!)\n- Tests verify `isTrickComplete`, `getNextPlayer`, etc. in layers that don't override them\n\n## The Solution: TestLayer Pattern\n\nCreate a `TestLayer` utility that provides controllable identity values for isolated testing:\n\n```typescript\nconst testLayer = createTestLayer({ getTrumpSelector: () =\u003e PASSTHROUGH_SENTINEL });\nconst rules = composeRules([testLayer, plungeLayer]); // Tests ONLY plunge's 18 lines\n```\n\n## Key Changes\n\n**Create:**\n- `src/tests/helpers/TestLayer.ts` (~60 lines) - the key innovation\n- `doubles-bid-factory.test.ts` - parameterized plunge/splash tests\n- `must-win-all.test.ts` - parameterized integration for plunge/splash/sevens\n- `standard-game.test.ts`, `nello-three-player.test.ts`\n\n**Delete (10 files):**\n- unit/plunge-layer.test.ts, unit/splash-layer.test.ts\n- integration/plunge-full-hand.test.ts, splash-full-hand.test.ts, sevens-full-hand.test.ts, base-full-hand.test.ts\n- composition/layer-overrides.test.ts\n- edge-cases/trump-selection.test.ts, nello-edge-cases.test.ts\n- integration/early-termination-general.test.ts\n\n## Principles\n\n1. Test layers in isolation with TestLayer (not composed with base)\n2. Test composition mechanism once in compose-rules.test.ts\n3. Parameterize similar contracts (plunge/splash/sevens share \"must win all\")\n4. Use sentinel values to prove passthrough definitively\n\n## Estimated LOC Delta\n\n-6,466 lines (8,556 → 2,090)","design":"See plan file: /home/jason/.claude/plans/federated-purring-parrot.md","acceptance_criteria":"- Layer tests consolidated to ~2,100 lines or less\n- All critical layer behaviors still covered\n- TestLayer.ts created and used for isolation\n- No regression in actual coverage of important edge cases\n- Test organization is clean and discoverable","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-11-27T00:03:31.758165249-06:00","updated_at":"2025-12-20T22:18:59.750597117-06:00","closed_at":"2025-11-27T00:54:41.771420905-06:00"}
{"id":"t42-fls","title":"Research and consolidate layers tests","description":"The layers test suite is disproportionately large compared to the implementation.\n\nCurrent state:\n- src/game/layers implementation: 2,300 lines\n- src/tests/layers tests: 8,556 lines\n- Ratio: 3.7:1 (tests:code)\n\nGoal: ~1:1 code/test ratio (~2,300 lines of tests)\n\nThis means reducing tests by ~6,200 lines while preserving coverage of important behaviors.","acceptance_criteria":"- Layer tests consolidated to ~2,500 lines or less\n- All critical layer behaviors still covered\n- No regression in actual coverage of important edge cases\n- Test organization is clean and discoverable","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-11-26T23:33:30.57622899-06:00","updated_at":"2025-12-20T22:18:59.751352287-06:00","closed_at":"2025-11-27T00:05:31.345515588-06:00"}
{"id":"t42-fo5q","title":"JS inference for policy network (ONNX runtime)","description":"Use texas-42 skill.\n\n## Goal\n\nLoad trained policy network in JavaScript for browser/Node inference.\n\n## Approach\n\nUse ONNX Runtime Web (onnxruntime-web) for browser inference.\n\n## Files\n\n```\nsrc/game/ai/neural/\n├── policy-net.ts      # Load ONNX, run inference\n├── features.ts        # GameState → tensor\n└── index.ts           # Exports\n```\n\n## API\n\n```typescript\ninterface PolicyNet {\n  load(modelUrl: string): Promise\u003cvoid\u003e;\n  predict(state: PackedState): Promise\u003cFloat32Array\u003e;  // 7 logits\n}\n\n// Feature extraction\nfunction stateToTensor(\n  remaining: [number, number, number, number],\n  leader: number,\n  trickLen: number,\n  plays: [number, number, number],\n  declId: number\n): Float32Array;\n```\n\n## Integration Points\n\n- Model file served from /models/policy-net.onnx\n- ~100KB model size (100K params × 4 bytes + overhead)\n- Inference time: \u003c1ms per position\n\n## Dependencies\n\n- onnxruntime-web package\n- Trained model from t42-6hi4","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T20:58:00.254546674-06:00","updated_at":"2025-12-27T20:58:00.254546674-06:00","dependencies":[{"issue_id":"t42-fo5q","depends_on_id":"t42-6hi4","type":"blocks","created_at":"2025-12-27T20:58:21.842100446-06:00","created_by":"jason"}]}
{"id":"t42-fwi","title":"Implement ultra-compact CFD2 format for MCCFR strategy deployment","description":"Use texas-42 skill.\n\n## Goal\nReduce MCCFR strategy file size from ~40-60 MB to \u003c 10 MB for mobile deployment.\n\n## Results (Achieved)\n- **CFD2 format implemented** in `compact-format-v2.ts`\n- **Compression verified**: 171.5 MB JSON → 1.27 MB CFD2+gzip (135x compression)\n- **Round-trip verified**: 96,007 valid nodes preserved\n- **Target exceeded**: \u003c 10 MB goal, achieved 1.27 MB\n\n### Compression Stats (250K iteration strategy)\n| Format | Size | Compression |\n|--------|------|-------------|\n| Raw JSON | 171.5 MB | 1x |\n| Compact (cfr) | 6.92 MB | 25x |\n| Deploy (CFD1) | 2.62 MB | 65x |\n| Ultra (CFD2) | 1.84 MB | 93x |\n| CFD2 + gzip | 1.27 MB | 135x |\n\nCFD2 is 30% smaller than CFD1.\n\n## Files Created/Modified\n- `src/game/ai/cfr/compact-format-v2.ts` - CFD2 format implementation\n- `scripts/convert-strategy.ts` - Conversion with --format support\n- `scripts/merge-strategies.ts` - Merge distributed training runs\n- `scripts/train-mccfr.ts` - Added checkpointing, resume, gzip support\n- `src/game/ai/cfr/mccfr-trainer.ts` - Added runSingleIteration, serializeCheckpoint, serializeFinal\n- `src/game/ai/cfr/types.ts` - Type updates for checkpointing\n\n## Success Criteria\n- [x] v2 format is 50%+ smaller than v1 deploy format (achieved: 30% smaller)\n- [x] Deserialization \u003c 100ms for 100K nodes\n- [x] Works in browser without Node.js dependencies\n- [x] Maintains gameplay quality (verified via round-trip)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-08T17:23:33.602885706-06:00","updated_at":"2025-12-20T22:18:59.719414557-06:00","closed_at":"2025-12-13T18:15:16.234988507-06:00"}
{"id":"t42-fwn","title":"Scope","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T16:24:26.892034261-06:00","updated_at":"2025-12-20T22:18:59.762196392-06:00","closed_at":"2025-11-25T08:55:02.970817738-06:00"}
{"id":"t42-g4o","title":"Fix console logging errors for unknown URL compression events","description":"Use texas-42 skill.\n\nBrowser console shows errors like:\n```\nUnknown event: agree-trick-p0\n```\n\nThe stack trace shows this originates from `url-compression.ts:224` in `compressEvents`. The `agree-trick-p0`, `agree-trick-p1`, etc. events are not mapped in `EVENT_TO_CHAR`.\n\nEither:\n1. Add mappings for these player-specific agree events\n2. Or silence/handle unmapped events gracefully\n\n## Completion Checklist\n\n1. Run `npm run test:all` and fix ANY issues (including pre-existing failures)\n2. Commit changes to git (do NOT push or bd sync)","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-20T15:24:01.371164094-06:00","updated_at":"2025-12-20T22:18:59.709635937-06:00","closed_at":"2025-12-20T15:27:59.667639304-06:00","close_reason":"Not a bug - was testing with old code"}
{"id":"t42-g4y","title":"Trump/Suit/Followsuit unification (Crystal Palace)","description":"Problem:\\nSuit/trump/follow-suit logic is fractured: base.ts, compose.ts, and core/dominoes.ts each carry their own algorithms; core/scoring.ts calculates trick winners outside the layer system; AI and UI utilities bypass GameRules; suitAnalysis is cached on state; and the Perfects feature + UI helpers reimplement trump logic on the client, violating the dumb-client boundary from ORIENTATION/ARCHITECTURE_PRINCIPLES.\\n\\nGoals (Crystal Palace):\\n- One source of truth for suit/trump/follow semantics in a rules-base module; layers only override deltas.\\n- GameRules gains isTrump; all consumers (engine, AI, UI projection) call ExecutionContext.rules.* for led suit, follow, rank, trump checks, and trick winner.\\n- Core helpers are rule-agnostic (pip/deck/points only); trick-winner logic lives in rules.\\n- Server-owned projection: kernel/buildKernelView derives the UI view with rules + filtered state; clients consume serialized projection only.\\n- No cached suitAnalysis on state; compute on demand server/AI side.\\n- Perfects and client-side rule helpers removed; client remains dumb.\\n\\nPlan:\\n1) Add src/game/layers/rules-base.ts exporting getLedSuitBase, suitsWithTrumpBase, canFollowBase, rankInTrickBase, isTrumpBase.\\n2) Rewire base.ts and compose.ts to delegate to rules-base; no inline base logic in compose. Add rules.isTrump to GameRules + implementations/overrides.\\n3) Strip rule logic from core/dominoes.ts and core/scoring.ts (remove getLedSuit/isTrump/getDominoValue/calculateTrickWinner); update all call sites to use GameRules.\\n4) Server-side projection only: build UI projection in kernel/buildKernelView with rules + filtered state; client uses derived fields. Delete/neutralize rule-aware client helpers.\\n5) Remove suitAnalysis from GameState; compute when needed (server/AI), not stored on state.\\n6) Delete Perfects feature and trump/follow UI helpers (dominoHelpers, domino-sort, related scripts/data/tests).\\n7) Tests/guardrails: base + special-contract rule conformance on all canonical methods; no-bypass tests to block imports from core/dominoes.ts/scoring.ts for rule logic; projection security (no hidden state leaks).","acceptance_criteria":"- Single rules-base implementation feeds GameRules (including isTrump); no duplicate base logic in compose/base.\\n- No rule logic remains in core/dominoes.ts or core/scoring.ts; trick winner/led-suit/follow/trump decisions come from rules.*.\\n- Engine/AI/UI all consume ExecutionContext.rules for rule-aware decisions; client receives server-derived projection only.\\n- suitAnalysis is not stored on GameState; computed on demand server/AI side.\\n- Perfects feature and client trump/follow helpers removed.\\n- Guardrail/tests cover: base + special contracts, no-bypass imports, projection security.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-21T10:41:28.987445719-06:00","updated_at":"2025-12-21T12:24:06.732545598-06:00","closed_at":"2025-12-21T12:24:06.732545598-06:00","close_reason":"All acceptance criteria met: single rules-base implementation feeds GameRules (including isTrump), no rule logic in core/dominoes.ts or core/scoring.ts, all consumers use GameRules interface, suitAnalysis removed from state, Perfects feature removed, guardrail tests in place for base+special contracts, no-bypass imports, and projection security."}
{"id":"t42-gpwz","title":"Benchmark PIMC evaluation with 4/5/6/7 tricks remaining","description":"Use texas-42 skill.\n\n## Goal\nMeasure actual PIMC evaluation time with varying game tree depths to understand scaling behavior after the checkHandOutcome optimization (t42-4ytq).\n\n## Design\n\nCreate a benchmark script that:\n1. Runs PIMC eval with 4, 5, 6, 7 tricks remaining\n2. Writes interim results after each depth completes (7 may never finish)\n3. Uses a timeout per depth level (e.g., 60s) to avoid hanging\n4. Reports: time, nodes explored, nodes/sec for each depth\n\n```typescript\n// Pseudocode\nfor (const tricksRemaining of [4, 5, 6, 7]) {\n  const startTime = performance.now();\n  const result = runWithTimeout(() =\u003e minimaxEvaluate(state), 60000);\n  \n  // Write interim result immediately\n  console.log(`${tricksRemaining} tricks: ${time}ms, ${nodes} nodes`);\n  \n  if (result.timedOut) {\n    console.log(`${tricksRemaining} tricks: TIMEOUT after 60s`);\n    break; // Don't bother with deeper trees\n  }\n}\n```\n\n## Expected Scaling\n- 4 tricks: ~milliseconds (we saw 0.3ms)\n- 5 tricks: ~tens of ms\n- 6 tricks: ~seconds (branching factor ~4-7 per ply)\n- 7 tricks: likely minutes to hours (full game tree)\n\n## Output\nWrite results to scratch/pimc-depth-benchmark.txt for comparison.","status":"closed","priority":2,"issue_type":"task","assignee":"claude","created_at":"2025-12-24T08:16:56.584211835-06:00","updated_at":"2025-12-24T08:23:56.00368709-06:00","closed_at":"2025-12-24T08:23:56.00368709-06:00","close_reason":"Benchmark complete. Results in scratch/pimc-depth-benchmark.txt. All depths (2-7 tricks) complete in \u003c2ms with alpha-beta pruning. The checkHandOutcome optimization from t42-4ytq is working - early termination detected correctly at 2 tricks.","labels":["ai","benchmark","performance"]}
{"id":"t42-gt2","title":"[Architecture \u0026 Code Quality] Review git history for original consensus design comparison","description":"Use texas-42 skill. Look back through git history to understand the original consensus design and compare it to the current implementation. This is a research/retrospective task to ensure the implementation aligns with or consciously diverges from the original design intent.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-27T20:58:08.026849916-06:00","updated_at":"2025-12-20T22:18:59.817450497-06:00","closed_at":"2025-11-29T11:39:36.845269334-06:00"}
{"id":"t42-gv0","title":"Update all unit and integration tests","description":"Update 10 test files: Change expect(outcome).toBeNull() to expect(outcome.determined).toBe(false). Change all isDetermined to determined. Depends on mk5-tailwind-2gg through mk5-tailwind-61x.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-16T16:55:07.092033392-06:00","updated_at":"2025-12-20T22:18:59.666770086-06:00","closed_at":"2025-11-16T17:13:10.723774622-06:00"}
{"id":"t42-h7h","title":"Investigate ESLint queueMicrotask errors - why now and what changed?","description":"ESLint errors in src/server/transports/InProcessTransport.ts (lines 54, 78):\n'queueMicrotask' is not defined (no-undef)\n\nqueueMicrotask is used to break synchronous call chains and prevent stack overflow. It's a valid browser/Node.js API since 2018.\n\nINVESTIGATION NEEDED:\n1. Did this file work before? When did it start failing ESLint?\n2. Was queueMicrotask recently added to this file?\n3. Did ESLint config change recently?\n4. Are there OTHER globals missing from eslint.config.js?\n\nThe fix is simple (add queueMicrotask to globals), but WHY is this failing NOW?\n\nRelated: Code comments mention consensus actions causing exponential broadcast loops. Is this related to recent core engine changes?","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-16T16:21:42.290904984-06:00","updated_at":"2025-12-20T22:18:59.706542429-06:00","closed_at":"2025-11-17T16:03:38.827057366-06:00"}
{"id":"t42-ha9","title":"MCCFR training pipeline integration","description":"Use texas-42 skill. Integrate MCCFR (Monte Carlo Counterfactual Regret Minimization) model generation into the build pipeline.\n\n## Requirements\n\n1. **Training data handling**\n   - Full training data cached as local file (gitignored)\n   - Only final compressed model checked into git\n\n2. **Build integration**\n   - Real model building is opt-in (not part of default build)\n   - Pipeline script for training\n\n3. **Multi-model support**\n   - Support multiple models for different difficulties/iterations\n   - Models have a name (input parameter to training pipeline)\n   - Example: `npm run train:mccfr -- --name=easy --iterations=1000`\n   - Example: `npm run train:mccfr -- --name=expert --iterations=100000`\n\n## Implementation Notes\n- Consider naming convention: `models/{name}.mccfr.json` for compressed models\n- Training artifacts in `scratch/` or dedicated gitignored directory\n- Model loader should support selecting model by name at runtime","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-09T21:14:06.412020569-06:00","updated_at":"2025-12-20T22:18:59.717458859-06:00","closed_at":"2025-12-20T22:06:00.176282583-06:00","close_reason":"MCCFR removed from codebase","dependencies":[{"issue_id":"t42-ha9","depends_on_id":"t42-d6g","type":"parent-child","created_at":"2025-12-20T08:52:14.992116766-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-ha9","depends_on_id":"t42-tgr","type":"blocks","created_at":"2025-12-20T08:53:18.583802466-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-i2s","title":"Extend MCCFR to bidding and trump selection","description":"Use texas-42 skill.\n\nThe current MCCFR implementation (mk5-tailwind-bj0) focuses on the trick-taking (playing) phase only. Bidding and trump selection use simple heuristics:\n- Bidding: Always bid 30 or pass\n- Trump: Use hand-strength heuristics (determineBestTrump)\n\n## Future Work\n\nExtend MCCFR training to cover:\n\n1. **Bidding Phase**\n   - Information set: hand composition, bid history, position\n   - Actions: pass, bid values (30-42, marks)\n   - Challenge: Variable action space per info set\n\n2. **Trump Selection Phase**  \n   - Information set: hand composition, winning bid value\n   - Actions: suit (0-6), doubles, no-trump\n   - Simpler than bidding (fixed action space)\n\n## Implementation Considerations\n\n- May need separate regret tables or unified approach\n- Bidding affects subsequent play utility - need end-to-end training\n- Trump selection strongly affects hand strength - coupling with bidding\n\n## Current Implementation\n\nLocated in `src/game/ai/cfr/`:\n- `types.ts` - Core types (InfoSetKey, ActionKey, CFRNode, MCCFRConfig)\n- `regret-table.ts` - Storage with getStrategy(), updateRegrets(), serialize()\n- `action-abstraction.ts` - actionToKey(), sampleAction(), selectBestAction()\n- `mccfr-trainer.ts` - External sampling MCCFR (playing phase only)\n- `mccfr-strategy.ts` - AIStrategy using trained regrets (heuristics for bidding/trump)\n- `index.ts` - Public exports\n\nTraining scripts:\n- `scripts/train-mccfr.ts` - Single-process training\n- `scripts/train-mccfr-parallel.ts` - Multi-process parallel training with live dashboard\n\nInfo set abstraction:\n- `computeCountCentricHash()` in `cfr-metrics.ts` - 32.5x compression for playing phase","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-07T22:07:42.708658908-06:00","updated_at":"2025-12-20T22:18:59.795863269-06:00","closed_at":"2025-12-20T22:05:59.671175361-06:00","close_reason":"MCCFR removed from codebase","dependencies":[{"issue_id":"t42-i2s","depends_on_id":"t42-d6g","type":"parent-child","created_at":"2025-12-20T08:52:15.58632913-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-i2s","depends_on_id":"t42-tgr","type":"blocks","created_at":"2025-12-20T08:53:18.730285246-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-if8","title":"Add unit tests for Monte Carlo AI pipeline (3.58% coverage)","description":"Use texas-42 skill.\n\nThe Monte Carlo AI pipeline has critically low test coverage:\n- `monte-carlo.ts` - 3.58% (lines 71-364, 371-397)\n- `hand-sampler.ts` - 8.45% (lines 51-127, 134-143)\n- `constraint-tracker.ts` - 5.15% (lines 97-203, 217-233)\n- `intermediate.ts` - 32.25% (lines 12-116, 126-134)\n\nThese files are ACTIVE and critical for AI quality but only tested indirectly through E2E.\n\n## What needs testing:\n\n### monte-carlo.ts\n- `evaluatePlayActions()` - evaluates plays via simulation\n- `selectBestPlay()` - chooses best action from candidates\n\n### hand-sampler.ts  \n- `sampleOpponentHands()` - generates valid opponent hand distributions\n- Constraint satisfaction (void suits, played dominoes)\n\n### constraint-tracker.ts\n- `buildConstraints()` - builds constraints from game history\n- `getCandidateDominoes()` - filters available dominoes\n- `getExpectedHandSizes()` - calculates remaining hand sizes\n\n### intermediate.ts\n- `choosePlayAction()` - integration with Monte Carlo\n- Configurable simulation budget\n\n## Test approach:\n- Unit test each function with mocked dependencies\n- Integration test: intermediate vs beginner decision quality","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-29T12:49:30.294977253-06:00","updated_at":"2025-12-20T22:18:59.738430577-06:00","labels":["ai","testing"],"dependencies":[{"issue_id":"t42-if8","depends_on_id":"t42-65p","type":"parent-child","created_at":"2025-11-30T10:44:27.744155665-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-if8","depends_on_id":"t42-8d5","type":"blocks","created_at":"2025-12-20T09:12:02.047699225-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-iz2","title":"Investigate checkHandOutcome API contract violation - 36 unit test failures after core engine changes","description":"CRITICAL: Do NOT change test expectations without approval. Core engine was recently modified and tests are now failing with:\n\nExpected: null\nReceived: { isDetermined: false }\n\nThis appears in 36 test failures across 13 files. The checkHandOutcome function contract (in GameRules interface, docs, ADRs) clearly states it should return null when hand continues, HandOutcome when hand ends.\n\nImplementation in src/game/core/handOutcome.ts returns { isDetermined: false } in 3 places where it should return null (lines 51-54, 64-67, 168).\n\nINVESTIGATION NEEDED:\n1. What core engine change caused this?\n2. Is the implementation wrong or did the contract intentionally change?\n3. Why are tests failing NOW - what broke?\n4. What's the correct fix - implementation or contract?\n\nAffected files: compose-rules.test.ts, ruleset-overrides.test.ts, backward-compatibility.test.ts, nello-ruleset.test.ts, and 9 others.\n\nDo NOT fix until root cause is understood.","notes":"Fixed via discriminated union refactor (mk5-tailwind-73a). All 36 checkHandOutcome contract violations resolved.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-11-16T16:21:07.936010531-06:00","updated_at":"2025-12-20T22:18:59.673239933-06:00","closed_at":"2025-11-16T17:13:32.459304104-06:00"}
{"id":"t42-jdb","title":"Apply dealConstraints test framework to existing tests","description":"Use texas-42 skill.\n\n**Goal**: Assess the value and viability of the new constraint-based deal generation approach by applying it to existing tests.\n\n## Full Scope Analysis\n\n**97 total test files surveyed:**\n\n| Category | Files | Instances | Fragility |\n|----------|-------|-----------|-----------|\n| Hard-coded domino arrays | 19 | ~142 | HIGH ⚠️ |\n| Seed-based dealing | 26 | ~125 | MODERATE 🟡 |\n| withPlayerHand() | 17 | ~73 | GOOD 🟢 |\n| Hand-agnostic | 22 | — | OPTIMAL 🟢 |\n| Already optimal | 13 | — | PERFECT 🏆 |\n\n**Key insight:** ~45 files (19 hard-coded + 26 seed-based) could potentially benefit from dealConstraints.\n\n## Assessment Sample (3-5 tests to refactor)\n\n| File | Pattern | Instances | Priority |\n|------|---------|-----------|----------|\n| `src/tests/layers/integration/standard-game.test.ts` | Seeds + hard-coded | 36 | 1 |\n| `src/tests/layers/integration/nello-three-player.test.ts` | Hard-coded fixtures | 8 | 2 |\n| `src/tests/unit/url-roundtrip.test.ts` | Hard-coded arrays | 16 | 3 |\n| `src/tests/rules/renege-validation.test.ts` | withPlayerHand | 10 | 4 |\n\n## Task\n1. Refactor these 3-5 tests using the new constraint-based approach\n2. Document findings: What worked well? What didn't? Are tests more readable?\n3. Based on results, recommend whether to adopt more widely or identify improvements needed\n\n## Success Criteria\n- Refactored tests are more self-documenting\n- Tests remain deterministic\n- No reduction in test coverage or reliability\n- Clear assessment of approach viability\n- If viable: prioritized list of remaining ~42 files for future refactoring","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-28T22:02:32.797247692-06:00","updated_at":"2025-12-20T22:18:59.740316754-06:00","closed_at":"2025-11-28T22:30:54.513377089-06:00","labels":["assessment","dx","testing"]}
{"id":"t42-jff","title":"Replace deep cloning with structural sharing","description":"Use texas-42 skill.\n\ncloneGameState() performs O(n²) deep cloning on every state transition. This betrays misunderstanding of persistent data structures.\n\nFiles: src/game/core/state.ts","design":"# Design Analysis: Structural Sharing vs Deep Cloning\n\n## Executive Summary\nThe current implementation performs O(n²) deep cloning on every state transition where n represents the compound structure size (players × dominoes × suit analysis arrays). This is **wasteful and unnecessary**. The problem admits a simple solution through structural sharing—a technique as old as LISP itself, requiring no external dependencies.\n\n## I. The Crime Against Computational Economy\n\n### Location of the Offense\n**File**: `src/game/core/state.ts`\n**Function**: `cloneGameState()` \n**Lines**: 207-256 (50 lines of needless copying)\n\n### The Wasteful Implementation\n```typescript\nexport function cloneGameState(state: GameState): GameState {\n  const clonedState: GameState = {\n    ...state,\n    // ... shallow copies ...\n    players: state.players.map(player =\u003e {\n      const clonedPlayer: Player = {\n        ...player,\n        hand: [...player.hand]  // Line 220: Unnecessary copy\n      };\n\n      if (player.suitAnalysis) {\n        // Lines 224-237: THE ATROCITY\n        clonedPlayer.suitAnalysis = {\n          count: { ...player.suitAnalysis.count },\n          rank: {\n            0: [...player.suitAnalysis.rank[0]],\n            1: [...player.suitAnalysis.rank[1]],\n            2: [...player.suitAnalysis.rank[2]],\n            3: [...player.suitAnalysis.rank[3]],\n            4: [...player.suitAnalysis.rank[4]],\n            5: [...player.suitAnalysis.rank[5]],\n            6: [...player.suitAnalysis.rank[6]],\n            doubles: [...player.suitAnalysis.rank.doubles],\n            trump: [...player.suitAnalysis.rank.trump]\n          }\n        };\n      }\n      return clonedPlayer;\n    }),\n    // ... more shallow copies ...\n  };\n}\n```\n\n## II. Complexity Analysis\n\n### Current Cost Per Clone\nLet D = 28 dominoes, P = 4 players, H = 7 dominoes/hand, S = 9 suits (including doubles/trump)\n\n**Operations per cloneGameState():**\n- players array: O(P) = 4 copies\n- Each player's hand array: O(H) × P = 7 × 4 = 28 copies\n- Each player's suitAnalysis.count: O(S) × P = 9 × 4 = 36 copies\n- Each player's suitAnalysis.rank arrays: O(S × H) × P = 9 × 7 × 4 = 252 copies\n\n**Total: ~320 array/object allocations per state transition**\n\n### Call Frequency\n**Critical Path** (capabilities.ts:237):\n```typescript\nexport function getVisibleStateForSession(state: GameState, session: PlayerSession): FilteredGameState {\n  const clone = cloneGameState(state);  // CALLED FOR EVERY VIEW RENDER\n  // ... then proceeds to filter the clone ...\n}\n```\n\nThis is called **every time a player requests state** - potentially dozens of times per second in active games.\n\n### Actual Mutation Points\nExamining `executeAction()` in actions.ts:25-70, state transitions use **shallow spread**:\n```typescript\nexport function executeAction(state: GameState, action: GameAction, rules: GameRules): GameState {\n  const newState: GameState = {\n    ...state,\n    actionHistory: [...state.actionHistory, action]\n  };\n  // ... process action with shallow updates ...\n}\n```\n\n**Only these fields ever change:**\n- `actionHistory` - grows by 1 action (correctly copied)\n- `players[i].hand` - shrinks by 1 domino when playing (line 245)\n- `players[i].suitAnalysis` - recomputed when hand changes (line 246)\n- `bids`, `tricks`, `currentTrick` - append operations\n- Scalar fields (phase, currentPlayer, etc.) - direct updates\n\n**What NEVER changes and NEVER needs cloning:**\n- Domino objects themselves (immutable by design)\n- suitAnalysis.rank arrays when hand unchanged\n- suitAnalysis.count object when hand unchanged\n\n## III. The Unnecessary Cloning of suitAnalysis\n\n### Evidence from Usage Analysis\n**Every suitAnalysis mutation recomputes from scratch** (actions.ts:194, 246, 394, 452, 519):\n```typescript\n// Trump selection - recompute for all players\nconst newPlayers = state.players.map(p =\u003e ({\n  ...p,\n  suitAnalysis: analyzeSuits(p.hand, selection)  // FRESH COMPUTATION\n}));\n\n// Playing a domino - recompute for one player\nconst newPlayer: typeof playerState = {\n  ...playerState,\n  hand: playerState.hand.filter(d =\u003e d.id !== dominoId),\n  suitAnalysis: analyzeSuits(                     // FRESH COMPUTATION\n    playerState.hand.filter(d =\u003e d.id !== dominoId),\n    state.trump\n  )\n};\n```\n\n**Critical Insight**: suitAnalysis is NEVER mutated in place. When it changes, it's completely replaced by `analyzeSuits()`. When it doesn't change, it should be **shared**, not cloned.\n\n### The Cloning is Pure Waste\nLines 224-237 perform deep cloning of a structure that:\n1. Is never mutated directly\n2. Is fully replaced when updates needed\n3. Contains only references to immutable Dominoes\n4. Could be safely shared across state versions\n\n## IV. The Solution: Structural Sharing\n\n### Principle\n\"Copy only what changes; share what doesn't.\" - McCarthy, 1960\n\n### Implementation Strategy\n\n#### Option A: Manual Structural Sharing (RECOMMENDED)\n**Eliminate cloneGameState() entirely.** The function is a LIABILITY.\n\nCurrent call sites:\n1. **advanceToNextPhase()** (state.ts:319) - Creates new state with phase change\n2. **getVisibleStateForSession()** (capabilities.ts:237) - Filters state for view\n3. **cloneMultiplayerState()** (kernel.ts:332) - Multiplayer wrapper\n\n**None of these need deep cloning.**\n\n**Replacement for advanceToNextPhase():**\n```typescript\nexport function advanceToNextPhase(state: GameState): GameState {\n  return {\n    ...state,\n    phase: getNextPhase(state.phase)\n  };\n}\n```\n**Before**: 320 allocations  \n**After**: 1 allocation  \n**Speedup**: 320×\n\n**Replacement for getVisibleStateForSession():**\n```typescript\nexport function getVisibleStateForSession(\n  state: GameState,\n  session: PlayerSession\n): FilteredGameState {\n  // No clone needed - just filter during mapping\n  return {\n    ...state,\n    players: state.players.map((player, index) =\u003e {\n      const canSee = canSeeHand(session, index);\n      return canSee \n        ? { ...player } // Share hand and suitAnalysis\n        : { \n            id: player.id,\n            name: player.name,\n            teamId: player.teamId,\n            marks: player.marks,\n            hand: [],\n            handCount: player.hand.length\n          };\n    })\n  };\n}\n```\n**Before**: 320 allocations + filter pass  \n**After**: 1 allocation + filter pass  \n**Speedup**: 320×\n\n**Replacement for cloneMultiplayerState():**\n```typescript\nexport function cloneMultiplayerState(state: MultiplayerGameState): MultiplayerGameState {\n  return {\n    gameId: state.gameId,\n    coreState: state.coreState, // SHARE, don't clone\n    players: state.players.map(session =\u003e ({\n      ...session,\n      capabilities: [...session.capabilities] // Only copy capability arrays\n    }))\n  };\n}\n```\n\n#### Option B: Immer Library\nCould use Immer for automatic structural sharing, but this adds:\n- 15KB dependency\n- Runtime overhead for proxy tracking\n- Cognitive overhead for \"draft\" API\n\n**Verdict**: Immer is OVERKILL. The mutation points are well-defined and few. Manual structural sharing is simpler, faster, and has zero dependencies.\n\n## V. Additional Optimizations\n\n### 1. Hand Array Cloning (Line 220)\n```typescript\nhand: [...player.hand]  // UNNECESSARY if hand not mutated\n```\n\n**Current**: `player.hand.filter(d =\u003e d.id !== dominoId)` creates NEW array  \n**Therefore**: No need to clone in cloneGameState()  \n**Action**: REMOVE this line when eliminating cloneGameState()\n\n### 2. Domino Objects\nDominoes are referenced, not cloned, which is CORRECT. They're immutable value objects.\n\n### 3. Action History (Line 252)\n```typescript\nactionHistory: [...state.actionHistory]\n```\n\nThis IS necessary because `executeAction()` appends to it (actions.ts:29).  \n**Keep this** in state transition functions.\n\n## VI. Acceptance Criteria\n\n### Functional Requirements\n1. All existing tests must pass unchanged\n2. State immutability must be preserved (verified by mutation tests)\n3. No observable behavior changes in game logic\n\n### Performance Requirements\n1. `getVisibleStateForSession()` must complete in \u003c1ms (vs current ~3ms)\n2. State transition memory allocations reduced by \u003e90%\n3. No increased GC pressure (measure with Chrome DevTools)\n\n### Code Quality Requirements\n1. ELIMINATE `cloneGameState()` function entirely (50 lines removed)\n2. Update 3 call sites to use structural sharing\n3. Add explanatory comments on structural sharing pattern\n4. Update test helpers in stateBuilder.ts (11 call sites)\n\n### Verification Strategy\n1. Run full test suite: `npm run test:all`\n2. Profile with: `node --expose-gc scripts/profile-state-transitions.js`\n3. Measure allocations before/after with heap snapshots\n4. Verify immutability with mutation detection test\n\n## VII. Implementation Plan\n\n### Phase 1: Preparation (5 min)\n1. Run current test suite to establish baseline\n2. Create performance benchmark for state transitions\n\n### Phase 2: Core Replacement (15 min)\n1. Update `advanceToNextPhase()` - remove cloneGameState() call\n2. Update `getVisibleStateForSession()` - use structural sharing\n3. Update `cloneMultiplayerState()` - share coreState\n\n### Phase 3: Test Helpers (10 min)\n1. Update stateBuilder.ts - replace 11 cloneGameState() calls\n2. Consider if test helpers even need cloning (most don't)\n\n### Phase 4: Cleanup (5 min)\n1. DELETE cloneGameState() function (lines 207-256)\n2. DELETE import/export references\n3. Run linter to catch any missed references\n\n### Phase 5: Verification (10 min)\n1. Run full test suite\n2. Run performance benchmarks\n3. Generate memory profiling comparison\n\n**Total Estimated Time**: 45 minutes\n\n## VIII. Risks and Mitigations\n\n### Risk: Accidental Mutation\n**Mitigation**: Run test suite with Object.freeze() on all state objects (development mode only)\n\n### Risk: Reference Leaks\n**Mitigation**: State objects already short-lived (single game session). No new leak vectors introduced.\n\n### Risk: Test Brittleness\n**Mitigation**: Tests should not depend on deep cloning. If they do, they're testing implementation, not behavior - FIX THE TESTS.\n\n## IX. Conclusion\n\nThe current implementation violates the principle of computational economy through unnecessary deep cloning of immutable data structures. The solution is not novel—structural sharing has been the cornerstone of functional programming for 60 years.\n\n**The code does not need Immer. The code does not need libraries. The code needs deletion.**\n\nRemove `cloneGameState()`. Use JavaScript's native spread operator judiciously. Share what doesn't change. Copy only what does.\n\nThis is not optimization. This is correction of a fundamental architectural mistake.\n\n**Estimated Performance Gain**: 320× reduction in allocations per state view, ~3× faster state transitions.\n\n**Estimated Code Simplification**: -50 lines of cloning code, +10 lines of comments explaining structural sharing.\n\n**Estimated Implementation Risk**: LOW. The mutation points are well-defined. The tests are comprehensive.\n\n---\n*\"Simplicity is prerequisite for reliability.\"* — Dijkstra, EWD498","status":"open","priority":3,"issue_type":"chore","created_at":"2025-11-29T12:10:05.386739543-06:00","updated_at":"2025-12-20T22:18:59.808526954-06:00","dependencies":[{"issue_id":"t42-jff","depends_on_id":"t42-8ee","type":"blocks","created_at":"2025-11-29T12:10:23.262090406-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-jff","depends_on_id":"t42-4b9","type":"parent-child","created_at":"2025-11-29T12:10:37.581425553-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"t42-kiw","title":"Update docs/rules.md with edge-case clarifications","description":"Use texas-42 skill.\n\n## Summary\n\nThe rules document is excellent but missing some edge-case clarifications discovered during review.\n\n## Clarifications Needed\n\n### 1. Suit Determination with Trump Pip (line 159)\nCurrent: \"Higher end of non-trump domino determines suit led\"\nMissing: When leading a domino where one pip IS trump, it leads as trump.\n\n### 2. Doubles-Trump Following Rules (lines 173-176)\nAdd explicit statements:\n- Non-doubles cannot follow a double lead (different suit)\n- Doubles cannot follow a non-double lead (they're trump, not that suit)\n\n### 3. Nello Doubles Authority (lines 257-260)\nSpecify which treatment is authoritative for this codebase:\n- \"Doubles form own suit\" is the standard tournament rule\n\n### 4. Sevens Equidistant Ties (lines 279-282)\nClarify: dominoes equidistant from 7 (e.g., 6 pips vs 8 pips) - first played wins.\n\n### 5. Led Suit with Trump Pip\nAdd explicit rule: If 4s are trump and you lead 4-2, it's a trump lead (contains trump pip).\n\n## Minor Polish\n- Line 149: Expand \"follow-me\" explanation\n- Section 6: Cross-reference \"count\" and \"counters\" terminology","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-20T20:32:41.555212108-06:00","updated_at":"2025-12-20T22:18:59.793489604-06:00","closed_at":"2025-12-20T20:35:01.822613457-06:00","close_reason":"Added 5 clarifications to docs/rules.md: trump pip suit determination, doubles-trump following rules, Nello doubles authority, Sevens equidistant ties, and follow-me explanation.","labels":["docs"]}
{"id":"t42-l2l","title":"Update gameStore to use createLocalGame","description":"Simplify gameStore to use the new createLocalGame() pattern.\n\n**Reference**: docs/MULTIPLAYER.md\n\n**IMPORTANT**: This is roll forward / clean break / NO backwards compatibility whatsoever.\n\n**Changes**:\n- Replace `wireUpGame()` with call to `createLocalGame()`\n- Remove Transport/Connection wiring code\n- Simplify to use new GameClient interface\n- Fix any type errors from the changes\n\n**Before**: ~30 lines of Transport/Room/Connection wiring\n**After**: ~10 lines calling createLocalGame()","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-25T14:55:49.110987194-06:00","updated_at":"2025-12-20T22:18:59.686120838-06:00","closed_at":"2025-11-25T15:44:16.10955044-06:00","dependencies":[{"issue_id":"t42-l2l","depends_on_id":"t42-don","type":"parent-child","created_at":"2025-11-25T14:55:53.945087997-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-l2l","depends_on_id":"t42-864","type":"blocks","created_at":"2025-11-25T14:55:54.814762003-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-l4t","title":"Minimum MCCFR integration: add to strategy registry","description":"Use texas-42 skill.\n\n## Status: Superseded by tgr (removal decision)\n\nThe MCCFR integration was completed but testing revealed the trained strategy was not good. The count-centric abstraction proved too lossy - the strategy couldn't learn suit-specific play (e.g., 'don't lead 5-0 when treys are trump').\n\n## What was done\n- MCCFR wired into actionSelector.ts with lazy loading\n- gameStore.ts auto-loaded and set MCCFR as default\n- Trained to 100k iterations with CFD2 compact format\n\n## Decision\nCFR punted. 'Boring and competent' isn't worth the squeeze when we could get that with fixed MCTS, and neural nets offer more upside for fun play.\n\n## Cleanup performed\n- Reverted actionSelector.ts to beginner/random only\n- Removed MCCFR auto-load from gameStore.ts\n- Full removal tracked in mk5-tailwind-tgr","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T19:03:45.388715893-06:00","updated_at":"2025-12-20T22:18:59.677280983-06:00","closed_at":"2025-12-19T20:53:49.092667392-06:00"}
{"id":"t42-lfy","title":"Fix pip-value vs game-suit mismatch in canFollowSuit","description":"Use texas-42 skill.\n\n## Problem\n\nThe `canFollowSuit()` function and `suitAnalysis.rank` system operate on **pip values** (0-6), but renege rules should operate on **game suits** (determined by trump).\n\n**Example:**\n- Trump: ACES (1)\n- Led suit: DEUCES (2)\n- Player has: `4-2` domino\n- Current behavior: `canFollowSuit(player, DEUCES)` returns `true` because domino contains pip 2\n- Expected behavior: Should return `false` because game suit of `4-2` is FOURS (higher non-trump pip)\n\n## Root Cause\n\nIn `src/game/core/suit-analysis.ts:122-125`:\n```typescript\nnonDoubles.forEach(domino =\u003e {\n  rank[domino.high].push(domino);\n  rank[domino.low].push(domino);  // Adds to BOTH pip arrays\n});\n```\n\nThis is correct for bidding analysis (knowing all pips you have) but wrong for play validation (need game suit only).\n\n## Impact\n\n- Discovered during dealConstraints assessment (mk5-tailwind-jdb)\n- The constraint system correctly operates on pip values\n- But renege-validation tests can't use constraints because they need game-suit precision\n- Currently worked around by using exact hand arrays in tests\n\n## Proposed Fix\n\nEither:\n1. Add a separate `gameSuitRanking` property to suit analysis that groups by game suit (respecting trump)\n2. Update `canFollowSuit()` to use `getDominoSuit()` directly instead of `suitAnalysis.rank`\n3. Accept this as intentional design and document the distinction\n\n## Files\n\n- `src/game/core/suit-analysis.ts` - calculateSuitRanking\n- `src/game/core/rules.ts` - canFollowSuit\n- `src/tests/rules/renege-validation.test.ts` - affected tests","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-11-28T22:35:33.187393212-06:00","updated_at":"2025-12-20T22:18:59.739358872-06:00","closed_at":"2025-11-29T10:03:28.583878284-06:00","labels":["core","discovered-during-refactor","rules"]}
{"id":"t42-liuw","title":"Design: Stronger bidding AI (adaptive trump + inference)","description":"Use texas-42 skill.\n\n## The Core Problem\n\nCurrent bidding evaluation is architecturally wrong:\n```\nWRONG: For each bid value (30, 31, ... 42):\n         Pick \"best trump\" heuristically\n         Simulate: can we make this bid?\n```\n\nThis approach:\n- Runs full minimax per bid level (slow!)\n- Uses static `determineBestTrump()` (misses nello, sevens, etc.)\n- Doesn't discover trump options from layers\n- Can't compare \"aces at 34\" vs \"nello all-or-nothing\"\n\n## The Correct Architecture\n\n```\n1. Discover trump options from composed layers\n   (getValidActions in trump_selection phase)\n   → suits 0-6, doubles, no-trump, nello, sevens...\n\n2. For EACH trump option, simulate many hands:\n   → Expected team points\n   → Distribution: P(≥30), P(≥34), P(≥42)\n\n3. Output: \"Trump → EV table\"\n   Aces:    avg 34 pts, 80% at 34+, 12% at 42\n   Nello:   83% × 42 + 17% × 0 = EV 35\n   Doubles: avg 31 pts, 60% at 34+\n\n4. THEN decide what to bid based on EV and risk\n```\n\n## Key Insights\n\n**Trump options come from layers** - nello adds itself via `getValidActions`:\n```typescript\n// nello.ts:23-34\nif (state.phase === 'trump_selection' \u0026\u0026 state.currentBid?.type === 'marks') {\n  return [...prev, { type: 'select-trump', trump: { type: 'nello' } }];\n}\n```\n\n**Special contracts have different payoff structures:**\n- **Nello**: All-or-nothing (win marks or lose marks)\n- **Plunge/Splash**: PARTNER bids - evaluate partner's hand\n- **Sevens**: 7s always trump regardless of declared suit\n\n**One simulation pass per trump, not per bid level** - much more efficient.\n\n## Implementation Approach\n\n1. Create `evaluateTrumpOptions(hand, ctx)` that:\n   - Gets valid trump selections from layer system\n   - For each trump, runs N simulations to hand completion\n   - Returns: `Map\u003cTrumpSelection, { avgPoints, distribution }\u003e`\n\n2. Create `decideBid(trumpEvaluations, riskTolerance)` that:\n   - Takes the EV table\n   - Applies risk preference (conservative vs aggressive)\n   - Returns: recommended bid action\n\n3. Handle special cases:\n   - Nello: binary outcome, weight by success probability\n   - Plunge: infer partner hand strength, evaluate their options\n   - Marks bids: unlock nello/plunge trump options\n\n## Why This Blocks t42-6nf (Policy Network)\n\nThe policy network learns from training data. If we generate training labels with the current broken bidding, the network learns broken bidding. We need correct evaluation FIRST to generate good training signal.\n\n## Files to Modify\n\n- `src/game/ai/monte-carlo.ts` - new `evaluateTrumpOptions()` function\n- `src/game/ai/strategies.ts` - use new evaluation in `BeginnerAIStrategy`\n- `src/game/ai/hand-strength.ts` - may still be useful for quick heuristics","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-21T21:40:12.226262497-06:00","updated_at":"2025-12-23T16:42:44.692792029-06:00"}
{"id":"t42-lk2","title":"Add canFollow, suitsWithTrump, rankInTrick to GameRules interface","description":"Use texas-42 skill.\n\n## Problem\n\nFollow-suit validation has caused hours of debugging. The logic is scattered, duplicated, and hard to reason about. Current functions (`dominoHasSuit`, `dominoContainsSuit`, `dominoBelongsToSuit`) have subtle semantic differences that cause bugs.\n\n**Architectural violation found**: `dominoBelongsToSuit` in `dominoes.ts:315` checks `trump.type === 'nello'`. This belongs in `nelloLayer`, not core.\n\n## The Insight\n\nA domino's identity narrows in **two stages**:\n\n1. **Trump declared** → domino either gets \"absorbed\" into trump (loses natural suits) or retains its potential suits\n2. **Suit led** → domino's role collapses to: trump, follower, or slough\n\n## The Architecture (per ORIENTATION.md)\n\nThese primitives are **GameRules methods**, not standalone functions:\n\n1. Add methods to `GameRules` interface in `layers/types.ts`\n2. Implement base behavior in `layers/base.ts`\n3. Override in `nelloLayer`, `sevensLayer` as needed\n4. Compose via reduce in `compose.ts`\n5. All callers use `ctx.rules.methodName(state, ...)`\n\n**No `if (trump.type === 'nello')` in core. Ever.**\n\n## New GameRules Methods (14→17)\n\n```typescript\ncanFollow(state: GameState, led: LedSuit, d: Domino): boolean;\nsuitsWithTrump(state: GameState, d: Domino): LedSuit[];\nrankInTrick(state: GameState, led: LedSuit, d: Domino): number;\n```\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `layers/types.ts` | Add `canFollow`, `suitsWithTrump`, `rankInTrick` to GameRules |\n| `layers/base.ts` | Implement base behavior for new methods, delete local helpers |\n| `layers/compose.ts` | Add composition for new methods, simplify validation (128→15 lines) |\n| `layers/nello.ts` | Override `canFollow`, `suitsWithTrump` (move logic from dominoes.ts) |\n| `core/dominoes.ts` | Delete `dominoBelongsToSuit`, `dominoContainsSuit`, nello check |\n| `core/scoring.ts` | Delete `calculateTrickWinner`, helpers (use composed rules) |\n| `ai/constraint-tracker.ts` | Use `ctx.rules.canFollow()`, `ctx.rules.suitsWithTrump()` |\n\n## Order of Operations\n\n1. Add new methods to GameRules interface in `layers/types.ts`\n2. Implement base behavior in `layers/base.ts`\n3. Add composition in `layers/compose.ts`\n4. Move nello logic from `dominoes.ts:315` to `nelloLayer` overrides\n5. Simplify compose.ts validation using `rules.canFollow()`\n6. Simplify calculateTrickWinner using `rules.rankInTrick()`\n7. Update AI to use composed rules\n8. Delete superseded code from dominoes.ts, scoring.ts\n9. Run tests - `npm run test:all`\n\n## Acceptance Criteria\n\n- `canFollow`, `suitsWithTrump`, `rankInTrick` added to GameRules interface\n- Base implementations in `layers/base.ts`\n- Composition in `layers/compose.ts`\n- nelloLayer overrides `canFollow`, `suitsWithTrump` (no more nello check in core)\n- `isValidPlayBase` reduced to ~10 lines using `rules.canFollow()`\n- `getValidPlaysBase` reduced to ~10 lines using `rules.canFollow()`\n- `calculateTrickWinner` uses `rules.rankInTrick()`\n- `dominoBelongsToSuit`, `dominoContainsSuit` deleted from dominoes.ts\n- Duplicate `isDominoTrump` helpers deleted from base.ts, scoring.ts\n- All existing tests pass\n- No `if (trump.type === 'nello')` in core/","acceptance_criteria":"- [ ] `dominoContext.ts` created with `suitsWithTrump`, `suitWithLead`, `rankInTrick` \n- [ ] All functions are pure (no state, no side effects)\n- [ ] `isValidPlayBase` reduced to ~5-10 lines\n- [ ] `getValidPlaysBase` reduced to ~5-10 lines\n- [ ] `calculateTrickWinner` uses `rankInTrick` + `maxBy`\n- [ ] Eliminate duplicated `isDominoTrump` implementations (use single source)\n- [ ] All existing tests pass\n- [ ] Nello, doubles-as-trump, no-trump, and standard play all work correctly\n- [ ] No changes needed to `nelloLayer.ts` (it should just work)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-02T21:04:20.16155137-06:00","updated_at":"2025-12-20T22:18:59.678405768-06:00","closed_at":"2025-12-20T17:37:19.62554434-06:00","close_reason":"Implemented canFollow, suitsWithTrump, rankInTrick in GameRules. Simplified validation logic. All tests pass.","labels":["DRY","refactor"]}
{"id":"t42-lq0","title":"Rules-base + layer rewiring","description":"Add src/game/layers/rules-base.ts implementing canonical getLedSuitBase/suitsWithTrumpBase/canFollowBase/rankInTrickBase/isTrumpBase. Rewire base.ts to delegate; remove base logic from compose.ts and seed its defaults from rules-base. Add rules.isTrump to GameRules + implementations/overrides. Ensure AI/helpers import base logic only from rules-base when needed.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T11:03:43.393629571-06:00","updated_at":"2025-12-21T11:26:13.818313987-06:00","closed_at":"2025-12-21T11:26:13.818313987-06:00","close_reason":"Closed","dependencies":[{"issue_id":"t42-lq0","depends_on_id":"t42-g4y","type":"discovered-from","created_at":"2025-12-21T11:03:43.397679715-06:00","created_by":"jason"},{"issue_id":"t42-lq0","depends_on_id":"t42-f26","type":"blocks","created_at":"2025-12-21T11:13:53.070425498-06:00","created_by":"jason"}]}
{"id":"t42-lrcv","title":"GPU solver: remove torch.unique bottleneck in BFS","description":"Use texas-42 skill. Context caching fix done (t42-q86b) - ctx.to(device) now called once in solve_seed instead of 29x in expand_gpu.\n\nRemaining bottleneck from profiling:\n- L13: 7.89s for torch.unique() on 9M states\n- L11: 10.74s for torch.unique() on 25M states\n\nFix per original spec:\n1. Remove periodic torch.unique() during BFS (solve.py:92-94) - dedup only at end\n2. Pre-compute level indices to avoid nonzero() in solve_gpu\n\nCurrent GPU timing for seed=42: L28→L11 in ~20s (most time in unique calls)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T15:24:15.210590889-06:00","updated_at":"2025-12-27T16:42:52.276331871-06:00","closed_at":"2025-12-27T16:42:52.276331871-06:00","close_reason":"Superseded by t42-ovlu with full problem context and learnings","dependencies":[{"issue_id":"t42-lrcv","depends_on_id":"t42-q86b","type":"blocks","created_at":"2025-12-27T15:24:33.800370067-06:00","created_by":"jason"}]}
{"id":"t42-mhn","title":"Remove perfects and document regeneration process","description":"Remove pre-computed perfect hands data files from git tracking to reduce repository size. These are deterministic outputs that can be regenerated on demand.\n\n**Files to remove from git:**\n- `data/perfect-hands.json` (88KB) - Pre-computed platinum/gold perfect hands\n- `data/3hand-partitions.json` (1.5MB) - 3-hand partition combinations\n\n**What are \"perfects\"?**\nPerfect hands in Texas 42 are 7-domino combinations that guarantee winning all 7 tricks:\n- **Platinum**: No external domino can beat any domino in the hand\n- **Gold**: Has 4+ highest trumps, non-trumps only beatable by trumps\n\n**Regeneration commands to document:**\n```bash\n# Generate perfect-hands.json\nnpx tsx scripts/find-perfect-hands.ts --json \u003e data/perfect-hands.json\n\n# Generate 3hand-partitions.json (check for script)\nnpx tsx scripts/find-perfect-partition.ts --json \u003e data/3hand-partitions.json\n```\n\n**Considerations:**\n- Add to .gitignore after removal\n- Update any CI/build that depends on these files\n- Consider adding npm script for regeneration\n- PerfectsApp.svelte imports 3hand-partitions.json directly","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-26T22:25:34.576135326-06:00","updated_at":"2025-12-20T22:18:59.824379218-06:00","closed_at":"2025-11-26T22:45:01.26653501-06:00"}
{"id":"t42-mtq","title":"Core cleanup: rule logic to GameRules","description":"Remove getLedSuit/isTrump/getDominoValue from core/dominoes.ts and calculateTrickWinner from core/scoring.ts. Update all consumers (engine, AI, utilities) to use ExecutionContext.rules.* for led suit, canFollow, rank, trick winner, and trump checks. Keep core helpers pure pip/deck/points only.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T11:03:46.592210323-06:00","updated_at":"2025-12-21T11:51:31.952064039-06:00","closed_at":"2025-12-21T11:51:31.952064039-06:00","close_reason":"Closed","dependencies":[{"issue_id":"t42-mtq","depends_on_id":"t42-g4y","type":"discovered-from","created_at":"2025-12-21T11:03:46.595664011-06:00","created_by":"jason"},{"issue_id":"t42-mtq","depends_on_id":"t42-lq0","type":"blocks","created_at":"2025-12-21T11:13:53.265648924-06:00","created_by":"jason"}]}
{"id":"t42-mxay","title":"Cache absorptionId/powerId in calculateTrickWinner","description":"Use texas-42 skill.\n\nMicro-optimization: compute absorptionId and powerId once per trick instead of once per domino.\n\n## Problem\nIn `rankInTrickBase()`, `getAbsorptionId()` and `getPowerId()` are called for every domino (4× per trick, 56× per hand). These only depend on `state.trump`, which is immutable during the trick.\n\n## Solution\n1. Add `rankInTrickWithConfig(absorptionId, powerId, led, domino)` to rules-base.ts\n2. Have `rankInTrickBase` delegate to it\n3. In compose.ts `calculateTrickWinner`, compute IDs once and use the optimized function","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-26T19:09:02.775317777-06:00","updated_at":"2025-12-26T19:10:54.030511389-06:00","closed_at":"2025-12-26T19:10:54.030511389-06:00","close_reason":"Implemented: rankInTrickWithConfig caches absorptionId/powerId, calculateTrickWinner now computes IDs once per trick instead of once per domino. All 1045 tests pass."}
{"id":"t42-ne8i","title":"solver2: vectorize expand_gpu move loop","description":"Use texas-42 skill.\n\nVectorize the Python loop in expand_gpu() (expand.py:37-69) to use (N,7) broadcast operations instead of iterating 7 times.\n\n## Investigation Summary\n\nTested three approaches on RTX 3050 (4GB VRAM):\n\n**Option A (Full vectorization)**: Faster for small N, but slower for large N due to (N,7) VRAM pressure (~2.6GB for 46M states).\n\n**Option B (Chunked vectorization)**: Process in 2M-state chunks. Mixed results - some cases faster, some slower.\n\n**Option C (Hybrid - precompute outside loop)**: Slower due to overhead when loop can early-exit via `is_legal.any()`.\n\n## Benchmark Results (RTX 3050)\n\n### Baseline (current loop-based code)\n| Seed | Trump | States | Time |\n|------|-------|--------|------|\n| 0 | blanks | 7.6M | 3.5s |\n| 0 | ones | 46.0M | 11.6s |\n| 0 | fives | 24.3M | 8.6s |\n| 1 | blanks | 10.4M | 3.5s |\n| 1 fives | 10.5M | 3.1s |\n| 2 | fives | 35.5M | 9.0s |\n\n### Option B (chunked vectorization, 2M chunk size)\n| Seed | Trump | States | Time | Delta |\n|------|-------|--------|------|-------|\n| 0 | blanks | 7.6M | ~2.8s | -20% |\n| 0 | ones | 46.0M | ~13.0s | +12% |\n| 0 | fives | 24.3M | ~6.3s | -27% |\n| 1 | blanks | 10.4M | ~3.5s | same |\n| 1 | fives | 10.5M | ~3.6s | +16% |\n| 2 | fives | 35.5M | ~9.9s | +10% |\n\nRun-to-run variance: 1-9%\n\n## Conclusion\n\nThe current loop-based implementation with `is_legal.any()` early-exit is well-optimized. Vectorization provides mixed results - faster for some workloads, slower for others. No clear win.\n\nLarger VRAM GPUs might benefit more from vectorization (fewer chunks, less loop overhead), but not tested.\n\n**Decision**: Keep current loop-based code. Fix device comparison bug only.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:17:32.735595846-06:00","updated_at":"2025-12-27T20:59:56.917826199-06:00","closed_at":"2025-12-27T20:59:56.917826199-06:00","close_reason":"Investigated. Vectorization provides mixed results (some faster, some slower). Current loop with early-exit is already well-optimized. Fixed device comparison bug only.","dependencies":[{"issue_id":"t42-ne8i","depends_on_id":"t42-oqvi","type":"blocks","created_at":"2025-12-27T19:17:41.849199547-06:00","created_by":"jason"}]}
{"id":"t42-nl02","title":"Replace StateBuilder with config-based buildState()","description":"Use texas-42 skill. Replace 800-line fluent StateBuilder class with ~100-150 line buildState(config) function. Specify only what you care about, everything else gets filled with valid defaults. Delete StateBuilder entirely, update all 38 files that use it.\n\nAcceptance:\n- buildState() works for all current test scenarios\n- StateBuilder class deleted (no coexistence)\n- All 38 files updated in one pass\n- No legacy/gradual migration patterns\n- npm run test:all passes","design":"Config object approach:\n\nconst state = buildState({\n  phase: 'playing',\n  trump: { type: 'suit', suit: ACES },\n  hands: { 0: ['6-6'] }  // rest filled validly\n});\n\nKey behaviors:\n- Smart defaults based on phase (playing needs trump/bids, etc.)\n- Distribute 28 dominoes validly - specified ones placed, rest shuffled\n- Set currentPlayer correctly for phase\n- Make bids array consistent with winningBidder/currentBid\n\nGoal: LLM-friendly (graspable in 50 lines), test configs are 3-5 lines.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-21T21:18:35.326260383-06:00","updated_at":"2025-12-23T14:18:14.756078396-06:00"}
{"id":"t42-nr3","title":"[Game Rules] Dropped on You - Dealer cannot pass if all others pass","description":"Use texas-42 skill.\n\n## Rule: \"Dropped on You\"\n\nIn this variant, there is no redeal. If all three non-dealer players pass, the dealer is forced to bid (cannot pass). The bid \"drops\" on them.\n\n## Implementation\n\n### Layer: `dropped-on-you.ts`\n\nA new layer that modifies bidding actions:\n- Track if all 3 non-dealer players have passed\n- When it's the dealer's turn and everyone else passed, filter out the \"pass\" action\n- Dealer must bid at least 30\n\n### Affected Files\n- New: `src/game/layers/dropped-on-you.ts`\n- Update: `src/game/layers/index.ts` (register layer)\n- Update: Layer configuration to include this as optional rule\n\n### Acceptance Criteria\n- [ ] When all non-dealers pass, dealer cannot pass\n- [ ] Dealer is forced to bid minimum (30)\n- [ ] Works correctly with other bidding layers\n- [ ] Unit tests for the layer logic","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-02T20:55:25.561597603-06:00","updated_at":"2025-12-20T22:18:59.735828262-06:00"}
{"id":"t42-nw1n","title":"Deduplicate 'which player executes this action' logic","description":"Use texas-42 skill.\\n\\nWe have duplicate logic for inferring which player should execute an action (player field vs consensus actions defaulting to P0). This appears in multiple places and can drift.\\n\\nEvidence:\\n- src/server/HeadlessRoom.ts getPlayerForAction()\\n- src/stores/gameStore.ts getPlayerIndexForAction()\\n\\nFix direction:\\n- Introduce a shared helper (e.g., getExecutingPlayerIndex(action, fallbackCurrentPlayer))\\n- Keep consensus/system-authority policy in one place","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-27T00:30:38.257972798-06:00","updated_at":"2025-12-27T00:30:38.257972798-06:00","dependencies":[{"issue_id":"t42-nw1n","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:30:38.261741522-06:00","created_by":"jason"}]}
{"id":"t42-ofy","title":"Crystal Palace: Suit System Consolidation","description":"Use texas-42 skill.\n\n## Vision\n\nConsolidate scattered suit logic into a clean, unified architecture. One authoritative way to handle suits game-wide.\n\n## Research Summary\n\nMapped **15 files** with suit logic. Found:\n- 2 dead functions (zero callers)\n- 3 duplicate type definitions\n- 1 local function copy\n- 1 unused parameter passed everywhere\n- 1 Nello violation in core\n\n## What to Delete\n\n| Dead Code | Location |\n|-----------|----------|\n| `dominoContainsSuit()` | dominoes.ts:220-239 (zero callers) |\n| `dominoBelongsToSuit()` | dominoes.ts:255-320 (superseded, Nello in core) |\n| `canFollowSuit()` | rules.ts:43-50 (only test callers) |\n| `getPlayableSuits()` | domino-strength.ts:29-69 (identical to suitsWithTrump) |\n| Duplicate types | suit-analysis.ts:8-38 (already in types.ts) |\n| Local `isTrump()` | utilities.ts:152-163 (copy of core) |\n| `_suitAnalysis` param | hand-strength.ts:51 (never used) |\n\n## Consolidation\n\n- `getPlayableSuits()` → `rules.suitsWithTrump(state, d)` (100% identical logic)\n- `canFollowSuit()` → `player.hand.some(d =\u003e rules.canFollow(state, led, d))`\n- All suit membership → GameRules interface\n\n## Keep (Intentionally Different)\n\n- `canPlayIntoSuit()` in domino-strength.ts - AI prediction semantics (trump CAN respond)\n- `suitAnalysis` on Player - required for event sourcing + multiplayer filtering\n\n## Files to Modify (13 total)\n\n1. `src/game/core/dominoes.ts` - Delete 2 functions, update comments\n2. `src/game/core/rules.ts` - Delete canFollowSuit\n3. `src/game/core/suit-analysis.ts` - Remove duplicate type definitions\n4. `src/game/index.ts` - Remove canFollowSuit export\n5. `src/game/ai/domino-strength.ts` - Delete getPlayableSuits, use rules.suitsWithTrump\n6. `src/game/ai/hand-strength.ts` - Remove unused _suitAnalysis parameter\n7. `src/game/ai/utilities.ts` - Import isTrump from core\n8. `src/game/ai/strategies.ts` - Don't pass suitAnalysis\n9. `src/game/ai/rollout-strategy.ts` - Don't pass suitAnalysis\n10. `src/game/ai/monte-carlo.ts` - Simplify bidding evaluation\n11. `src/game/ai/cfr/mccfr-strategy.ts` - Don't pass suitAnalysis\n12. `src/tests/rules/gameplay/following-suit.test.ts` - Update assertions\n13. `src/tests/rules/renege-validation.test.ts` - Update assertions\n\n## Result\n\n~150 lines deleted, GameRules interface as single source of truth for suit logic.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T17:55:23.645991585-06:00","updated_at":"2025-12-20T22:18:59.674138322-06:00","closed_at":"2025-12-20T20:48:52.625910915-06:00","close_reason":"Completed suit system consolidation: deleted 2 dead functions (dominoContainsSuit, dominoBelongsToSuit), 1 duplicate function (canFollowSuit), 1 duplicate function (getPlayableSuits → suitsWithTrumpBase), duplicate types, local isTrump copy, and unused _suitAnalysis parameter. ~150 lines deleted, GameRules interface is now single source of truth for suit logic.","labels":["core","dx","refactor"],"dependencies":[{"issue_id":"t42-ofy","depends_on_id":"t42-e92","type":"parent-child","created_at":"2025-12-20T17:55:55.509121924-06:00","created_by":"jason"}]}
{"id":"t42-oqd","title":"MCTS Bidding + Delete Dead Lexicographic/Threshold Code","description":"## Problem (Updated)\n\nThe AI bidding system uses broken threshold-based logic that never worked well. Rather than fix the calibration, we're replacing it with MCTS simulation - the same approach that works well for play decisions.\n\n## Current State (Broken)\n\n- `lexicographic-strength.ts` computes hand scores\n- Scores compared to `BID_THRESHOLDS` (55, 998, 998...)\n- Thresholds completely miscalibrated → AI always bids 30, never passes\n- This code was never properly hooked up and is a dead end\n\n## New Approach: MCTS Bidding\n\nUse Monte Carlo simulation for bidding decisions (same as play MCTS):\n\n1. For each candidate bid:\n   - Sample N opponent hand distributions\n   - Select trump using `determineBestTrump()`\n   - Rollout full hand using beginner AI\n   - Track win rate (did we make the bid?)\n2. Select bid with highest win rate\n3. Pass if all bids below threshold\n\n### AI Tiers\n- **Beginner**: Uses MCTS for bidding (same as intermediate)\n- **Intermediate**: Uses MCTS for both bidding and plays\n\n## Implementation\n\n### Phase 1: Delete Dead Code\n- DELETE `src/game/ai/lexicographic-strength.ts`\n- DELETE `src/game/ai/hand-strength-components.ts`\n- Remove `BID_THRESHOLDS` from `hand-strength.ts` (keep `determineBestTrump`)\n- Remove threshold logic from `strategies.ts` `makeBidDecision()`\n- Update `docs/CONCEPTS.md` (remove lexicographic references)\n\n### Phase 2: Implement MCTS Bidding\n- Add `evaluateBidActions()` to `monte-carlo.ts`\n- Rewrite `makeBidDecision()` to use MCTS\n- Both beginner and intermediate use same implementation\n\n### Phase 3: Update Scripts \u0026 Tests\n- Rewrite `scripts/bid-validation.ts` for MCTS\n- Add unit tests for `evaluateBidActions()`\n\n## Files Affected\n\n| File | Action |\n|------|--------|\n| `src/game/ai/lexicographic-strength.ts` | DELETE |\n| `src/game/ai/hand-strength-components.ts` | DELETE |\n| `src/game/ai/hand-strength.ts` | Remove BID_THRESHOLDS |\n| `src/game/ai/monte-carlo.ts` | Add evaluateBidActions() |\n| `src/game/ai/strategies.ts` | Rewrite makeBidDecision() |\n| `scripts/bid-validation.ts` | Rewrite for MCTS |\n| `docs/CONCEPTS.md` | Remove lexicographic refs |\n\n## Acceptance Criteria\n\n- [ ] No lexicographic strength code remains\n- [ ] No BID_THRESHOLDS code remains\n- [ ] MCTS bidding implemented\n- [ ] AI passes ~70-80% of the time (vs current ~10%)\n- [ ] AI bids appropriate amounts based on win rate\n- [ ] bid-validation.ts works with new system\n- [ ] All tests pass","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-20T16:49:59.081168963-06:00","updated_at":"2025-12-20T22:18:59.691292795-06:00","closed_at":"2025-12-02T21:59:12.70524058-06:00"}
{"id":"t42-oqs0","title":"Feature: PIMC-learned move ordering","description":"Context: Our PIMC/minimax uses fixed heuristics in orderMoves; move ordering drives alpha-beta pruning and practical play quality. Current heuristic (lead non-count, dump when partner winning) is static and ignores per-hand evidence from sampled worlds. \n\nMotivation: Use PIMC telemetry to learn which move features correlate with higher EV/win rate within the current hand/trump, so search prunes faster and lines reflect the sampled world instead of generic rules. This should especially help in swingy bids (36-42) and trump-sparse hands where the static heuristic misorders winning lines.\n\nDesired outcome: A lightweight learning orderer that, during PIMC simulations, buckets per-play features (led suit, trump, trick position, partner winning?, is trump, pip bucket, is double) and aggregates win/EV stats. orderMoves consumes these aggregates to score actions instead of the static heuristic. Cache is in-memory per hand (no persistence) and falls back to old heuristic when no data.\n\nHow to measure: 1) Unit/bench: node count vs baseline for fixed seeds (expect fewer nodes with similar result). 2) Play-level: compare average EV/win rate across 1k sampled worlds for the same positions with/without learning orderer. 3) Gameplay: fewer obvious misorders (burning high count while behind, spending trump to take low EV tricks) in seeded replays.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-22T22:45:16.657381365-06:00","updated_at":"2025-12-23T16:18:31.50209827-06:00","closed_at":"2025-12-23T16:18:31.50209827-06:00","close_reason":"Research concluded: learned move ordering within PIMC provides only marginal speedup (2-3x in endgame) due to constant factor improvement in alpha-beta pruning. Doesn't solve the core problem: PIMC is too slow for testing because it runs full minimax (10 sims × 4-5 moves × exponential tree). The real solution is t42-6nf (policy network) - distill PIMC's wisdom into a fast neural net that runs in milliseconds. Move ordering optimization is superseded by this approach."}
{"id":"t42-oqvi","title":"solver2: post-VRAM-fix speed optimizations (rules tables + reward path)","description":"After t42-ze7i (score removed from state) lands, do a speed-focused pass on scripts/solver2 for large-scale GPU runs.\n\nKey targets (current code):\n- scripts/solver2/solve.py compute_transition_rewards() builds TRICK_* indices and gathers winner/points for every chunk (and loops in Python over 7 moves).\n- scripts/solver2/expand.py does TRICK_WINNER gathers inside move loop even though only trick_len==3 needs it.\n- enumeration still relies heavily on torch.unique; need to minimize its input and peak temps.\n\nWork items:\n1) Precompute signed trick rewards table in SeedContext\n   - Add TRICK_REWARD[int8] with entries already +points (team0 wins) / -points (team1 wins)\n   - Optionally keep TRICK_WINNER/TRICK_POINTS for debugging, but remove them from hot paths\n\n2) Compute transition rewards only for completing states\n   - In solve path, filter to completes indices (trick_len==3) so we don't gather TRICK_* for mid-trick states\n   - Avoid allocating full (N,7) rewards when most rows are mid-trick (or compute rewards directly into cv_with_rewards)\n\n3) Avoid trick-outcome lookups for non-completing states in expand\n   - Split completes/~completes code paths or index only completes subset before gathering winner\n\n4) Vectorize move dimension (remove Python loops over 7 where possible)\n   - Use broadcasted moves to build (K,7) trick_idx and gather in one shot\n   - Apply same idea to expand and reward computations\n\n5) Reduce dtype/temporary overhead in state helpers\n   - popcount table can be int8; compute_level can be incremental to reduce temp tensors\n\n6) Enumeration dedup tuning\n   - Benchmark alt dedup per chunk (sort + unique_consecutive) vs torch.unique for speed/peak memory\n   - Keep enum_chunk_size effective; expose it in CLI if not already\n\nAcceptance:\n- Same root values and move_values as baseline for a small seed set\n- Measurable per-seed runtime reduction on RTX 3050 (target: \u003e20% faster)\n- No regression in peak VRAM on 4GB GPUs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T18:45:48.234584746-06:00","updated_at":"2025-12-27T20:22:00.999993666-06:00","closed_at":"2025-12-27T20:22:00.999993666-06:00","close_reason":"Implemented phases 1-3: int8 popcount, TRICK_REWARD precomputed table, vectorized compute_transition_rewards with completes filtering. Achieved 63-69% speedup (9.6s→3.5s for 7.6M states). Phase 4 (expand_gpu vectorization) filed as t42-ne8i.","dependencies":[{"issue_id":"t42-oqvi","depends_on_id":"t42-ze7i","type":"discovered-from","created_at":"2025-12-27T18:45:48.238701323-06:00","created_by":"jason"},{"issue_id":"t42-oqvi","depends_on_id":"t42-ze7i","type":"blocks","created_at":"2025-12-27T18:45:48.239909396-06:00","created_by":"jason"}]}
{"id":"t42-os3","title":"Replace JSON.stringify with direct comparison in kernel.ts","description":"## Context\nPerformance optimization for seedFinder/gameSimulator hot paths.\n\n## Problem\nkernel.ts uses JSON.stringify() for object comparison and deep cloning in hot paths:\n- Line 254: Trump comparison via JSON serialization (called 100+ times per state)\n- Lines 216 \u0026 375: Deep cloning action metadata via JSON round-trip\n\n## Tasks\n1. Replace JSON.stringify trump comparison (line 254) with direct equality function\n2. Investigate if metadata deep cloning (lines 216, 375) is actually necessary\n3. If cloning needed, use faster method (structuredClone or manual clone)\n\n## Impact\n- Line 254: 10-100x faster per comparison (called in every findMatchingTransition)\n- Lines 216/375: Potentially significant if metadata is large\n\n## Files\n- src/kernel/kernel.ts:216,254,375\n\n## Related\nPart of seedFinder performance optimization investigation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-19T15:43:01.082998635-06:00","updated_at":"2025-12-20T22:18:59.694258723-06:00","closed_at":"2025-11-19T21:27:17.411830506-06:00"}
{"id":"t42-otet","title":"Make derived fields required in view-projection (Crystal Palace completion)","description":"Use texas-42 skill.\n\n## Problem\nThe `derived` parameter in `createViewProjection()` is optional with fallbacks, which violates the Crystal Palace \"dumb client\" principle:\n\n```typescript\noptions: {\n  derived?: DerivedViewFields;  // Should be required!\n}\n```\n\nFallbacks that need removal:\n- Line 224: `derived?.currentTrickWinner ?? -1`\n- Line 185-190: Tooltip fallback to generic text\n- Line 310: `derived?.currentHandPoints ?? calculateTeamPoints(...)`\n\n## Task\n1. Make `derived: DerivedViewFields` required (remove `?`)\n2. Remove all `??` fallback patterns for derived fields\n3. Update all test files that call `createViewProjection()` to provide proper derived fields\n4. Consider creating a test helper `createTestDerived(state, rules)` that computes real derived fields for tests\n\n## Files to Update\n\n### Core\n- `src/game/view-projection.ts` - Make derived required, remove fallbacks\n\n### Tests (grep for `createViewProjection`)\n- Find all test files using createViewProjection\n- Update each to pass derived fields\n\n### Helpers\n- `src/tests/helpers/` - May need a helper to compute derived fields for tests\n\n## Verification\n- `npm run typecheck` - no errors\n- `npm run test:all` - all pass\n- Grep for `derived\\?\\.` in view-projection.ts - should find nothing","notes":"Scope analysis shows only ~6 files to update:\n\n**Main files:**\n- `src/game/view-projection.ts` - Make derived required\n- `src/stores/gameStore.ts` - Already passes derived\n\n**Fixtures:**\n- `src/tests/fixtures/game-states.ts` - Has `createDefaultDerived()` helper\n\n**Tests:**\n- `src/tests/guardrails/projection-security.test.ts`\n- `src/tests/guardrails/no-bypass.test.ts`\n\nSmall task, maybe 15-20 turns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T17:42:39.031416209-06:00","updated_at":"2025-12-21T17:46:03.405004315-06:00","closed_at":"2025-12-21T17:46:03.405004315-06:00","close_reason":"Made derived required in createViewProjection options, removed all ?? fallback patterns. Tests pass.","dependencies":[{"issue_id":"t42-otet","depends_on_id":"t42-g4y","type":"discovered-from","created_at":"2025-12-21T17:42:45.011150968-06:00","created_by":"jason"}]}
{"id":"t42-ovlu","title":"GPU solver: fit 85M state solve in 4GB VRAM","description":"Use texas-42 skill.\n\n## Problem\nSolve Texas 42 game trees on RTX 3050 Ti (4GB VRAM). For seed=42: 85M states.\n\n## Three-Phase Solver\n1. **Enumerate** (BFS): Find all reachable states → 2.08GB peak ✅\n2. **Build child_idx**: Map moves to child positions → 3.31GB peak ✅  \n3. **Solve** (backward induction): Compute minimax → 4.52GB peak ❌\n\n## What Works\n- Chunked expand_gpu (500k chunks): 13s→1.2s, 6.4GB→0.9GB\n- Removed redundant cross-level dedup (levels are disjoint by bit encoding)\n- Chunked build_child_index: 8.4GB→3.31GB\n- int32 for child_idx: saves 2.4GB\n- Keep child_idx on CPU during solve: 7.6GB→4.52GB\n\n## The 0.5GB Gap\nDuring solve, largest level (L5) has 14M states. Per-level temps:\n- cidx: 14M×7×4 = 392MB (int32)\n- cidx.long(): 14M×7×8 = 784MB (PyTorch requires int64 for indexing!)\n- cv, cv16, cv_max, cv_min: ~100-200MB each\n- Total: ~2GB temporaries\n\nBase arrays (V, level_of, is_team0): ~250MB\n\n## Untried Ideas\n1. Sub-chunk large levels (2M at a time instead of 14M)\n2. Fuse operations to reduce intermediate tensors\n3. Use torch.take instead of fancy indexing (might accept int32?)\n\n## Files\n- scripts/solver/solve.py - main solver\n- scripts/solver/expand.py - state expansion\n- scripts/solver/state.py - bit packing\n- scripts/solver/context.py - precomputed tables\n\n## Goal\nFull solve_seed(42, 0) completing in \u003c60s with peak VRAM \u003c4GB","notes":"Dev pace: Use verbose logging and short timeouts (15s). Better to fail fast and increase than wait 3+ mins on blank screen.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T16:42:47.869627282-06:00","updated_at":"2025-12-27T19:05:47.525000935-06:00","closed_at":"2025-12-27T19:05:47.525000935-06:00","close_reason":"Obsolete - superseded by solver2 implementation"}
{"id":"t42-pbs","title":"Hall's condition violation in constraint tracker during MCTS play evaluation","description":"Use texas-42 skill.\n\nThe constraint tracker (src/game/ai/constraint-tracker.ts) can produce constraints that violate Hall's condition, making hand sampling impossible even though the real game state is valid.\n\nError occurs in evaluatePlayActions() when sampleOpponentHands() fails with:\n\"Hall's condition violated for player X. This indicates a bug in constraint tracking.\"\n\nExample failure (seed 12345):\n- 4 tricks played, 2 in current trick\n- Pool size: 7 dominoes\n- Expected sizes: [3, 2, 2, 3] (myPlayerIndex=3)\n- Void constraints too restrictive for valid distribution\n\nThe real game state IS satisfiable (it's the actual game), so the constraint inference is over-constraining.\n\nExposed by MCTS refactor (mk5-tailwind-oqd) where BeginnerAIStrategy now uses Monte Carlo for plays, not just bidding.\n\n## Skipped tests (re-enable after fix)\n- src/tests/integration/complete-game-flow.test.ts: \"should complete game with beginner MCTS strategy\"\n- src/tests/unit/seedFinder.test.ts: \"should return consistent results for the same seed\"\n\nThese tests use random AI strategy as workaround because BeginnerAI with MCTS is too slow when the fallback to heuristics triggers frequently.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-02T21:42:35.433471264-06:00","updated_at":"2025-12-20T22:18:59.734262735-06:00","closed_at":"2025-12-02T22:34:11.516970935-06:00","labels":["ai","mcts"]}
{"id":"t42-q86b","title":"GPU solver performance: cache context tables on device","description":"Use texas-42 skill. Current solve time is 22s for seed=100 (10.3M states), target is 2-3s per spec.\n\nRoot cause: Context tables (L, LOCAL_FOLLOW, TRICK_WINNER, TRICK_POINTS) are transferred CPU→GPU on every expand_gpu() call - that's 29+ device transfers per solve.\n\nFix:\n1. Add to(device) method to SeedContext in context.py\n2. Call ctx.to(device) once in solve_seed()\n3. Remove .to(device) calls from expand.py lines 33-36\n\nExpected: 5-10x speedup (22s → 2-4s)\n\nSecondary optimizations (if needed):\n- Remove periodic torch.unique() during BFS (solve.py:92-94)\n- Pre-compute level indices to avoid nonzero() in solve_gpu","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T15:03:05.345279088-06:00","updated_at":"2025-12-27T15:24:40.398957809-06:00","closed_at":"2025-12-27T15:24:40.398957809-06:00","close_reason":"Implemented ctx.to(device) caching - context tables now transferred once instead of 29x. Discovered torch.unique() is the real bottleneck (7-11s per call at large levels). Created t42-lrcv for that fix."}
{"id":"t42-q9v","title":"Decompose gameStore.ts God Object","description":"Use texas-42 skill.\n\n557 lines handling game creation, action execution, URL replay, perspective switching, one-hand mode, and seed finding. Split into focused modules.\n\nFiles: src/stores/gameStore.ts","design":"## God Object Decomposition Analysis\n\n**File**: src/stores/gameStore.ts (557 lines)\n**Status**: Detailed decomposition design complete\n\n### Seven Distinct Responsibilities Identified\n\n**R1: URL State Management** (lines 7, 156-226)\n- Encoding/decoding game state to/from URL parameters\n- Browser history sync\n- Extract to: `urlGameState.ts` (~50 lines, pure functions)\n\n**R2: Game Lifecycle Management** (lines 234-271, 385-461)\n- Creating, resetting, initializing games\n- AI attachment management\n- Extract to: `gameLifecycle.ts` (~120 lines, clear interface)\n\n**R3: Action Replay Logic** (lines 298-353)\n- Replaying action sequences deterministically\n- Player index resolution for actions\n- Extract to: `actionReplay.ts` (~60 lines, pure functions)\n\n**R4: Svelte Store Derivations** (lines 80-148)\n- Creating reactive derived stores from base state\n- ViewProjection computation\n- Extract to: `gameDerivedStores.ts` (~80 lines, testable transformations)\n\n**R5: Perspective Management** (lines 404-428)\n- Switching viewing perspectives\n- Player control type changes\n- Extract to: `perspectiveManager.ts` (~60 lines, focused interface)\n\n**R6: Action Execution** (lines 362-380)\n- Validating and executing player actions\n- Capability checking\n- Extract to: `actionExecutor.ts` (~40 lines, clear preconditions)\n\n**R7: Configuration \u0026 Initialization** (lines 22-32, 38-69, 90)\n- Setting up player types, test mode, initial state\n- Will be absorbed into module constructors\n\n### Cross-Cutting Concerns\n\n**CC1: Client Management** - Tangled with lifecycle, needs extraction\n**CC2: Public API Surface** - Scattered exports, needs consolidation\n\n### Proposed Architecture\n\n```\nurlGameState (LEAF) ──┐\nactionReplay (LEAF) ──┤\nperspectiveManager ───┤\nactionExecutor ───────┤\ngameDerivedStores ────┤\n                      ├──→ gameLifecycle ──→ gameStore (FACADE)\n```\n\nFinal gameStore.ts becomes ~150 line facade that:\n- Composes all 6 modules\n- Exposes same public API (zero breaking changes)\n- Orchestrates subscriptions and lifecycle\n\n### Migration Strategy\n\n1. Extract LEAF modules first (no internal dependencies)\n2. Extract gameLifecycle (depends on actionReplay, urlGameState)\n3. Slim gameStore to pure composition\n4. Test after each extraction (incremental safety)\n\n### Risk Assessment\n\n**Complexity**: Medium-High (7 module extraction)\n**Breaking Changes**: Low (public API preserved)\n**Testing Burden**: Medium (~70 unit tests + 15 integration tests)\n\n**Key Risks**:\n- R1: Reactivity breakage (store updates)\n- R2: URL sync timing (history pollution)\n- R3: AI attachment race (replay + AI)\n- R4: Perspective auto-correct (invalid state)\n- R5: Module coupling (circular dependencies)\n\n**Mitigations**: DAG structure enforcement, dependency injection, incremental testing\n\n### Success Criteria\n\n✓ Each module has single, clear responsibility\n✓ Each module testable in isolation  \n✓ Public API unchanged\n✓ All reactivity preserved\n✓ No module exceeds 150 lines\n✓ Module dependencies form DAG\n✓ All tests pass\n\n**Estimated effort**: 8-12 hours focused work\n**Value**: High (maintainability, testability, clarity)\n\nSee full analysis: /home/jason/.claude/plans/purrfect-percolating-button-agent-06de4e7a.md","status":"open","priority":3,"issue_type":"chore","created_at":"2025-11-29T12:10:06.48321533-06:00","updated_at":"2025-12-20T22:18:59.80656268-06:00","dependencies":[{"issue_id":"t42-q9v","depends_on_id":"t42-8ee","type":"blocks","created_at":"2025-11-29T12:10:23.462289989-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-q9v","depends_on_id":"t42-4b9","type":"parent-child","created_at":"2025-11-29T12:10:37.743339701-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"t42-qnwe","title":"Crystal Palace follow-through: cleanup and assessment","description":"Use texas-42 skill.\n\n## Final Follow-Through for Crystal Palace Epic\n\nAfter all implementation is complete (f26 → lq0 → mtq → 3xp7 → 20ue → r3ia), perform these final steps:\n\n### 1. Delete trump-unification documents\n- `docs/trump-unification-codex.md`\n- `docs/trump-unification-gemini.md`\n- `docs/trump-unification-opus.md`\n- Keep `docs/archive/` versions if any exist there\n\n### 2. Validate implementation\n- Run `npm run test:all` - all tests must pass\n- Run `npm run typecheck` - no errors\n- Run `npm run lint` - no errors\n\n### 3. Assess for outstanding/discovered work\n- Grep codebase for any remaining rule logic outside GameRules\n- Check if any bypasses were missed\n- Review AI modules for any lingering core/ imports\n- Check if any documentation needs updating\n\n### 4. Create beads for any discovered issues\n- File new beads for any gaps found\n- Link them appropriately\n\n### 5. Close the epic\n- Close t42-g4y (Crystal Palace) if all acceptance criteria met","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T11:14:11.083807478-06:00","updated_at":"2025-12-21T12:24:14.041644381-06:00","closed_at":"2025-12-21T12:24:14.041644381-06:00","close_reason":"Crystal Palace follow-through complete: deleted trump-unification docs, all tests/typecheck/lint pass (fixed minor unused imports in guardrail tests), assessed codebase for remaining issues (none found), verified all acceptance criteria met, closed epic t42-g4y.","dependencies":[{"issue_id":"t42-qnwe","depends_on_id":"t42-r3ia","type":"blocks","created_at":"2025-12-21T11:14:18.897375444-06:00","created_by":"jason"},{"issue_id":"t42-qnwe","depends_on_id":"t42-g4y","type":"parent-child","created_at":"2025-12-21T11:14:19.083841335-06:00","created_by":"jason"}]}
{"id":"t42-qr2","title":"Summary","description":"**4 new phases** (16-19) + 1 documentation phase (20):","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T13:51:33.099531296-06:00","updated_at":"2025-12-20T22:18:59.763647371-06:00","closed_at":"2025-11-24T13:51:50.242514773-06:00"}
{"id":"t42-qsg6","title":"Fix trick completion assumptions in kernel/view-projection","description":"Use texas-42 skill.\\n\\nSeveral places assume a 4-play trick (standard 4-player) instead of delegating to rules/layers. This breaks nello (3-player tricks) and any future non-4 trick variants.\\n\\nEvidence:\\n- src/kernel/kernel.ts computes currentTrickWinner only when currentTrick.length === 4\\n- src/game/view-projection.ts sets TrickDisplay.isComplete via currentTrick.length === 4 and depends on derived.currentTrickWinner\\n\\nFix direction:\\n- In kernel derived fields, compute \"is trick complete\" via ctx.rules.isTrickComplete(state) (or equivalent based on coreState/currentTrick)\\n- Compute currentTrickWinner when rules says trick complete\\n- Extend DerivedViewFields with isCurrentTrickComplete (and/or trickSizeExpected) so client never hardcodes 4\\n- Update view-projection/UI to use derived values instead of length===4","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-27T00:29:44.797693461-06:00","updated_at":"2025-12-27T00:29:44.797693461-06:00","dependencies":[{"issue_id":"t42-qsg6","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:29:44.801757099-06:00","created_by":"jason"}]}
{"id":"t42-qvr","title":"Estimated Scope","description":"- ~50-60 files to modify","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T16:24:26.894886599-06:00","updated_at":"2025-12-20T22:18:59.76147257-06:00","closed_at":"2025-11-25T08:55:03.767013474-06:00"}
{"id":"t42-r3ia","title":"Guardrails and contract tests","description":"Add tests enforcing rule contract: base + special contracts across getLedSuit/suitsWithTrump/canFollow/rankInTrick/calculateTrickWinner/isTrump. Add no-bypass checks to block rule logic imports from core/dominoes.ts/scoring.ts in UI/AI. Add projection security tests to ensure no hidden state leaks and all rule-aware fields come from server rules.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T11:03:57.5087617-06:00","updated_at":"2025-12-21T12:20:13.852486136-06:00","closed_at":"2025-12-21T12:20:13.852486136-06:00","close_reason":"Closed","dependencies":[{"issue_id":"t42-r3ia","depends_on_id":"t42-g4y","type":"discovered-from","created_at":"2025-12-21T11:03:57.512206598-06:00","created_by":"jason"},{"issue_id":"t42-r3ia","depends_on_id":"t42-20ue","type":"blocks","created_at":"2025-12-21T11:13:53.844365103-06:00","created_by":"jason"}]}
{"id":"t42-r4x","title":"Investigate 3 sevens-full-hand.test.ts failures - zero play transitions generated","description":"Tests failing:\n1. should complete successful sevens when bidding team wins all 7 tricks - expected playTransitions.length \u003e 0, got 0\n2. should award correct marks for successful sevens - expected playTransitions.length \u003e 0, got 0\n3. should end early when opponents win the first trick - expected teamMarks[1] \u003e 0, got 0\n\nRoot cause: Different issue than base/nello. Sevens games are NOT generating ANY play actions at all. This suggests:\n- Problem in action generation for sevens phase\n- Game transitioning to scoring before playing starts\n- Sevens ruleset not being composed correctly\n- Issue with how sevens initializes\n\nThis is P0 because it's a complete failure, not just incorrect test expectations.","notes":"RESOLVED: Fixed multiple issues:\n\n1. Invalid hand fixtures - had duplicate dominoes (only 22 unique instead of 28)\n2. Redundant getNextPlayer override in sevens ruleset causing P0 to play twice per trick  \n3. Simplified test to use HeadlessRoom pattern (crystal palace approach)\n4. Removed meaningless strategy parameter (sevens is deterministic)\n5. Added partner-wins-and-leads test\n\nRoot cause was sevens.ts getNextPlayer override interfering with base rotation. Removed override - core engine already handles winner-leads-next-trick correctly.\n\nAll 5 tests now pass.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-17T16:40:12.714194111-06:00","updated_at":"2025-12-20T22:18:59.662925516-06:00","closed_at":"2025-11-19T12:02:52.327802857-06:00"}
{"id":"t42-rl4","title":"Phase 10: Update test helpers","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.324384344-06:00","updated_at":"2025-12-20T22:18:59.773113243-06:00","closed_at":"2025-11-24T13:30:23.17715022-06:00","dependencies":[{"issue_id":"t42-rl4","depends_on_id":"t42-31j","type":"blocks","created_at":"2025-11-24T10:35:50.395920572-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-rl4","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:54.724187218-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-s1o","title":"Optimize PIMC 2: Enumerate endgame rather than over-sample","description":"Use texas-42 skill.\n\nPerformance optimization for PIMC: in late game, enumerate all possible opponent hand distributions rather than sampling.\n\n## Problem\n\nWith 3 plays remaining, the number of possible opponent hand configurations is small. Sampling wastes time hitting the same configurations multiple times.\n\n## Investigation\n\nCollect stats on last 3 plays:\n- How many distinct opponent hand configurations exist?\n- At what point does enumeration become cheaper than sampling?\n\n## Solution\n\nWhen the number of possible configurations is below a threshold (e.g., \u003c100):\n- Enumerate all valid opponent hand distributions\n- Run minimax on each\n- Weight by probability if needed (or assume uniform)\n\nThis gives exact expected value instead of Monte Carlo approximation.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-20T09:26:23.70457011-06:00","updated_at":"2025-12-20T22:18:59.710396587-06:00","dependencies":[{"issue_id":"t42-s1o","depends_on_id":"t42-9ed","type":"blocks","created_at":"2025-12-20T09:26:31.390129579-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-s6u","title":"[Maintenance \u0026 Cleanup] Update dependencies and address security vulnerabilities","description":"Use texas-42 skill.\n\nMany package.json dependencies are outdated. This task involves:\n\n1. Run `npm audit` to identify security vulnerabilities\n2. Review outdated packages with `npm outdated`\n3. Update packages to bring in latest performance improvements and features\n4. Run full test suite after updates to ensure nothing breaks\n\nRelated to mk5-tailwind-stg (audit for unused dependencies) - could be done together.\n\n## Completion Checklist\n\n1. Run `npm run test:all` and fix ANY issues (including pre-existing failures)\n2. Commit changes to git (do NOT push or bd sync)","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-29T11:17:41.327182295-06:00","updated_at":"2025-12-20T22:18:59.8117787-06:00","closed_at":"2025-12-20T10:37:43.866953885-06:00","close_reason":"Closed","labels":["maintenance"]}
{"id":"t42-s7rh","title":"Unify trick-based contract scoring with shared helper","description":"Use texas-42 skill.\n\nThe scoring logic for trick-based contracts (nello, sevens, plunge, splash) is nearly identical but duplicated 4 times. They already share `checkTrickBasedHandOutcome(state, team, mustWin)` for early termination - the scoring should use the same pattern.\n\n## Current Duplication\n\n| Layer | Lines | Logic |\n|-------|-------|-------|\n| nello.ts | 45-70 | biddingTeamTricks === 0 |\n| sevens.ts | 51-76 | nonBiddingTeamTricks === 0 |\n| doubles-bid-factory.ts | 85-108 | nonBiddingTeamTricks === 0 |\n\nAll do the same thing: count tricks, check if correct team has zero, award marks accordingly.\n\n## Solution\n\nAdd a helper to `helpers.ts`:\n```typescript\nexport function calculateTrickBasedScore(\n  state: GameState,\n  mustWin: boolean  // same param as checkTrickBasedHandOutcome\n): [number, number] {\n  const bidder = state.players[state.winningBidder];\n  if (!bidder) return state.teamMarks;\n  \n  const biddingTeam = bidder.teamId;\n  const opponentTeam = biddingTeam === 0 ? 1 : 0;\n  \n  // Count tricks for the team that must have zero\n  const teamToCheck = mustWin ? opponentTeam : biddingTeam;\n  const tricksWon = state.tricks.filter(trick =\u003e {\n    if (trick.winner === undefined) return false;\n    const winner = state.players[trick.winner];\n    return winner?.teamId === teamToCheck;\n  }).length;\n  \n  const newMarks: [number, number] = [...state.teamMarks];\n  if (tricksWon === 0) {\n    newMarks[biddingTeam] += state.currentBid.value!;\n  } else {\n    newMarks[opponentTeam] += state.currentBid.value!;\n  }\n  return newMarks;\n}\n```\n\n## Usage After\n\n```typescript\n// nello.ts\ncalculateScore: (state, prev) =\u003e {\n  if (state.currentBid.type !== BID_TYPES.MARKS || state.trump.type !== 'nello') return prev;\n  return calculateTrickBasedScore(state, false);  // mustWin = false\n}\n\n// sevens.ts\ncalculateScore: (state, prev) =\u003e {\n  if (state.currentBid.type !== BID_TYPES.MARKS || state.trump.type !== 'sevens') return prev;\n  return calculateTrickBasedScore(state, true);  // mustWin = true\n}\n\n// doubles-bid-factory.ts\ncalculateScore: (state, prev) =\u003e {\n  if (state.currentBid?.type !== name) return prev;\n  return calculateTrickBasedScore(state, true);  // mustWin = true\n}\n```","acceptance_criteria":"- [ ] Add calculateTrickBasedScore helper to helpers.ts\n- [ ] Update nello.ts to use helper with mustWin=false\n- [ ] Update sevens.ts to use helper with mustWin=true\n- [ ] Update doubles-bid-factory.ts to use helper with mustWin=true\n- [ ] npm run test:all passes","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-26T19:25:49.549531961-06:00","updated_at":"2025-12-26T19:35:20.622373081-06:00","closed_at":"2025-12-26T19:35:20.622373081-06:00","close_reason":"Implemented calculateTrickBasedScore helper, updated nello/sevens/doubles-bid-factory to use it. All tests pass."}
{"id":"t42-seg","title":"Success Criteria","description":"- Zero occurrences of \"RuleSet\" in src/ (except in historical comments)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T16:24:26.899248852-06:00","updated_at":"2025-12-20T22:18:59.760696902-06:00","closed_at":"2025-11-25T08:55:04.599654782-06:00"}
{"id":"t42-shyv","title":"Integrate policy network as game AI player","description":"Use texas-42 skill.\n\n## Goal\n\nWire the policy network into the game as a selectable AI difficulty level.\n\n## AI Strategy Implementation\n\n```typescript\n// src/game/ai/neural-strategy.ts\nexport class NeuralAIStrategy implements AIStrategy {\n  private policyNet: PolicyNet;\n  \n  async selectAction(view: PlayerView): Promise\u003cGameAction\u003e {\n    // 1. Extract state from view\n    const state = extractPackedState(view);\n    \n    // 2. Get policy logits\n    const logits = await this.policyNet.predict(state);\n    \n    // 3. Mask illegal moves\n    const legal = getLegalMask(view);\n    \n    // 4. Sample or argmax\n    const localIdx = this.selectMove(logits, legal);\n    \n    // 5. Convert to GameAction\n    return { type: 'play', domino: view.hand[localIdx] };\n  }\n}\n```\n\n## Configuration\n\nAdd to AI difficulty options:\n- Beginner: Random/Heuristic\n- Intermediate: Monte Carlo  \n- **Expert: Neural Network** ← new\n\n## UI Changes\n\n- AI difficulty selector includes 'Expert'\n- Model loads on first Expert game (lazy load)\n- Loading indicator while model downloads\n\n## Testing\n\n- NeuralAI vs MonteCarloAI benchmark\n- Verify NeuralAI makes legal moves\n- Performance: \u003c5ms per decision\n\n## Files\n\n- `src/game/ai/neural-strategy.ts`\n- `src/game/ai/index.ts` (add export)\n- `src/server/Room.ts` (wire up difficulty)\n- `public/models/policy-net.onnx` (model file)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T20:58:14.249460178-06:00","updated_at":"2025-12-27T20:58:14.249460178-06:00","dependencies":[{"issue_id":"t42-shyv","depends_on_id":"t42-fo5q","type":"blocks","created_at":"2025-12-27T20:58:22.017853914-06:00","created_by":"jason"}]}
{"id":"t42-spx","title":"Unify 5 implementations of can-follow-suit logic into single function","description":"Use texas-42 skill.\n\n## Context\n\nDuring mk5-tailwind-lfy fix, we discovered 5 implementations of \"can domino follow suit\" logic scattered across the codebase:\n\n| Location | Function | Status |\n|----------|----------|--------|\n| `rules.ts:36-72` | `canFollowSuit(player, suit, trump)` | Fixed in mk5-tailwind-lfy |\n| `compose.ts:176-187` | inline filter in `getValidPlaysBase` | Correct |\n| `constraint-tracker.ts:34-81` | `canFollowSuitForConstraints` | Correct |\n| `domino-strength.ts:98-106` | `canFollowSuit(domino, suit, trump)` | Correct |\n| `dominoes.ts:237-256` | `dominoContainsSuit` | Correct (slightly different semantics) |\n\n## Semantic Clarification Needed\n\nThe current naming is confusing. There are two distinct concepts:\n\n1. **CAN follow suit** - Is this domino legally capable of following the led suit?\n   - A trump domino CAN be played even when it doesn't follow suit\n   - But a trump domino CANNOT be used to \"follow\" a non-trump suit\n\n2. **REQUIRED to follow suit** - Must the player follow suit if able?\n   - You are ALWAYS required to follow suit if you have a non-trump domino of the led suit\n   - If you can't follow suit, you CAN play trump (but aren't required to)\n   - If you can't follow suit and have no trump, you can play anything\n\n### Current confusing semantics:\n\n- `canFollowSuit(player, suit, trump)` in rules.ts - Answers \"does player have dominoes that can legally follow this suit?\" (excludes trump)\n- `canFollowSuit(domino, suit, trump)` in domino-strength.ts - Returns TRUE for trump dominoes because they \"can follow\" by trumping in\n\nThese answer different questions with the same function name!\n\n## Proposal\n\nWhen unifying, clarify naming:\n\n- `canDominoFollowSuit(domino, ledSuit, trump)` → Can this domino legally satisfy the follow-suit requirement? (Returns false for trump when non-trump led)\n- `isDominoLegalPlay(domino, ledSuit, trump, canPlayerFollowSuit)` → Is this a legal play given context?\n- Or document clearly that \"follow suit\" means \"satisfy the follow-suit rule\", not \"can be played\"\n\n## Files to Modify\n\n1. `src/game/core/dominoes.ts` - Add unified function with clear semantics\n2. `src/game/core/rules.ts` - Use new function\n3. `src/game/layers/compose.ts` - Replace inline filtering\n4. `src/game/ai/constraint-tracker.ts` - Replace `canFollowSuitForConstraints`\n5. `src/game/ai/domino-strength.ts` - Replace local function (note: may need different semantics)\n\n## Benefits\n\n- Single source of truth for this critical game concept\n- Clear, unambiguous naming\n- Eliminates duplication (5 implementations → 1 or 2 with clear purposes)\n- Aligns with codebase \"crystal palace\" philosophy","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-29T10:01:37.573369154-06:00","updated_at":"2025-12-20T22:18:59.812530133-06:00","closed_at":"2025-11-29T12:12:45.716063404-06:00","labels":["core","dx","refactor"]}
{"id":"t42-stg","title":"[Maintenance \u0026 Cleanup] Audit package.json for unused/vestigial dependencies","description":"Use texas-42 skill.\n\nReview package.json and identify any dependencies or devDependencies that are no longer used in the codebase. Remove unused packages to keep the project clean.\n\n## Completion Checklist\n\n1. Run `npm run test:all` and fix ANY issues (including pre-existing failures)\n2. Commit changes to git (do NOT push or bd sync)","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-27T10:44:43.416384894-06:00","updated_at":"2025-12-20T22:18:59.819598627-06:00","closed_at":"2025-12-20T10:29:49.229676584-06:00","close_reason":"Closed","dependencies":[{"issue_id":"t42-stg","depends_on_id":"t42-xxi","type":"parent-child","created_at":"2025-11-28T10:14:53.649308545-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-szy","title":"URL compression: explore branching for 'what if I played...' scenarios","description":"Use texas-42 skill.\n\nExplore adding branching support to URL state compression. This would enable 'what if' analysis:\n\n## Use Cases\n- **Post-game analysis**: 'What if I had played the 6-4 instead of the 5-5?'\n- **Teaching**: Show alternative lines and their outcomes\n- **Debugging**: Compare different play sequences from the same position\n\n## Design Questions\n- How to encode branch points in the URL? (fork notation like git?)\n- Should branches be named/labeled?\n- How to handle UI for navigating branches?\n- Memory/URL length implications of multiple branches?\n\n## Possible Approaches\n1. **Tree encoding**: Full action tree with branch markers\n2. **Diff-based**: Store deltas from main line\n3. **Multiple URLs**: Link between related game states\n4. **Hybrid**: Main line in URL, branches in localStorage\n\n## Related\n- Current URL compression in src/utils/urlCompression.ts\n- Event sourcing makes this natural - just fork the action history","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-19T20:44:54.235940919-06:00","updated_at":"2025-12-20T22:18:59.795108138-06:00"}
{"id":"t42-t3g","title":"Investigate sevens early termination bug - partner wins should not end hand","description":"Sevens ruleset incorrectly returns determined=true when partner wins a trick. Expected: partner winning should allow play to continue (only opponents winning should trigger early termination). Affected test: 'user scenario: partner wins with 7, not set' in sevens-ruleset.test.ts:628. Pre-existing bug, not caused by discriminated union refactor.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-11-16T17:16:39.455577857-06:00","updated_at":"2025-12-20T22:18:59.665084346-06:00","closed_at":"2025-11-16T19:23:28.701385029-06:00"}
{"id":"t42-tgr","title":"Gate: Remove MCCFR code and document in archive","description":"Use texas-42 skill.\n\nMCCFR (Monte Carlo Counterfactual Regret Minimization) was explored but the count-centric abstraction proved too lossy. The strategy couldn't learn suit-specific play (e.g., 'don't lead 5-0 when treys are trump').\n\n## Decision\n\nCFR is punted. 'Boring and competent' isn't worth the squeeze when we could get that with fixed MCTS, and neural nets offer more upside for fun play.\n\n## What to Remove\n\n### Files to delete\n- `src/game/ai/cfr/` - entire directory\n  - action-abstraction.ts\n  - compact-format.ts\n  - compact-format-v2.ts\n  - index.ts\n  - mccfr-strategy.ts\n  - mccfr-trainer.ts\n  - regret-table.ts\n  - types.ts\n- `src/game/ai/cfr-metrics.ts`\n- `scripts/train-mccfr.ts`\n- `scripts/train-mccfr-parallel.ts`\n- `public/trained-strategy.json` (172MB)\n- `trained-strategy-100k.json` (if still in root)\n\n### Code to revert\n- `src/game/ai/actionSelector.ts` - remove MCCFR imports and lazy loading\n- `src/stores/gameStore.ts` - remove MCCFR auto-load\n\n### Tests to remove\n- `src/tests/ai/cfr/` - CFR test directory\n\n## What to Create\n\n### docs/archive/MCCFR-EXPLORATION.md\n\nDocument containing:\n1. What MCCFR is and why we tried it\n2. The count-centric abstraction design\n3. Why it failed (abstraction too lossy, lost trump suit identity)\n4. Key learnings about CFR for imperfect information games\n5. Reference to last commit with working code\n\n## Last Commit Reference\n\nMCCFR implementation commits:\n- `665c749` - CFD2 ultra-compact format\n- `53d8a40` - CFD2 implementation complete\n- `eec9ee6` - Training up to 100k iterations\n\nCurrent HEAD: `dfa3ef2`\n\n## Related Beads\n\n- Closes mk5-tailwind-cfb (integrate MCCFR - no longer needed)\n- Closes mk5-tailwind-i2s (extend MCCFR to bidding - no longer needed)\n- Closes mk5-tailwind-l4t (minimum integration - superseded)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T20:48:51.378530226-06:00","updated_at":"2025-12-20T22:18:59.675247028-06:00","closed_at":"2025-12-20T22:06:00.411264361-06:00","close_reason":"MCCFR code deleted, archive document created"}
{"id":"t42-u01z","title":"Update documentation for Crystal Palace completion","description":"Use texas-42 skill.\n\n## Context\nCrystal Palace epic (t42-g4y) and follow-through (t42-qnwe, t42-otet) completed. Documentation is now stale.\n\n## Issues Found\n\n### 1. PERFECTS.md still exists\nThe Perfects feature was deleted (t42-f26) but `docs/PERFECTS.md` still exists.\n- Move to `docs/archive/perfects-feature.md` or delete if duplicate\n\n### 2. MCCFR documentation is stale\nMCCFR was removed (t42-tgr) but ORIENTATION.md lines 706-756 still document it extensively.\n- Remove or move to archive\n- Update AI System section to reflect current strategies\n\n### 3. Crystal Palace changes not documented\n\n**New patterns to document:**\n- `rules-base.ts` as single source of truth for base rule logic\n- `isTrump` added to GameRules interface\n- DerivedViewFields and \"dumb client\" pattern\n- Server-owned projection via `buildKernelView` computing derived fields\n- suitAnalysis removed from GameState (computed on demand)\n- No-bypass architecture tests in `src/tests/guardrails/`\n\n### 4. GameRules method count is inconsistent\n- ORIENTATION.md line 374: \"GameRules (13 Methods)\"\n- ORIENTATION.md line 115: \"14 pure methods\"\n- ARCHITECTURE_PRINCIPLES.md line 92: \"14 methods\"\n- Actual: Now includes isTrump, suitsWithTrump, canFollow, rankInTrick\n\nUpdate to reflect actual interface.\n\n### 5. File Map outdated (ORIENTATION.md ~303-340)\n- `src/game/core/rules.ts` - description outdated\n- `src/game/layers/rules-base.ts` - MISSING (new file)\n- `src/tests/guardrails/` - MISSING (new directory)\n\n## Files to Update\n\n1. `docs/ORIENTATION.md`\n   - Update GameRules section with actual method list\n   - Update File Map with rules-base.ts, guardrails/\n   - Remove or archive MCCFR section\n   - Add \"Dumb Client\" pattern to mental models or architecture\n\n2. `docs/ARCHITECTURE_PRINCIPLES.md`\n   - Update GameRules method count\n   - Add \"Single Source of Truth for Rules\" (rules-base.ts)\n\n3. `docs/PERFECTS.md`\n   - Move to archive or delete\n\n## Verification\n- Read updated docs and verify accuracy against code\n- Ensure no references to deleted features remain","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T19:21:52.27903849-06:00","updated_at":"2025-12-21T19:30:03.542917353-06:00","closed_at":"2025-12-21T19:30:03.542917353-06:00","close_reason":"Documentation updated: removed stale MCCFR section, fixed GameRules method count (14→18), updated File Map with rules-base.ts and guardrails/, added Dumb Client pattern documentation, archived PERFECTS.md","dependencies":[{"issue_id":"t42-u01z","depends_on_id":"t42-g4y","type":"discovered-from","created_at":"2025-12-21T19:21:59.102171683-06:00","created_by":"jason"}]}
{"id":"t42-u5oc","title":"Clean up stores (avoid await void, internal client access, subscribe/unsubscribe getters)","description":"Use texas-42 skill.\\n\\nSome store code uses patterns that are misleading or violate stated boundaries (e.g., internal client accessor).\\n\\nEvidence:\\n- src/stores/playerConfigStore.ts applyConfiguration() awaits game.setPlayerControl() even though it returns void\\n- src/stores/playerConfigStore.ts uses getInternalClient() despite its 'DO NOT use in application code' warning\\n- src/stores/seedFinderStore.ts getStoreValue() uses subscribe/unsubscribe to read state (should use get() from svelte/store)\\n\\nFix direction:\\n- Make command APIs consistently sync (void) or async (Promise) and update callers\\n- Remove internal client dependency from playerConfigStore or move this code to scratch/dev-only\\n- Replace subscribe/unsubscribe getters with get(store)","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-27T00:30:54.092459577-06:00","updated_at":"2025-12-27T00:30:54.092459577-06:00","dependencies":[{"issue_id":"t42-u5oc","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:30:54.095958275-06:00","created_by":"jason"}]}
{"id":"t42-u87","title":"Phase 17: Rename directories and update imports","description":"**Title**: Phase 17: Rename rulesets/ to layers/ directories and update all imports","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T13:51:33.08281154-06:00","updated_at":"2025-12-20T22:18:59.766790712-06:00","closed_at":"2025-11-24T14:27:28.704368456-06:00","dependencies":[{"issue_id":"t42-u87","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T13:52:06.302573043-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-u87","depends_on_id":"t42-c9o","type":"blocks","created_at":"2025-11-24T13:52:15.904001397-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-ueq","title":"[Maintenance \u0026 Cleanup] Fix postinstall script - remove error suppression","description":"Use texas-42 skill.\n\nThe `postinstall` script in package.json currently uses `|| true`, which can hide important errors during installation. This makes debugging harder and can mask real problems.\n\nRemove the `|| true` to make the build process more robust and surface any installation issues immediately.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-29T11:18:52.35296553-06:00","updated_at":"2025-12-20T22:18:59.81108762-06:00","closed_at":"2025-11-29T11:31:59.521304695-06:00"}
{"id":"t42-uf9","title":"Phase 4: Rename directory and update registry","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.299014031-06:00","updated_at":"2025-12-20T22:18:59.778039568-06:00","closed_at":"2025-11-24T13:29:44.176894035-06:00","dependencies":[{"issue_id":"t42-uf9","depends_on_id":"t42-atk","type":"blocks","created_at":"2025-11-24T10:35:45.326711654-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-uf9","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:49.686123382-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-uig","title":"Abstract duplicated executor patterns in actions.ts","description":"Use texas-42 skill.\n\n11-case switch statement and 8 nearly-identical executor functions (validate phase, validate player, apply transformation, check phase transition). The same code written eight times.\n\nFiles: src/game/core/actions.ts","design":"## Design Analysis: Abstracting Duplicated Executor Patterns\n\n### The Crime Against Elegance\n\nExamining `src/game/core/actions.ts`, I observe **eight executor functions** that share an identical structural pattern. This is not merely code repetition - **duplicated code is duplicated bugs**. When we fix validation logic in one executor, we must remember to fix it in seven others.\n\n### The Invariant Pattern\n\nEvery executor follows this **rigid ceremony**:\n\n```\n1. Phase validation     → throw if wrong phase\n2. Player validation    → throw if invalid player (when applicable)  \n3. Rules validation     → rules.isValid*(state, action_data, context)\n4. State transformation → create new immutable state\n5. Phase transition     → determine if phase changes\n6. Return new state     → spread operator with selective updates\n```\n\nThis pattern appears **eight times** with only superficial variations.\n\n### What Varies (The Essence)\n\nThe **essential differences** between executors:\n\n1. **Expected phase** - string literal ('bidding', 'trump_selection', 'playing', etc.)\n2. **Validation function** - which `rules.isValid*` method to invoke\n3. **Validation context** - what additional data the validator needs\n4. **State transformation** - the specific fields to update\n5. **Phase transition logic** - how to determine next phase\n\n### Proposed Solution: Declarative Executor Configuration\n\n```typescript\ninterface ActionExecutorConfig\u003cTAction extends GameAction\u003e {\n  validPhases: GameState['phase'][];\n  phaseError: string;\n  validate: (state: GameState, action: TAction, rules: GameRules) =\u003e boolean;\n  validationError: string;\n  transform: (state: GameState, action: TAction, rules: GameRules) =\u003e Partial\u003cGameState\u003e;\n  requiresPlayer?: boolean;\n}\n\nfunction executeWithConfig\u003cTAction extends GameAction\u003e(\n  state: GameState,\n  action: TAction,\n  config: ActionExecutorConfig\u003cTAction\u003e,\n  rules: GameRules\n): GameState {\n  // 1. Phase validation\n  if (!config.validPhases.includes(state.phase)) {\n    throw new Error(config.phaseError);\n  }\n\n  // 2. Player validation (if required)\n  if (config.requiresPlayer \u0026\u0026 'player' in action) {\n    const playerData = state.players[(action as any).player];\n    if (!playerData) {\n      throw new Error(`Invalid player ID: ${(action as any).player}`);\n    }\n  }\n\n  // 3. Rules validation\n  if (!config.validate(state, action, rules)) {\n    throw new Error(config.validationError);\n  }\n\n  // 4. State transformation\n  return { ...state, ...config.transform(state, action, rules) };\n}\n\nconst executorConfigs = {\n  bid: {\n    validPhases: ['bidding'],\n    phaseError: 'Invalid phase for bidding',\n    requiresPlayer: true,\n    validate: (state, action, rules) =\u003e {\n      const bid = action.value !== undefined\n        ? { type: action.bid, value: action.value, player: action.player }\n        : { type: action.bid, player: action.player };\n      return rules.isValidBid(state, bid, state.players[action.player]!.hand);\n    },\n    validationError: 'Invalid bid',\n    transform: (state, action, rules) =\u003e {\n      // Only the unique bid logic here\n    }\n  },\n  // ... configs for pass, select-trump, play, etc.\n} satisfies Record\u003cstring, ActionExecutorConfig\u003cany\u003e\u003e;\n```\n\n### The Gains\n\n**Before**: 8 functions, ~400 lines, 8 places to fix bugs  \n**After**: 1 generic executor, 8 config objects, ~150 lines, 1 place to fix bugs\n\n✓ **Single point of control** - validation pattern lives in ONE place  \n✓ **Declarative essence** - each config captures ONLY what varies  \n✓ **Type safety** - TypeScript ensures configs match action types  \n✓ **Bug elimination** - fix validation once, fixed everywhere\n\n\u003e \"The purpose of abstraction is not to be vague, but to create a new semantic level in which one can be absolutely precise.\" — E.W. Dijkstra\n\nThis is not premature abstraction - this is **belated** abstraction. The pattern has proven itself across 8 concrete instances.","status":"open","priority":3,"issue_type":"chore","created_at":"2025-11-29T12:10:09.502850858-06:00","updated_at":"2025-12-20T22:18:59.800156242-06:00","dependencies":[{"issue_id":"t42-uig","depends_on_id":"t42-8ee","type":"blocks","created_at":"2025-11-29T12:10:24.735257464-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-uig","depends_on_id":"t42-4b9","type":"parent-child","created_at":"2025-11-29T12:10:39.126722139-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"t42-uik","title":"Update docs to explain consensus layer","description":"Use texas-42 skill.\n\n**Context**: The consensus layer was extracted and refactored (mk5-tailwind-dkn, mk5-tailwind-xql) but docs were not updated to explain it.\n\n**Current state**: SKILL.md just lists `consensus.ts` in the file map without explanation.\n\n**Needed**:\n1. Explain what consensus layer does (gates trick completion/scoring behind human \"agree\" actions)\n2. When to use it (multiplayer human games needing \"tap to continue\" UX)\n3. How it contrasts with speed layer (auto-execution for AI-only games)\n4. Update architecture.md if needed with layer composition examples\n\n**Files to update**:\n- `.claude/skills/texas-42/SKILL.md` - Add consensus to layer descriptions\n- `.claude/skills/texas-42/architecture.md` - Add consensus layer details if missing\n- `docs/ORIENTATION.md` - Brief mention in layer overview if appropriate","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-28T22:38:46.675702297-06:00","updated_at":"2025-12-20T22:18:59.81335266-06:00","closed_at":"2025-11-29T10:54:43.227047629-06:00","labels":["docs"]}
{"id":"t42-umsi","title":"Update URL tooling scripts to match current url-compression (remove legacy d=base64)","description":"Use texas-42 skill.\\n\\nSeveral scripts still assume the legacy '?d=\u003cbase64-json\u003e' URL format, but the app now uses the v2 query-param compression (s/i/p/d/l/t/v/a). This conflicts with the CLAUDE.md 'CRITICAL: URL HANDLING - AUTOMATED TEST GENERATION' workflow.\\n\\nEvidence (legacy d= scripts):\\n- scripts/encode-url.js\\n- scripts/decode-url.js\\n- scripts/get-state-from-url.js\\n- scripts/replay-from-url.js (generate-test path expects d= param)\\n\\nFix direction:\\n- Decide whether to fully delete legacy d= support (preferred per 'No legacy')\\n- Update scripts to accept current URLs and use src/game/utils/urlReplay.ts (already exists)\\n- Ensure --generate-test works with current encoding and writes scratch/*.test.ts per CLAUDE.md\\n- Avoid network-dependent npx usage where possible (pin tsx as devDependency or run via node/ts-node alternative)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-27T00:30:09.491488776-06:00","updated_at":"2025-12-27T00:30:09.491488776-06:00","dependencies":[{"issue_id":"t42-umsi","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:30:09.495408543-06:00","created_by":"jason"}]}
{"id":"t42-ux6","title":"Ensure getView without session never returns unfiltered state","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-11-25T20:21:34.487152543-06:00","updated_at":"2025-12-20T22:18:59.75534161-06:00","closed_at":"2025-11-26T22:10:51.401647875-06:00"}
{"id":"t42-v17","title":"Make suit analysis lazy or derivation-based","description":"Use texas-42 skill.\n\nSuit analysis is computed at state creation, becomes stale after plays, and requires \"IMPORTANT\" comments to prevent bugs. The abstraction has failed.\n\nFiles: src/game/core/suit-analysis.ts, src/game/layers/compose.ts","design":"## The Fundamental Error: Caching Without Invalidation\n\n\"Cache invalidation is one of the two hard problems in computer science.\" This codebase has \"solved\" it by ignoring it entirely—a solution reminiscent of the drunkard searching for his keys under the streetlight because that's where the light is good.\n\n## The Lifecycle of SuitAnalysis: A Study in Staleness\n\n### Birth (Initial State Creation)\n**Location:** `src/game/core/state.ts:177-180`\n```typescript\n{ id: 0, name: 'Player 1', hand: hands[0], teamId: 0 as const, marks: 0, \n  suitAnalysis: analyzeSuits(hands[0]) }\n```\n\nAt state creation, `suitAnalysis` is computed for each player's 7-domino hand with no trump (trump = 'not-selected'). This produces initial suit counts and rankings based purely on natural suits.\n\n### Recomputation (Trump Selection)\n**Location:** `src/game/core/actions.ts:190-194`\n```typescript\nfunction executeTrumpSelection(state, player, selection, rules) {\n  const newPlayers = state.players.map(p =\u003e ({\n    ...p,\n    suitAnalysis: analyzeSuits(p.hand, selection)  // RECOMPUTED with trump\n  }));\n```\n\nWhen trump is selected, ALL players' `suitAnalysis` is recomputed to include trump counts and rankings. This is correct—the trump suit changes what dominoes belong to which conceptual groups.\n\n### Progressive Staleness (Every Play)\n**Location:** `src/game/core/actions.ts:245-249`\n```typescript\nconst newPlayer = {\n  ...playerState,\n  hand: playerState.hand.filter(d =\u003e d.id !== dominoId),\n  suitAnalysis: analyzeSuits(\n    playerState.hand.filter(d =\u003e d.id !== dominoId),\n    state.trump\n  )\n};\n```\n\nEach time a player plays a domino:\n1. The domino is removed from their hand\n2. `suitAnalysis` is RECOMPUTED for the new 6-domino hand\n3. Other players' `suitAnalysis` remains STALE\n\n### The Critical Bug Pattern\n**Location:** `src/game/layers/compose.ts:173-176`\n```typescript\n// IMPORTANT: Suit analysis may be stale after plays, so filter to only include\n// dominoes still in the player's hand\nconst handIds = new Set(player.hand.map(d =\u003e d.id));\nconst validSuitPlays = belongsToSuitDominoes.filter(d =\u003e handIds.has(d.id));\n```\n\nThis comment is the smoking gun. The code must defensively filter `suitAnalysis.rank[suit]` against `player.hand` because `suitAnalysis` may reference dominoes that have already been played.\n\n**When does this occur?** When trump is selected, all players get fresh analysis. But as play progresses:\n- Player 0 plays a domino → Player 0's analysis updated, others remain with 7-domino analysis\n- Player 1 plays a domino → Player 1's analysis updated to 6 dominoes, Player 0 has 6-domino analysis, Players 2-3 still have 7-domino analysis\n- After trick 1 completes: Each player has analysis for their current hand size, but the analysis was computed at DIFFERENT points in time\n\nThe staleness manifests in two dimensions:\n1. **Count Staleness**: `suitAnalysis.count.trump` may overcount trump remaining in hand\n2. **Ranking Staleness**: `suitAnalysis.rank.trump` may include dominoes no longer in hand (the bug this comment prevents)\n\n## The Architectural Mistake\n\n`suitAnalysis` is stored as **denormalized derived state**. The hand is the source of truth, but we maintain a redundant representation of hand structure that must be kept synchronized. This violates the principle: \"State should be normalized; duplication invites inconsistency.\"\n\nThe system has two invariants that should hold but don't:\n1. `suitAnalysis.count[s] === countSuit(hand, s)` for all suits s\n2. `suitAnalysis.rank[s] === hand.filter(d =\u003e belongsToSuit(d, s)).sort(...)` for all suits s\n\nThese invariants hold immediately after computation but decay with every play action.\n\n## Performance Analysis\n\nHow expensive is `analyzeSuits(hand, trump)`?\n\n**Complexity:**\n- Iterates through hand once (7 dominoes max, declining to 0)\n- For each domino: constant-time suit membership checks\n- Sorting 8 suit arrays, each with ≤7 dominoes\n- Total: O(n log n) where n ≤ 7, so effectively O(1)\n\n**Frequency:**\n- Called once per player at state creation (4 calls)\n- Called for all players at trump selection (4 calls)\n- Called once per play (28 calls total for a hand)\n- Total: ~36 calls per hand, each processing ≤7 dominoes\n\n**Benchmark estimate:**\nProcessing 7 dominoes through suit analysis: ~1-2 microseconds on modern hardware.\nTotal analysis overhead per hand: ~50-100 microseconds.\n\nThis is **completely negligible** compared to rendering, network I/O, or even JSON serialization costs.\n\n## Design Proposals\n\n### Proposal A: Pure Derivation (Eliminate Storage)\n\n**Concept:** Delete `suitAnalysis` from `Player` type entirely. Compute on demand.\n\n```typescript\ninterface Player {\n  id: number;\n  name: string;\n  hand: Domino[];\n  teamId: 0 | 1;\n  marks: number;\n  // suitAnalysis DELETED - derive when needed\n}\n\n// Usage sites change from:\nplayer.suitAnalysis.rank.trump\n\n// To:\nanalyzeSuits(player.hand, state.trump).rank.trump\n```\n\n**Advantages:**\n- **Impossible to be stale** - always computed from current hand\n- Simplifies state mutations - no analysis to update\n- Reduces state size and serialization cost\n- Makes state more readable (less redundancy)\n- Eliminates entire class of cache invalidation bugs\n\n**Disadvantages:**\n- Repeated computation at multiple call sites\n- No memoization across calls in same tick\n\n**Performance Impact:**\nCurrent: 28 explicit recomputations + storage updates\nProposed: ~50-100 derivations per hand (rough estimate: 2-3 reads per play decision)\n\nCost increase: 50-100 microseconds per hand. Negligible.\n\n### Proposal B: Lazy Evaluation with Getter\n\n**Concept:** Make `suitAnalysis` a computed property that caches per-instance.\n\n```typescript\ninterface Player {\n  id: number;\n  name: string;\n  hand: Domino[];\n  teamId: 0 | 1;\n  marks: number;\n  _cachedAnalysis?: { hand: Domino[], trump: TrumpSelection, result: SuitAnalysis };\n}\n\nfunction getSuitAnalysis(player: Player, trump: TrumpSelection): SuitAnalysis {\n  if (player._cachedAnalysis?.hand === player.hand \u0026\u0026 \n      isEqual(player._cachedAnalysis?.trump, trump)) {\n    return player._cachedAnalysis.result;\n  }\n  const result = analyzeSuits(player.hand, trump);\n  player._cachedAnalysis = { hand: player.hand, trump, result };\n  return result;\n}\n```\n\n**Advantages:**\n- Automatic invalidation (cache keyed on hand identity)\n- Amortizes cost across multiple reads in same state\n- Transparent to call sites (if using getter)\n\n**Disadvantages:**\n- **Violates immutability** - mutates player object on read\n- Cache key comparison complexity (hand array equality)\n- Hidden state makes reasoning harder\n- Adds complexity for marginal benefit\n\n**Performance:** Slightly better than pure derivation, but at architectural cost.\n\n### Proposal C: Memoization at State Level\n\n**Concept:** Use a WeakMap keyed on state to cache analysis results.\n\n```typescript\nconst analysisCache = new WeakMap\u003cGameState, Map\u003cnumber, SuitAnalysis\u003e\u003e();\n\nfunction getSuitAnalysis(state: GameState, playerId: number): SuitAnalysis {\n  let stateCache = analysisCache.get(state);\n  if (!stateCache) {\n    stateCache = new Map();\n    analysisCache.set(state, stateCache);\n  }\n  \n  let analysis = stateCache.get(playerId);\n  if (!analysis) {\n    const player = state.players[playerId];\n    analysis = analyzeSuits(player.hand, state.trump);\n    stateCache.set(playerId, analysis);\n  }\n  return analysis;\n}\n```\n\n**Advantages:**\n- Preserves immutability\n- Automatic garbage collection when state discarded\n- Amortizes cost within state lifecycle\n- Transparent to state structure\n\n**Disadvantages:**\n- Global cache management\n- WeakMap overhead\n- Complexity for marginal benefit\n- Doesn't serialize (but that's fine - caches shouldn't)\n\n## The Dijkstra Choice: Proposal A (Pure Derivation)\n\n**\"Simplicity is prerequisite for reliability.\"**\n\nThe performance cost is **unmeasurable**. The architectural gain is **immense**.\n\nConsider the reasoning burden each proposal imposes:\n\n**Current (Stored + Manual Invalidation):**\n\"Is this suitAnalysis fresh? Did I update it after the last hand modification? Do I need to filter against hand IDs?\"\n\n**Proposal A (Pure Derivation):**\n\"What is the suit analysis of this hand right now?\"\n\nThe second question has one answer, always correct. The first has infinite answers depending on program history.\n\n## Implementation Strategy\n\n1. **Phase 1: Add derivation helpers**\n   ```typescript\n   // src/game/core/suit-analysis.ts\n   export function getPlayerSuitAnalysis(player: Player, trump: TrumpSelection): SuitAnalysis {\n     return analyzeSuits(player.hand, trump);\n   }\n   ```\n\n2. **Phase 2: Convert all reads**\n   Change `player.suitAnalysis.rank.trump` → `getPlayerSuitAnalysis(player, state.trump).rank.trump`\n   (~30 call sites based on grep)\n\n3. **Phase 3: Delete stored analysis**\n   - Remove from `Player` interface\n   - Remove computations in `createInitialState`\n   - Remove updates in `executeTrumpSelection`\n   - Remove updates in `executePlay`\n   - Remove cloning logic in `cloneGameState`\n\n4. **Phase 4: Delete defensive filtering**\n   Remove the \"IMPORTANT\" comment and its associated filtering logic—no longer needed.\n\n## Conclusion\n\nThis is not premature optimization; it is **belated simplification**. The current design chose to optimize a non-bottleneck (suit analysis computation) at the cost of correctness complexity (staleness bugs requiring defensive coding).\n\nDijkstra would eliminate the cache without hesitation. The performance cost is negligible. The correctness gain is absolute.\n\n**Recommendation: Implement Proposal A.**","status":"open","priority":3,"issue_type":"chore","created_at":"2025-11-29T12:10:06.960650938-06:00","updated_at":"2025-12-20T22:18:59.805616891-06:00","dependencies":[{"issue_id":"t42-v17","depends_on_id":"t42-8ee","type":"blocks","created_at":"2025-11-29T12:10:23.554477756-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-v17","depends_on_id":"t42-4b9","type":"parent-child","created_at":"2025-11-29T12:10:37.830862136-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"t42-v17","depends_on_id":"t42-e92","type":"parent-child","created_at":"2025-12-20T17:55:55.703923507-06:00","created_by":"jason"},{"issue_id":"t42-v17","depends_on_id":"t42-ofy","type":"blocks","created_at":"2025-12-20T17:56:26.292192348-06:00","created_by":"jason"}]}
{"id":"t42-vpn","title":"Use strength table in utilities.ts to eliminate nested loops","description":"## Context\nPerformance optimization for seedFinder/gameSimulator. The strength table exists but is orphaned - never integrated into the hand analysis pipeline.\n\n## Problem\nutilities.ts:196-303 (getDominoesCanBeat/getDominoesBeaten) uses nested loops that call getTrickWinner() 28 times per domino analyzed.\n\nCurrent implementation:\n- Iterates all 28 possible dominoes via nested for loops\n- Calls getTrickWinner() for each to determine if it beats the target domino\n- This happens thousands of times during AI hand analysis\n\n## Solution\nstrength-table.generated.ts already contains precomputed lookup data for exactly this:\n- Pre-computed beatenBy/beats/cannotFollow arrays for all domino/trump/suit combinations\n- domino-strength.ts provides analyzeDominoAsSuitFast() that uses the table\n- Just needs integration into utilities.ts\n\n## Tasks\n1. Replace getDominoesCanBeat() nested loops with strength table lookup\n2. Replace getDominoesBeaten() nested loops with strength table lookup\n3. Ensure exclusion filtering (played dominoes, hand dominoes) still works correctly\n4. Verify determinism - same results as before, just faster\n\n## Impact\nHIGH - Eliminates ~1,700+ getTrickWinner() calls per hand strength evaluation\nExpected: 50-80% reduction in nested loop overhead\n\n## Files\n- src/game/ai/utilities.ts:196-303 (getDominoesCanBeat, getDominoesBeaten)\n- src/game/ai/strength-table.generated.ts (existing lookup table)\n- src/game/ai/domino-strength.ts (analyzeDominoAsSuitFast - reference implementation)\n\n## Related\nPart of seedFinder performance optimization. Biggest single win available.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-19T15:45:20.942469082-06:00","updated_at":"2025-12-20T22:18:59.693375512-06:00","closed_at":"2025-11-19T21:27:17.413947753-06:00"}
{"id":"t42-vvvz","title":"Epic: Perfect-play policy network from solver2 data","description":"Use texas-42 skill.\n\nTrain a neural network on solver2's perfect-play data to create a strong JS-playable AI.\n\n## Pipeline\n\n```\nsolver2 output (.pt) → Python training → ONNX model → JS inference → Game AI\n```\n\n## Why This Approach\n\n- **Ground truth data**: solver2 produces optimal move values for every state\n- **No self-play needed**: Perfect supervision beats noisy self-play\n- **Compact model**: ~100K params, runs in browser\n- **Proven pattern**: Distill expensive solver into fast neural net\n\n## State Counts (from solver2 benchmarks)\n\n- Seed 0 blanks: 7.6M states\n- Seed 0 ones: 46.0M states  \n- Seed 0 fives: 24.3M states\n- Seed 1 blanks: 10.4M states\n- Seed 2 fives: 35.5M states\n\n10 seeds × 10 declarations = ~100-500M training examples.\n\n## Child Beads\n\n1. Train policy network on solver2 output (Python/PyTorch)\n2. JS inference via ONNX\n3. Game integration as AI player","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-27T20:57:31.196613639-06:00","updated_at":"2025-12-27T20:57:31.196613639-06:00"}
{"id":"t42-vw0","title":"attachAIBehavior doc/code mismatch in MULTIPLAYER.md","description":"In MULTIPLAYER.md, the documentation describes attachAIBehavior as picking a strategy, but the actual implementation in the code doesn't match. Found during comprehension test review of the Intermediate AI system.\n\nNeed to:\n1. Verify what attachAIBehavior actually does in the code\n2. Update either the doc or the code to match\n3. Ensure AI strategy selection (beginner/intermediate/random) is properly wired","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-26T15:07:12.725213521-06:00","updated_at":"2025-12-20T22:18:59.753759534-06:00","closed_at":"2025-11-26T23:42:42.677677772-06:00"}
{"id":"t42-vwnt","title":"Finish Factored Algebraic Model Implementation","description":"Use texas-42 skill.\n\n**Status:** in-progress\n**Continues:** t42-9xy3 (Factored Algebraic Model for Dominoes)\n\n---\n\n## What's Done\n\n1. **Created `src/game/core/domino-tables.ts`** - Complete with:\n   - DOMINO_PIPS, dominoToId, getAbsorptionId, getPowerId\n   - EFFECTIVE_SUIT, SUIT_MASK, RANK, HAS_POWER tables\n   - Helper functions: getLedSuitFromTable, canFollowFromTable, etc.\n\n2. **Created verification test** `src/tests/unit/domino-tables.test.ts` - 28 tests, all pass\n\n3. **Updated `src/game/layers/rules-base.ts`** to use suit 7 for ALL absorbed dominoes (not just doubles-trump). Key semantic change: absorbed dominoes lead suit 7, not the trump pip value.\n\n---\n\n## What's Broken (20 test failures)\n\n### Category 1: Test expectations need updating (harmless)\nTests hardcoded old expectations like `expect(getLedSuit(...)).toBe(3)` when 3s are trump. Now returns 7. Files:\n- `src/tests/guardrails/rule-contracts.test.ts`\n- `src/tests/layers/unit/base-layer.test.ts`\n- `src/tests/unit/doubles-trump-renege.test.ts`\n\n### Category 2: Strength table needs regeneration\n- `src/tests/unit/strength-table-generation.test.ts` - 49 missing entries for suit-7\n- Run `npm run generate:strength-table` after fixing\n\n### Category 3: Real bug - Nello broken\n- `src/tests/layers/integration/nello-three-player.test.ts` - Only 1 trick plays instead of 7\n\n**Root cause:** In `canFollowBase`, we check `isAbsorbed` using:\n```typescript\nconst isAbsorbed = isDoublesTrump(trumpSuit)\n  ? isDouble\n  : isRegularSuitTrump(trumpSuit) \u0026\u0026 dominoHasSuit(domino, trumpSuit);\n```\n\nFor nello, `getTrumpSuit()` returns -1 (TRUMP_NOT_SELECTED), so `isAbsorbed = false` for all dominoes. The nello layer overrides `canFollow`, but something in the composition or validation chain is calling the base and getting wrong results.\n\n---\n\n## Fix Strategy\n\n1. **Fix nello bug first** - Either:\n   - Update `canFollowBase` to recognize nello's absorption pattern (doubles)\n   - Or ensure layer composition correctly uses nello's override everywhere\n\n2. **Update test expectations** - Change `toBe(trumpPip)` to `toBe(7)` for absorbed dominoes\n\n3. **Regenerate strength table** - `npm run generate:strength-table`\n\n4. **Run full test suite** - `npm run test:all`\n\n---\n\n## Key Files Changed\n\n- `src/game/core/domino-tables.ts` (NEW)\n- `src/tests/unit/domino-tables.test.ts` (NEW)\n- `src/game/layers/rules-base.ts` (MODIFIED - semantic change to suit 7)\n\n---\n\n## Design Decision Made\n\n**User explicitly chose:** All absorbed dominoes use suit 7, rejecting the old model where trump pip value was reused. Quote: \"this confusion via incidental value alignment has cost us time and time again.\"\n\nThis aligns with the bead's S₇ symmetry insight: all pip trumps are isomorphic, so treat them uniformly as \"absorbed\" rather than \"contains pip X\".","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T19:17:42.382342326-06:00","updated_at":"2025-12-25T20:36:42.655929141-06:00","closed_at":"2025-12-25T20:36:42.655929141-06:00","close_reason":"Fixed nello bug, updated test expectations for suit 7 semantics, regenerated strength table. All 1045 unit tests pass.","dependencies":[{"issue_id":"t42-vwnt","depends_on_id":"t42-9xy3","type":"parent-child","created_at":"2025-12-25T19:17:48.81458147-06:00","created_by":"jason"}]}
{"id":"t42-w2g","title":"Remove all temporal concepts from AI - no fake delays or timing","description":"## Problem\n\nThe AI system currently has timing/delay concepts baked in (artificial delays, setTimeout wrappers, etc.). These are a distracting source of bugs and add complexity without value during development.\n\n## Goal\n\nStrip out ALL temporal concepts from the AI:\n- No artificial delays\n- No setTimeout/setInterval wrappers\n- No \"thinking time\" simulation\n- AI should respond instantly/synchronously where possible\n\n## Rationale\n\n- Timing/delays are presentation concerns, not game logic\n- Can be added later as a thin wrapper at the UI layer\n- Mixing timing into core AI creates subtle bugs and harder debugging\n- \"Crystal palace\" philosophy: keep core logic pure, add decoration later\n\n## Scope\n\nAudit and remove timing-related code from:\n- AI strategy selection\n- AI move execution\n- Any \"delay before AI acts\" logic\n- attachAIBehavior and related wiring\n\nThe UI can add delays later when displaying AI moves - that's where timing belongs.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-26T22:49:31.051976112-06:00","updated_at":"2025-12-20T22:18:59.682771449-06:00","closed_at":"2025-11-26T23:42:42.821150877-06:00"}
{"id":"t42-w8l","title":"Update registry tests to expect 7 rulesets (not 6)","description":"Registry tests expect 6 rulesets but oneHand ruleset was added. Update tests in src/tests/rulesets/composition/registry.test.ts to expect 7 rulesets. Quick fix: change assertions from 6 to 7.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-16T17:16:30.037969607-06:00","updated_at":"2025-12-20T22:18:59.703623696-06:00","closed_at":"2025-11-16T17:19:12.891552656-06:00"}
{"id":"t42-wdf","title":"Create new simple multiplayer code","description":"Create the new simplified multiplayer interfaces and classes.\n\n**Reference**: docs/MULTIPLAYER.md\n\n**IMPORTANT**: This is roll forward / clean break / NO backwards compatibility whatsoever.\n\n**Files to create**:\n- `src/multiplayer/Socket.ts` - Socket interface (~5 lines)\n- `src/multiplayer/GameClient.ts` - Client class (~40 lines)\n- `src/multiplayer/protocol.ts` - Message types (~20 lines)\n- `src/multiplayer/local.ts` - Local wiring with createLocalGame() (~50 lines)\n\n**Key patterns**:\n- Socket: `send()`, `onMessage()`, `close()`\n- GameClient: wraps Socket, maintains view, notifies subscribers\n- Fire-and-forget actions, results via subscription\n- AI clients are just GameClients with AI behavior attached","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-25T14:53:32.570087881-06:00","updated_at":"2025-12-20T22:18:59.688222721-06:00","closed_at":"2025-11-25T15:29:46.679998707-06:00","dependencies":[{"issue_id":"t42-wdf","depends_on_id":"t42-don","type":"parent-child","created_at":"2025-11-25T14:54:05.445791898-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-wdf","depends_on_id":"t42-xka","type":"blocks","created_at":"2025-11-25T14:54:06.289267834-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-wutc","title":"Deduplicate capability builders and tighten playerIndex typing","description":"Use texas-42 skill.\\n\\nHuman and AI base capabilities are currently identical but implemented twice, and several places cast numbers to 0|1|2|3. This is redundant and can hide out-of-range bugs.\\n\\nEvidence:\\n- src/multiplayer/capabilities.ts humanCapabilities() and aiCapabilities() are identical\\n- src/multiplayer/capabilities.ts buildBaseCapabilities() casts playerIndex as 0|1|2|3\\n- src/server/Room.ts casts i as 0|1|2|3 when constructing PlayerSession\\n\\nFix direction:\\n- Collapse human/ai base capability creation into a single function\\n- Add a runtime assert/invariant for playerIndex range where needed\\n- Prefer PlayerIndex type alias (0|1|2|3) and convert at boundaries","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-27T00:30:31.527361819-06:00","updated_at":"2025-12-27T00:30:31.527361819-06:00","dependencies":[{"issue_id":"t42-wutc","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:30:31.530895503-06:00","created_by":"jason"}]}
{"id":"t42-xb4","title":"[Architecture \u0026 Code Quality] Make processAutoExecuteActions pure (remove console logging side effects)","description":"Use texas-42 skill.\n\nMake processAutoExecuteActions pure by removing console logging side effects.\n\n## Completion Checklist\n\n1. Run `npm run test:all` and fix ANY issues (including pre-existing failures)\n2. Commit changes to git (do NOT push or bd sync)","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-11-25T20:21:42.979446326-06:00","updated_at":"2025-12-20T22:18:59.828077883-06:00","closed_at":"2025-12-20T15:21:04.108800422-06:00","close_reason":"Completed"}
{"id":"t42-xka","title":"Delete old multiplayer code","description":"Delete the overcomplicated multiplayer code. This is step 1 of the simplification.\n\n**Reference**: docs/MULTIPLAYER.md\n\n**IMPORTANT**: This is roll forward / clean break / NO backwards compatibility whatsoever.\n\n**Files to delete**:\n- `src/game/multiplayer/NetworkGameClient.ts` (~550 lines of promise queues and caches)\n- `src/server/transports/InProcessTransport.ts`\n- `src/server/transports/Transport.ts`\n- Any other transport-related code\n\n**Why delete first**: Forces us to build the new thing without temptation to keep old patterns. Clean break.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-25T14:52:11.004083141-06:00","updated_at":"2025-12-20T22:18:59.689171476-06:00","closed_at":"2025-11-25T15:17:22.30865088-06:00","dependencies":[{"issue_id":"t42-xka","depends_on_id":"t42-don","type":"parent-child","created_at":"2025-11-25T14:52:59.818293583-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-xlg","title":"Phase 11: Update URL compression","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.328400872-06:00","updated_at":"2025-12-20T22:18:59.772326864-06:00","closed_at":"2025-11-24T13:30:30.85903536-06:00","dependencies":[{"issue_id":"t42-xlg","depends_on_id":"t42-rl4","type":"blocks","created_at":"2025-11-24T10:35:51.244579249-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-xlg","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:55.563861331-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-xoe","title":"Update base ruleset and composition layer","description":"Update src/game/rulesets/base.ts and compose.ts: Change composition base identity from null to { determined: false }. Update base ruleset checkHandOutcome. Depends on mk5-tailwind-2gg.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-16T16:54:47.193807582-06:00","updated_at":"2025-12-20T22:18:59.669123301-06:00","closed_at":"2025-11-16T17:13:10.721945927-06:00"}
{"id":"t42-xql","title":"Verify consensus layer refactor and unify remaining patterns","description":"## Context\n\nmk5-tailwind-dkn completed: consensus extracted into optional layer. Net -204 lines.\n\n## Verification Tasks\n\n1. **Manual testing** - Play a game with consensus layer enabled, verify \"tap to continue\" UX works\n2. **Play without consensus** - Verify AI games flow instantly without agree actions\n3. **URL round-trip** - Confirm URLs no longer contain agree actions, old URLs still decode\n\n## Potential Unification Opportunities\n\nReview what was changed and look for remaining patterns that could be simplified:\n\n1. **consensusHelpers.ts** - Was kept but modified. Is it still needed or can tests be simplified further?\n2. **Integration tests** - Do they still have manual consensus loops that could be removed with speed layer?\n3. **view-projection.ts** - Still has consensus filtering logic (line 192-194). Is this still needed?\n4. **kernel.ts isRecommendedAction** - Still checks for `agree-score`. Review if this is correct behavior.\n\n## Files to Review\n\n- `src/tests/helpers/consensusHelpers.ts` - Delete if no longer valuable\n- `src/tests/layers/integration/*.test.ts` - Simplify if still verbose\n- `src/game/view-projection.ts:192-194` - Check consensus filtering\n- `src/kernel/kernel.ts:207` - Check isRecommendedAction logic","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T12:27:51.30639252-06:00","updated_at":"2025-12-20T22:18:59.681947199-06:00","closed_at":"2025-11-27T18:19:26.412648462-06:00"}
{"id":"t42-xtk","title":"[Architecture \u0026 Code Quality] Speed layer must be opt-in only, never default","description":"The speed layer (`src/game/layers/speed.ts`) auto-executes forced moves (single legal actions) to speed up gameplay. This is a convenience feature that should ONLY be enabled when a player explicitly opts in - never as any kind of default.\n\n**What the speed layer does:**\n- When a player has exactly one legal action, marks it with `autoExecute: true`\n- Sets `authority: 'system'` to bypass normal capability checks\n- Auto-executes consensus actions (complete-trick, score-hand) when no player actions exist\n- Adds `speedMode: true` and `reason` metadata to annotated actions\n\n**Why opt-in only:**\n- Some players prefer to see and confirm every action, even forced ones\n- Speed mode removes the deliberate pacing of standard gameplay\n- Players should consciously choose faster gameplay, not have it imposed\n\n**Current state:**\n- Layer exists in registry as `'speed'` \n- Enabled via `config.layers` array (e.g., `layers: ['speed']`)\n- No evidence of it being a default - layers default to empty array\n\n**Acceptance criteria:**\n- Verify speed layer is never included in default layer configurations\n- Document clearly in any UI/settings that speed mode is optional\n- Consider adding a user preference toggle for speed mode","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-27T10:13:28.989771398-06:00","updated_at":"2025-12-20T22:18:59.747037834-06:00","closed_at":"2025-11-29T10:52:24.58952386-06:00","labels":["layer","ux"],"dependencies":[{"issue_id":"t42-xtk","depends_on_id":"t42-ade","type":"parent-child","created_at":"2025-11-28T10:14:52.758551166-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-xwx","title":"Phase 2: Update type system (GameRuleSet → Layer)","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.292841597-06:00","updated_at":"2025-12-20T22:18:59.78488931-06:00","closed_at":"2025-11-24T11:58:15.840364363-06:00","dependencies":[{"issue_id":"t42-xwx","depends_on_id":"t42-am3","type":"blocks","created_at":"2025-11-24T10:35:43.688382003-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-xwx","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:48.023946409-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-xxi","title":"Maintenance \u0026 Cleanup","description":"Technical debt, broken scripts, coverage gaps, and dependency hygiene.","status":"closed","priority":3,"issue_type":"epic","created_at":"2025-11-28T10:14:25.729087606-06:00","updated_at":"2025-12-20T22:18:59.816619895-06:00","closed_at":"2025-11-28T10:21:24.493724023-06:00"}
{"id":"t42-y0j","title":"Eliminate global AI strategy variable - make strategy per-AI and immutable","description":"Use texas-42 skill.\n\n## Problem\n\nCurrently AI strategy is a **global variable** set via `setDefaultAIStrategy()`. This is architecturally wrong:\n- Global mutable state\n- All AIs share the same strategy\n- Can't have mixed-difficulty games\n- Strategy can change under running AIs\n\n## Goal\n\nEliminate the global strategy variable entirely. Each AI player gets its strategy **at join time** and it's **immutable** for that AI's lifetime.\n\n## Design\n\n1. **Strategy passed at AI creation**: When an AI joins a game, pass the strategy type as a parameter\n   - `attachAIBehavior(client, session, strategyType: AIStrategyType)`\n   - The AI holds its own strategy instance\n\n2. **Immutable per-AI**: Once an AI is created with a strategy, it cannot change\n   - No `setDefaultAIStrategy()` affecting running AIs\n   - Each AI maintains its own strategy reference\n\n3. **Mid-game difficulty changes**: If we want to change difficulty mid-game:\n   - Kick the AI player\n   - Re-add a new AI with the desired difficulty\n   - This is explicit and intentional, not implicit global mutation\n\n4. **Delete global state**:\n   - Remove `setDefaultAIStrategy()` \n   - Remove `getDefaultAIStrategy()`\n   - Remove module-level `defaultStrategy` variable\n\n## Files to Change\n\n- `src/game/ai/actionSelector.ts` - Remove global state, pass strategy to functions\n- `src/multiplayer/local.ts` - Pass strategy type when creating AI\n- `src/stores/gameStore.ts` - Remove any `setDefaultAIStrategy()` calls\n- Tests - Update to pass strategy explicitly\n\n## Future: UI for AI difficulty\n\nOnce this is done, UI for selecting AI difficulty becomes straightforward:\n- User picks difficulty before starting game\n- That difficulty is passed when AIs are created\n- No global state, no mid-game surprises","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-20T08:45:55.064577128-06:00","updated_at":"2025-12-20T22:18:59.71306228-06:00","closed_at":"2025-12-20T15:44:09.099133399-06:00","close_reason":"Eliminated ALL global state from AI strategy system. Now uses dependency injection via AIStrategyConfig - RNG and Monte Carlo config are passed explicitly, no global mutation."}
{"id":"t42-y27y","title":"Unify ranking implementation to match SUIT_ALGEBRA.md","description":"Use texas-42 skill.\n\nThe current codebase was implemented based on a flawed model. Unify everything to the algebraic rules specified in `docs/SUIT_ALGEBRA.md`.\n\n## Problem Statement\n\nThe algebra specifies a clean 6-bit encoding for trick ranking:\n```\nτ(d, ℓ, δ) = (tier \u003c\u003c 4) + rank\n\nTier 2 (trump):    32-46  (binary 10_xxxx)\nTier 1 (follows):  16-30  (binary 01_xxxx)  \nTier 0 (slough):   0      (binary 00_0000)\n\nrank = 14 for doubles, pipSum for others\nException: doubles-trump → rank = p (0-6)\n```\n\nThe current code uses inconsistent encodings:\n- `rankInTrickBase`: 200+/50+/pipSum\n- `RANK` table: 100/50+/20+/pipSum\n- Sloughs get pipSum instead of 0\n\n## Files to Modify\n\n### Primary: `src/game/layers/rules-base.ts`\n- `rankInTrickBase` must implement the algebra's τ function exactly\n- Use `(tier \u003c\u003c 4) + rank` encoding\n- Doubles get rank 14 (except doubles-trump where rank = pip value)\n- Sloughs get rank 0 (not pipSum)\n\n### Primary: `src/game/core/domino-tables.ts`  \n- `RANK` table must match the algebra's encoding\n- Consider whether RANK table should encode full τ or just power-based rank\n- Document the boundary between configuration-dependent and context-dependent\n\n### Secondary: `src/game/layers/nello.ts`\n- Assess whether nello layer can delegate to tables with absorptionId=7, powerId=8\n- Currently reimplements getLedSuit, suitsWithTrump, canFollow, rankInTrick, getValidPlays\n- These should use the unified tables, not duplicate logic\n\n## Implementation Steps\n\n1. Read `docs/SUIT_ALGEBRA.md` thoroughly - this is the specification\n2. Implement the τ function encoding in `rankInTrickBase`:\n   - tier 2 (hasPower): `(2 \u003c\u003c 4) + rank` = 32-46\n   - tier 1 (followsSuit): `(1 \u003c\u003c 4) + rank` = 16-30\n   - tier 0 (slough): 0\n   - rank = 14 for doubles, pipSum for non-doubles\n   - Special case: doubles-trump → rank = pip value (0-6)\n3. Update `RANK` table to match or document why it differs\n4. Fix any linting errors introduced\n5. Run tests and ASSESS failures - do NOT fix tests yet, just document what breaks\n6. Verify nello layer can delegate to tables\n\n## On Completion\n\nWhen this task is complete, create a new bead:\n- Title: \"Remove vestigial ranking code and assess test impact\"\n- Description: Remove getTrickWinnerFromTable, getRankFromTable exports; simplify nello layer to delegate to tables; fix broken tests and document any rule changes discovered","acceptance_criteria":"- [ ] `rankInTrickBase` implements τ(d, ℓ, δ) = (tier \u003c\u003c 4) + rank exactly\n- [ ] Tier encoding: 32-46 trump, 16-30 follows, 0 slough\n- [ ] Doubles get rank 14 (except doubles-trump: rank = p)\n- [ ] Sloughs all return 0\n- [ ] No linting errors\n- [ ] Tests assessed and failures documented (not fixed)\n- [ ] Follow-up bead created for vestigial cleanup","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T18:11:07.559946513-06:00","updated_at":"2025-12-26T18:23:36.142441308-06:00","closed_at":"2025-12-26T18:23:36.142441308-06:00","close_reason":"Implemented τ(d, ℓ, δ) = (tier \u003c\u003c 4) + rank encoding in rankInTrickBase and RANK table. Nello updated to rank doubles by pip value per rules.md. 3 test failures documented in follow-up bead t42-dmze."}
{"id":"t42-ycr","title":"Remove vestigial pre-ruleset logic from core","description":"splash/plunge cases in handOutcome.ts and mathematicalVerification.ts should be handled by rulesets, not core. Core should know nothing about special contracts. This is vestigial from before the ruleset architecture existed.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-16T19:20:55.172278654-06:00","updated_at":"2025-12-20T22:18:59.70290268-06:00","closed_at":"2025-11-16T20:52:01.956743131-06:00"}
{"id":"t42-ygk","title":"Phase 6: Merge oneHand split implementation","description":"**Type**: task","acceptance_criteria":"npm run test:all passes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T10:35:24.307248902-06:00","updated_at":"2025-12-20T22:18:59.776351824-06:00","closed_at":"2025-11-24T13:29:57.444945856-06:00","dependencies":[{"issue_id":"t42-ygk","depends_on_id":"t42-8qf","type":"blocks","created_at":"2025-11-24T10:35:47.007466228-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-ygk","depends_on_id":"t42-8mw","type":"parent-child","created_at":"2025-11-24T11:32:51.363065713-06:00","created_by":"jason","metadata":"{}"}]}
{"id":"t42-ypl","title":"Fix connect handshake leaks unfiltered state/action view before JOIN","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-25T20:21:26.604046182-06:00","updated_at":"2025-12-20T22:18:59.684491163-06:00","closed_at":"2025-11-26T22:10:46.904858828-06:00"}
{"id":"t42-ze7i","title":"Remove score from GPU solver state to reduce 79M→2M states","description":"Use texas-42 skill.\n\n## Problem\nGPU solver at scripts/solver2/ generates 79M states instead of ~2M. Root cause: score (bits 28-33) is included in state, creating 40x redundant states.\n\n## Solution\nRemove score from state representation. The optimal ACTION doesn't depend on current score - you always maximize points-from-here. Score just adds a constant offset to values.\n\n## Implementation\n1. state.py - Remove score from pack/unpack, shift bit positions down\n2. expand.py - Remove score tracking from state transitions  \n3. context.py - Update initial_state() to not include score\n4. solve.py - Terminal value = 0, backward pass accumulates points\n5. Rename TRICK_POINTS to something clearer (e.g., TRICK_VALUE or POINTS_PER_TRICK)\n\n## Constraints\n- Use GPU for testing (--device cuda:0)\n- Use short timeouts (max 30s)\n- ONLY look in scripts/solver2/ - do NOT look in scripts/solver/\n\n## Expected Result\n- State count: 79M → ~2M\n- Peak VRAM: ~3.5GB → ~88MB\n- Fits easily in 4GB GPU","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-27T18:30:57.399732272-06:00","updated_at":"2025-12-27T19:04:22.79422226-06:00","closed_at":"2025-12-27T19:04:22.79422226-06:00","close_reason":"Removed score from state. States reduced from 79M to 5-31M depending on seed. VRAM ~500MB-2.5GB. Added progress logging."}
{"id":"t42-zkd","title":"Optimize PIMC 1: Eliminate deep copies","description":"Use texas-42 skill.\n\nPerformance optimization for PIMC: eliminate unnecessary deep copies during minimax search.\n\n## Problem\n\nDeep copying game state at every node in the minimax tree is expensive. With 100-500 nodes per minimax call and 100+ samples per PIMC decision, this adds up.\n\n## Solution\n\nUse incremental state updates with undo:\n- Apply action (mutate state)\n- Recurse\n- Undo action (restore state)\n\nOr use a copy-on-write approach where only modified fields are copied.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T09:26:23.556704721-06:00","updated_at":"2025-12-23T16:53:27.699783822-06:00","closed_at":"2025-12-23T16:53:27.699783822-06:00","close_reason":"Profiling (t42-79h0) showed executeAction/deep copies are only 3.5% of CPU time. The real bottleneck is checkHandOutcome (~50%). Closing as \"won't fix\" - optimization not justified by data.","dependencies":[{"issue_id":"t42-zkd","depends_on_id":"t42-9ed","type":"blocks","created_at":"2025-12-20T09:26:31.268671577-06:00","created_by":"jason","metadata":"{}"},{"issue_id":"t42-zkd","depends_on_id":"t42-79h0","type":"blocks","created_at":"2025-12-21T22:06:06.408327811-06:00","created_by":"jason"}]}
{"id":"t42-zl13","title":"Fix hints layer capability + requiredCapabilities semantics","description":"Use texas-42 skill.\\n\\nThe hints layer annotates actions with meta.hint and sets meta.requiredCapabilities to [{type:'see-hints'}], but the Capability union does not include 'see-hints'. Worse, requiredCapabilities is currently used as an EXECUTION gate in filterActionForSession(), so adding it can hide/remove actions entirely for all sessions.\\n\\nEvidence:\\n- src/game/layers/hints.ts adds requiredCapabilities: [{ type: 'see-hints' as const }]\\n- src/multiplayer/types.ts Capability union lacks 'see-hints'\\n- src/multiplayer/capabilities.ts canExecuteActionWithCapabilities() blocks actions if requiredCapabilities not satisfied\\n\\nFix direction:\\n- Decide semantics: requiredCapabilities should likely gate visibility of meta fields, not action executability\\n- Either add a dedicated metaVisibility/metadataCapabilities field OR change filterActionForSession to prune hint metadata based on capability, without filtering the action\\n- If we keep capability gating for meta, add 'see-hints' to Capability and grant it appropriately (config or session defaults)","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-27T00:29:52.329966481-06:00","updated_at":"2025-12-27T00:29:52.329966481-06:00","dependencies":[{"issue_id":"t42-zl13","depends_on_id":"t42-21ze","type":"discovered-from","created_at":"2025-12-27T00:29:52.333754234-06:00","created_by":"jason"}]}
